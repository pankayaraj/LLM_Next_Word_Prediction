{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.959878419452888,
  "eval_steps": 1604,
  "global_step": 1536,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 0.271484375,
      "learning_rate": 6.666666666666667e-07,
      "loss": 2.9144,
      "step": 1
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5390625,
      "learning_rate": 1.3333333333333334e-06,
      "loss": 3.1733,
      "step": 2
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.302734375,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 2.9035,
      "step": 3
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.333984375,
      "learning_rate": 2.666666666666667e-06,
      "loss": 3.0506,
      "step": 4
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.298828125,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 3.0884,
      "step": 5
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.26171875,
      "learning_rate": 4.000000000000001e-06,
      "loss": 2.8609,
      "step": 6
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.84375,
      "learning_rate": 4.666666666666667e-06,
      "loss": 3.1147,
      "step": 7
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.41015625,
      "learning_rate": 5.333333333333334e-06,
      "loss": 3.0802,
      "step": 8
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.33984375,
      "learning_rate": 6e-06,
      "loss": 3.0755,
      "step": 9
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.302734375,
      "learning_rate": 6.666666666666667e-06,
      "loss": 3.0057,
      "step": 10
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.50390625,
      "learning_rate": 7.333333333333334e-06,
      "loss": 3.1739,
      "step": 11
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.470703125,
      "learning_rate": 8.000000000000001e-06,
      "loss": 3.0523,
      "step": 12
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.34375,
      "learning_rate": 8.666666666666668e-06,
      "loss": 3.1007,
      "step": 13
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.35546875,
      "learning_rate": 9.333333333333334e-06,
      "loss": 3.1231,
      "step": 14
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.296875,
      "learning_rate": 1e-05,
      "loss": 3.1346,
      "step": 15
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4921875,
      "learning_rate": 1.0666666666666667e-05,
      "loss": 3.0745,
      "step": 16
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.234375,
      "learning_rate": 1.1333333333333334e-05,
      "loss": 3.0629,
      "step": 17
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.259765625,
      "learning_rate": 1.2e-05,
      "loss": 3.0531,
      "step": 18
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.279296875,
      "learning_rate": 1.2666666666666668e-05,
      "loss": 2.9855,
      "step": 19
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.03125,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 3.0807,
      "step": 20
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.341796875,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 3.0656,
      "step": 21
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.41015625,
      "learning_rate": 1.4666666666666668e-05,
      "loss": 3.013,
      "step": 22
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.271484375,
      "learning_rate": 1.5333333333333334e-05,
      "loss": 3.054,
      "step": 23
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.26171875,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 2.9214,
      "step": 24
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.2314453125,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 3.0305,
      "step": 25
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.2490234375,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 2.9111,
      "step": 26
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.2373046875,
      "learning_rate": 1.8e-05,
      "loss": 2.953,
      "step": 27
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.400390625,
      "learning_rate": 1.866666666666667e-05,
      "loss": 2.9529,
      "step": 28
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.34375,
      "learning_rate": 1.9333333333333333e-05,
      "loss": 2.94,
      "step": 29
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.32421875,
      "learning_rate": 2e-05,
      "loss": 2.9738,
      "step": 30
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.2421875,
      "learning_rate": 2.0666666666666666e-05,
      "loss": 3.0292,
      "step": 31
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.251953125,
      "learning_rate": 2.1333333333333335e-05,
      "loss": 3.1237,
      "step": 32
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.63671875,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 3.06,
      "step": 33
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.240234375,
      "learning_rate": 2.2666666666666668e-05,
      "loss": 2.8771,
      "step": 34
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.365234375,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 3.1387,
      "step": 35
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.2353515625,
      "learning_rate": 2.4e-05,
      "loss": 3.0573,
      "step": 36
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.240234375,
      "learning_rate": 2.466666666666667e-05,
      "loss": 2.9563,
      "step": 37
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.23046875,
      "learning_rate": 2.5333333333333337e-05,
      "loss": 3.026,
      "step": 38
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3046875,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 3.0003,
      "step": 39
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.2490234375,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 3.0974,
      "step": 40
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.234375,
      "learning_rate": 2.733333333333333e-05,
      "loss": 2.9068,
      "step": 41
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.251953125,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 2.9938,
      "step": 42
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.22265625,
      "learning_rate": 2.8666666666666668e-05,
      "loss": 2.9428,
      "step": 43
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.21875,
      "learning_rate": 2.9333333333333336e-05,
      "loss": 3.0387,
      "step": 44
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.859375,
      "learning_rate": 3e-05,
      "loss": 3.117,
      "step": 45
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.263671875,
      "learning_rate": 3.066666666666667e-05,
      "loss": 3.0246,
      "step": 46
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.232421875,
      "learning_rate": 3.1333333333333334e-05,
      "loss": 2.9719,
      "step": 47
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4453125,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 3.0238,
      "step": 48
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.236328125,
      "learning_rate": 3.266666666666667e-05,
      "loss": 3.0306,
      "step": 49
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3203125,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 2.9845,
      "step": 50
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.46875,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 2.9583,
      "step": 51
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5,
      "learning_rate": 3.466666666666667e-05,
      "loss": 2.9359,
      "step": 52
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.265625,
      "learning_rate": 3.5333333333333336e-05,
      "loss": 2.9842,
      "step": 53
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.275390625,
      "learning_rate": 3.6e-05,
      "loss": 2.9851,
      "step": 54
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.220703125,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 2.9112,
      "step": 55
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3125,
      "learning_rate": 3.733333333333334e-05,
      "loss": 2.9996,
      "step": 56
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.640625,
      "learning_rate": 3.8e-05,
      "loss": 2.9541,
      "step": 57
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.296875,
      "learning_rate": 3.866666666666667e-05,
      "loss": 2.938,
      "step": 58
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.30859375,
      "learning_rate": 3.933333333333333e-05,
      "loss": 2.8846,
      "step": 59
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5078125,
      "learning_rate": 4e-05,
      "loss": 2.9886,
      "step": 60
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.224609375,
      "learning_rate": 4.066666666666667e-05,
      "loss": 2.945,
      "step": 61
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.25,
      "learning_rate": 4.133333333333333e-05,
      "loss": 2.9903,
      "step": 62
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.2333984375,
      "learning_rate": 4.2e-05,
      "loss": 3.0499,
      "step": 63
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.369140625,
      "learning_rate": 4.266666666666667e-05,
      "loss": 2.9856,
      "step": 64
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.28515625,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 2.9009,
      "step": 65
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.2421875,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 2.8973,
      "step": 66
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3125,
      "learning_rate": 4.466666666666667e-05,
      "loss": 2.9631,
      "step": 67
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.2373046875,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 2.8766,
      "step": 68
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.3828125,
      "learning_rate": 4.600000000000001e-05,
      "loss": 2.9828,
      "step": 69
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.388671875,
      "learning_rate": 4.666666666666667e-05,
      "loss": 3.0682,
      "step": 70
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.369140625,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 2.9485,
      "step": 71
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.2353515625,
      "learning_rate": 4.8e-05,
      "loss": 2.9371,
      "step": 72
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.2490234375,
      "learning_rate": 4.866666666666667e-05,
      "loss": 2.938,
      "step": 73
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.310546875,
      "learning_rate": 4.933333333333334e-05,
      "loss": 3.0083,
      "step": 74
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.240234375,
      "learning_rate": 5e-05,
      "loss": 2.9544,
      "step": 75
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.69140625,
      "learning_rate": 5.0666666666666674e-05,
      "loss": 3.0131,
      "step": 76
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.23828125,
      "learning_rate": 5.133333333333333e-05,
      "loss": 2.9047,
      "step": 77
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.2734375,
      "learning_rate": 5.2000000000000004e-05,
      "loss": 2.9007,
      "step": 78
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.478515625,
      "learning_rate": 5.266666666666666e-05,
      "loss": 2.9153,
      "step": 79
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.2373046875,
      "learning_rate": 5.333333333333333e-05,
      "loss": 2.9161,
      "step": 80
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.251953125,
      "learning_rate": 5.4000000000000005e-05,
      "loss": 2.9946,
      "step": 81
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3203125,
      "learning_rate": 5.466666666666666e-05,
      "loss": 2.9849,
      "step": 82
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.314453125,
      "learning_rate": 5.5333333333333334e-05,
      "loss": 2.9912,
      "step": 83
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.271484375,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 2.9311,
      "step": 84
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.361328125,
      "learning_rate": 5.666666666666667e-05,
      "loss": 2.9557,
      "step": 85
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.365234375,
      "learning_rate": 5.7333333333333336e-05,
      "loss": 2.975,
      "step": 86
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.66796875,
      "learning_rate": 5.8e-05,
      "loss": 2.8936,
      "step": 87
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.25390625,
      "learning_rate": 5.866666666666667e-05,
      "loss": 2.9508,
      "step": 88
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.2392578125,
      "learning_rate": 5.9333333333333343e-05,
      "loss": 3.0377,
      "step": 89
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.2451171875,
      "learning_rate": 6e-05,
      "loss": 3.0361,
      "step": 90
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.2373046875,
      "learning_rate": 6.066666666666667e-05,
      "loss": 2.9769,
      "step": 91
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.255859375,
      "learning_rate": 6.133333333333334e-05,
      "loss": 3.0047,
      "step": 92
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.26171875,
      "learning_rate": 6.2e-05,
      "loss": 2.9052,
      "step": 93
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.30859375,
      "learning_rate": 6.266666666666667e-05,
      "loss": 2.9517,
      "step": 94
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.265625,
      "learning_rate": 6.333333333333333e-05,
      "loss": 2.882,
      "step": 95
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.294921875,
      "learning_rate": 6.400000000000001e-05,
      "loss": 2.9969,
      "step": 96
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.234375,
      "learning_rate": 6.466666666666666e-05,
      "loss": 2.995,
      "step": 97
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.244140625,
      "learning_rate": 6.533333333333334e-05,
      "loss": 2.9385,
      "step": 98
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.2431640625,
      "learning_rate": 6.6e-05,
      "loss": 3.0115,
      "step": 99
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.251953125,
      "learning_rate": 6.666666666666667e-05,
      "loss": 2.9369,
      "step": 100
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.248046875,
      "learning_rate": 6.733333333333333e-05,
      "loss": 2.9646,
      "step": 101
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.2314453125,
      "learning_rate": 6.800000000000001e-05,
      "loss": 2.889,
      "step": 102
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.2412109375,
      "learning_rate": 6.866666666666666e-05,
      "loss": 2.9159,
      "step": 103
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.2578125,
      "learning_rate": 6.933333333333334e-05,
      "loss": 3.0632,
      "step": 104
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.2353515625,
      "learning_rate": 7e-05,
      "loss": 3.0563,
      "step": 105
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.2412109375,
      "learning_rate": 7.066666666666667e-05,
      "loss": 2.876,
      "step": 106
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.2451171875,
      "learning_rate": 7.133333333333334e-05,
      "loss": 2.8341,
      "step": 107
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.27734375,
      "learning_rate": 7.2e-05,
      "loss": 2.851,
      "step": 108
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.2373046875,
      "learning_rate": 7.266666666666667e-05,
      "loss": 2.8592,
      "step": 109
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.2333984375,
      "learning_rate": 7.333333333333333e-05,
      "loss": 2.8983,
      "step": 110
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.240234375,
      "learning_rate": 7.4e-05,
      "loss": 2.8241,
      "step": 111
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.2158203125,
      "learning_rate": 7.466666666666667e-05,
      "loss": 2.9959,
      "step": 112
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.26171875,
      "learning_rate": 7.533333333333334e-05,
      "loss": 2.9701,
      "step": 113
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.228515625,
      "learning_rate": 7.6e-05,
      "loss": 2.8544,
      "step": 114
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.2138671875,
      "learning_rate": 7.666666666666667e-05,
      "loss": 2.9675,
      "step": 115
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.220703125,
      "learning_rate": 7.733333333333333e-05,
      "loss": 2.9452,
      "step": 116
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.2216796875,
      "learning_rate": 7.800000000000001e-05,
      "loss": 3.059,
      "step": 117
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.2314453125,
      "learning_rate": 7.866666666666666e-05,
      "loss": 2.8302,
      "step": 118
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.234375,
      "learning_rate": 7.933333333333334e-05,
      "loss": 2.8319,
      "step": 119
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.2275390625,
      "learning_rate": 8e-05,
      "loss": 2.9534,
      "step": 120
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.2177734375,
      "learning_rate": 8.066666666666667e-05,
      "loss": 2.8976,
      "step": 121
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.2119140625,
      "learning_rate": 8.133333333333334e-05,
      "loss": 2.8291,
      "step": 122
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.2236328125,
      "learning_rate": 8.2e-05,
      "loss": 2.949,
      "step": 123
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.220703125,
      "learning_rate": 8.266666666666667e-05,
      "loss": 2.8532,
      "step": 124
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.208984375,
      "learning_rate": 8.333333333333334e-05,
      "loss": 2.8897,
      "step": 125
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.2353515625,
      "learning_rate": 8.4e-05,
      "loss": 2.9134,
      "step": 126
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.2392578125,
      "learning_rate": 8.466666666666667e-05,
      "loss": 2.8757,
      "step": 127
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.22265625,
      "learning_rate": 8.533333333333334e-05,
      "loss": 2.8755,
      "step": 128
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.21484375,
      "learning_rate": 8.6e-05,
      "loss": 2.84,
      "step": 129
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.2255859375,
      "learning_rate": 8.666666666666667e-05,
      "loss": 2.929,
      "step": 130
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.2265625,
      "learning_rate": 8.733333333333333e-05,
      "loss": 2.8519,
      "step": 131
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.21484375,
      "learning_rate": 8.800000000000001e-05,
      "loss": 2.8904,
      "step": 132
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.2080078125,
      "learning_rate": 8.866666666666668e-05,
      "loss": 3.0264,
      "step": 133
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.2138671875,
      "learning_rate": 8.933333333333334e-05,
      "loss": 2.9073,
      "step": 134
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.232421875,
      "learning_rate": 9e-05,
      "loss": 2.9181,
      "step": 135
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.22265625,
      "learning_rate": 9.066666666666667e-05,
      "loss": 2.781,
      "step": 136
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.212890625,
      "learning_rate": 9.133333333333334e-05,
      "loss": 2.9504,
      "step": 137
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.205078125,
      "learning_rate": 9.200000000000001e-05,
      "loss": 2.9644,
      "step": 138
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.2314453125,
      "learning_rate": 9.266666666666666e-05,
      "loss": 2.9637,
      "step": 139
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.2177734375,
      "learning_rate": 9.333333333333334e-05,
      "loss": 2.8942,
      "step": 140
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.2265625,
      "learning_rate": 9.4e-05,
      "loss": 3.0688,
      "step": 141
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.201171875,
      "learning_rate": 9.466666666666667e-05,
      "loss": 2.9737,
      "step": 142
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.294921875,
      "learning_rate": 9.533333333333334e-05,
      "loss": 3.0496,
      "step": 143
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.23046875,
      "learning_rate": 9.6e-05,
      "loss": 3.0276,
      "step": 144
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.220703125,
      "learning_rate": 9.666666666666667e-05,
      "loss": 2.8307,
      "step": 145
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.2109375,
      "learning_rate": 9.733333333333335e-05,
      "loss": 2.8994,
      "step": 146
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.20703125,
      "learning_rate": 9.8e-05,
      "loss": 2.9371,
      "step": 147
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.2080078125,
      "learning_rate": 9.866666666666668e-05,
      "loss": 2.9944,
      "step": 148
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.216796875,
      "learning_rate": 9.933333333333334e-05,
      "loss": 3.0063,
      "step": 149
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.21484375,
      "learning_rate": 0.0001,
      "loss": 2.9402,
      "step": 150
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.2314453125,
      "learning_rate": 9.999987229439212e-05,
      "loss": 2.9824,
      "step": 151
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.2353515625,
      "learning_rate": 9.999948917822081e-05,
      "loss": 2.8866,
      "step": 152
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.2060546875,
      "learning_rate": 9.999885065344314e-05,
      "loss": 3.0125,
      "step": 153
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2158203125,
      "learning_rate": 9.99979567233208e-05,
      "loss": 2.9351,
      "step": 154
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.19921875,
      "learning_rate": 9.999680739242022e-05,
      "loss": 2.8545,
      "step": 155
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.2099609375,
      "learning_rate": 9.999540266661242e-05,
      "loss": 2.9388,
      "step": 156
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.21484375,
      "learning_rate": 9.999374255307308e-05,
      "loss": 2.9749,
      "step": 157
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.20703125,
      "learning_rate": 9.999182706028239e-05,
      "loss": 3.0017,
      "step": 158
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.23046875,
      "learning_rate": 9.998965619802514e-05,
      "loss": 2.9253,
      "step": 159
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.203125,
      "learning_rate": 9.99872299773906e-05,
      "loss": 2.9141,
      "step": 160
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.2109375,
      "learning_rate": 9.998454841077243e-05,
      "loss": 2.958,
      "step": 161
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.19921875,
      "learning_rate": 9.998161151186865e-05,
      "loss": 2.8914,
      "step": 162
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.19140625,
      "learning_rate": 9.997841929568164e-05,
      "loss": 2.852,
      "step": 163
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.220703125,
      "learning_rate": 9.997497177851794e-05,
      "loss": 2.8664,
      "step": 164
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.275390625,
      "learning_rate": 9.997126897798825e-05,
      "loss": 2.8991,
      "step": 165
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.197265625,
      "learning_rate": 9.996731091300728e-05,
      "loss": 2.7524,
      "step": 166
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.2119140625,
      "learning_rate": 9.996309760379375e-05,
      "loss": 2.9375,
      "step": 167
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.2158203125,
      "learning_rate": 9.995862907187015e-05,
      "loss": 3.0093,
      "step": 168
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.2255859375,
      "learning_rate": 9.995390534006278e-05,
      "loss": 2.8198,
      "step": 169
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.2138671875,
      "learning_rate": 9.994892643250147e-05,
      "loss": 2.8519,
      "step": 170
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.2255859375,
      "learning_rate": 9.994369237461966e-05,
      "loss": 2.9596,
      "step": 171
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.201171875,
      "learning_rate": 9.993820319315405e-05,
      "loss": 3.0501,
      "step": 172
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.2216796875,
      "learning_rate": 9.993245891614462e-05,
      "loss": 2.7585,
      "step": 173
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.2021484375,
      "learning_rate": 9.992645957293444e-05,
      "loss": 3.007,
      "step": 174
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.201171875,
      "learning_rate": 9.992020519416948e-05,
      "loss": 2.9235,
      "step": 175
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.224609375,
      "learning_rate": 9.991369581179852e-05,
      "loss": 3.0794,
      "step": 176
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.21484375,
      "learning_rate": 9.990693145907295e-05,
      "loss": 2.7655,
      "step": 177
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.2001953125,
      "learning_rate": 9.989991217054659e-05,
      "loss": 2.9608,
      "step": 178
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.2099609375,
      "learning_rate": 9.989263798207555e-05,
      "loss": 2.8049,
      "step": 179
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.2158203125,
      "learning_rate": 9.988510893081799e-05,
      "loss": 2.8418,
      "step": 180
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.19921875,
      "learning_rate": 9.987732505523404e-05,
      "loss": 3.0291,
      "step": 181
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.1953125,
      "learning_rate": 9.986928639508546e-05,
      "loss": 2.8627,
      "step": 182
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.2119140625,
      "learning_rate": 9.986099299143549e-05,
      "loss": 2.8165,
      "step": 183
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.2099609375,
      "learning_rate": 9.985244488664878e-05,
      "loss": 3.0648,
      "step": 184
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.2080078125,
      "learning_rate": 9.984364212439088e-05,
      "loss": 2.9655,
      "step": 185
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.2216796875,
      "learning_rate": 9.983458474962834e-05,
      "loss": 2.8958,
      "step": 186
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.2099609375,
      "learning_rate": 9.982527280862821e-05,
      "loss": 2.9539,
      "step": 187
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.23828125,
      "learning_rate": 9.981570634895802e-05,
      "loss": 2.9028,
      "step": 188
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.1982421875,
      "learning_rate": 9.980588541948537e-05,
      "loss": 2.9867,
      "step": 189
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.1943359375,
      "learning_rate": 9.979581007037776e-05,
      "loss": 2.8809,
      "step": 190
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.2080078125,
      "learning_rate": 9.978548035310234e-05,
      "loss": 2.9999,
      "step": 191
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.1953125,
      "learning_rate": 9.977489632042565e-05,
      "loss": 2.873,
      "step": 192
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.1953125,
      "learning_rate": 9.976405802641327e-05,
      "loss": 2.8733,
      "step": 193
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.2060546875,
      "learning_rate": 9.975296552642963e-05,
      "loss": 2.9467,
      "step": 194
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.21875,
      "learning_rate": 9.974161887713775e-05,
      "loss": 2.8847,
      "step": 195
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.2216796875,
      "learning_rate": 9.973001813649882e-05,
      "loss": 2.9088,
      "step": 196
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.1982421875,
      "learning_rate": 9.971816336377204e-05,
      "loss": 2.9149,
      "step": 197
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.1962890625,
      "learning_rate": 9.970605461951426e-05,
      "loss": 2.9141,
      "step": 198
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.205078125,
      "learning_rate": 9.969369196557965e-05,
      "loss": 2.9257,
      "step": 199
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.220703125,
      "learning_rate": 9.968107546511942e-05,
      "loss": 2.8938,
      "step": 200
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.2275390625,
      "learning_rate": 9.966820518258149e-05,
      "loss": 2.8086,
      "step": 201
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.19921875,
      "learning_rate": 9.965508118371013e-05,
      "loss": 3.0066,
      "step": 202
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.201171875,
      "learning_rate": 9.964170353554569e-05,
      "loss": 3.0168,
      "step": 203
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.22265625,
      "learning_rate": 9.96280723064242e-05,
      "loss": 2.9836,
      "step": 204
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.2294921875,
      "learning_rate": 9.961418756597702e-05,
      "loss": 2.9601,
      "step": 205
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.2294921875,
      "learning_rate": 9.960004938513053e-05,
      "loss": 2.8612,
      "step": 206
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.1943359375,
      "learning_rate": 9.958565783610574e-05,
      "loss": 2.8281,
      "step": 207
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.1943359375,
      "learning_rate": 9.957101299241788e-05,
      "loss": 2.8781,
      "step": 208
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.2177734375,
      "learning_rate": 9.955611492887612e-05,
      "loss": 2.8388,
      "step": 209
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.22265625,
      "learning_rate": 9.95409637215831e-05,
      "loss": 2.9818,
      "step": 210
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.201171875,
      "learning_rate": 9.95255594479346e-05,
      "loss": 3.0438,
      "step": 211
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.212890625,
      "learning_rate": 9.950990218661908e-05,
      "loss": 2.9992,
      "step": 212
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.21484375,
      "learning_rate": 9.949399201761738e-05,
      "loss": 2.8257,
      "step": 213
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.2041015625,
      "learning_rate": 9.947782902220217e-05,
      "loss": 2.8423,
      "step": 214
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.216796875,
      "learning_rate": 9.94614132829377e-05,
      "loss": 2.9551,
      "step": 215
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.224609375,
      "learning_rate": 9.944474488367921e-05,
      "loss": 3.029,
      "step": 216
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.2080078125,
      "learning_rate": 9.942782390957264e-05,
      "loss": 2.9184,
      "step": 217
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.2041015625,
      "learning_rate": 9.941065044705411e-05,
      "loss": 2.8325,
      "step": 218
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.1943359375,
      "learning_rate": 9.939322458384954e-05,
      "loss": 3.0197,
      "step": 219
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.19921875,
      "learning_rate": 9.937554640897413e-05,
      "loss": 2.9362,
      "step": 220
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.267578125,
      "learning_rate": 9.935761601273197e-05,
      "loss": 2.8568,
      "step": 221
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.1943359375,
      "learning_rate": 9.933943348671555e-05,
      "loss": 2.9815,
      "step": 222
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.2021484375,
      "learning_rate": 9.932099892380529e-05,
      "loss": 2.8069,
      "step": 223
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.212890625,
      "learning_rate": 9.930231241816906e-05,
      "loss": 2.8999,
      "step": 224
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.220703125,
      "learning_rate": 9.928337406526172e-05,
      "loss": 2.9832,
      "step": 225
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.1962890625,
      "learning_rate": 9.926418396182465e-05,
      "loss": 2.7757,
      "step": 226
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.2177734375,
      "learning_rate": 9.924474220588519e-05,
      "loss": 2.8659,
      "step": 227
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.1982421875,
      "learning_rate": 9.922504889675618e-05,
      "loss": 2.8736,
      "step": 228
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.2451171875,
      "learning_rate": 9.920510413503547e-05,
      "loss": 2.8315,
      "step": 229
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.1953125,
      "learning_rate": 9.918490802260538e-05,
      "loss": 2.9549,
      "step": 230
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.20703125,
      "learning_rate": 9.916446066263219e-05,
      "loss": 2.9471,
      "step": 231
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.201171875,
      "learning_rate": 9.914376215956558e-05,
      "loss": 2.8697,
      "step": 232
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.1953125,
      "learning_rate": 9.912281261913816e-05,
      "loss": 2.8846,
      "step": 233
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.1982421875,
      "learning_rate": 9.910161214836489e-05,
      "loss": 2.9,
      "step": 234
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.208984375,
      "learning_rate": 9.90801608555425e-05,
      "loss": 2.9037,
      "step": 235
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.2021484375,
      "learning_rate": 9.905845885024903e-05,
      "loss": 2.9618,
      "step": 236
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.2060546875,
      "learning_rate": 9.903650624334319e-05,
      "loss": 2.8623,
      "step": 237
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.19921875,
      "learning_rate": 9.901430314696381e-05,
      "loss": 2.744,
      "step": 238
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.2060546875,
      "learning_rate": 9.89918496745293e-05,
      "loss": 3.0137,
      "step": 239
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.197265625,
      "learning_rate": 9.896914594073703e-05,
      "loss": 2.924,
      "step": 240
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.1953125,
      "learning_rate": 9.894619206156276e-05,
      "loss": 3.0208,
      "step": 241
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.212890625,
      "learning_rate": 9.892298815426005e-05,
      "loss": 2.8904,
      "step": 242
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.19921875,
      "learning_rate": 9.889953433735968e-05,
      "loss": 2.9592,
      "step": 243
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.201171875,
      "learning_rate": 9.887583073066899e-05,
      "loss": 2.8104,
      "step": 244
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.2001953125,
      "learning_rate": 9.885187745527133e-05,
      "loss": 2.6908,
      "step": 245
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.2216796875,
      "learning_rate": 9.88276746335254e-05,
      "loss": 2.9496,
      "step": 246
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.2060546875,
      "learning_rate": 9.880322238906462e-05,
      "loss": 2.9413,
      "step": 247
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.201171875,
      "learning_rate": 9.87785208467966e-05,
      "loss": 2.9854,
      "step": 248
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.1923828125,
      "learning_rate": 9.875357013290232e-05,
      "loss": 2.9978,
      "step": 249
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.21484375,
      "learning_rate": 9.87283703748356e-05,
      "loss": 2.8108,
      "step": 250
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.1865234375,
      "learning_rate": 9.87029217013225e-05,
      "loss": 2.8798,
      "step": 251
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.20703125,
      "learning_rate": 9.867722424236054e-05,
      "loss": 2.9159,
      "step": 252
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.2041015625,
      "learning_rate": 9.865127812921809e-05,
      "loss": 2.8654,
      "step": 253
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.2109375,
      "learning_rate": 9.862508349443374e-05,
      "loss": 2.997,
      "step": 254
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.193359375,
      "learning_rate": 9.859864047181552e-05,
      "loss": 2.9448,
      "step": 255
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.201171875,
      "learning_rate": 9.857194919644036e-05,
      "loss": 2.7776,
      "step": 256
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.23046875,
      "learning_rate": 9.854500980465328e-05,
      "loss": 2.8727,
      "step": 257
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.2177734375,
      "learning_rate": 9.851782243406671e-05,
      "loss": 2.967,
      "step": 258
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.201171875,
      "learning_rate": 9.849038722355986e-05,
      "loss": 2.9313,
      "step": 259
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.193359375,
      "learning_rate": 9.846270431327793e-05,
      "loss": 2.8396,
      "step": 260
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.1982421875,
      "learning_rate": 9.843477384463144e-05,
      "loss": 2.892,
      "step": 261
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.203125,
      "learning_rate": 9.840659596029548e-05,
      "loss": 2.9916,
      "step": 262
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.208984375,
      "learning_rate": 9.837817080420903e-05,
      "loss": 2.8211,
      "step": 263
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.21484375,
      "learning_rate": 9.834949852157414e-05,
      "loss": 2.9546,
      "step": 264
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.2119140625,
      "learning_rate": 9.832057925885525e-05,
      "loss": 2.9448,
      "step": 265
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.205078125,
      "learning_rate": 9.829141316377847e-05,
      "loss": 2.9736,
      "step": 266
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.2177734375,
      "learning_rate": 9.826200038533073e-05,
      "loss": 2.9454,
      "step": 267
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.193359375,
      "learning_rate": 9.823234107375914e-05,
      "loss": 2.8735,
      "step": 268
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.2734375,
      "learning_rate": 9.820243538057006e-05,
      "loss": 2.8702,
      "step": 269
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.1953125,
      "learning_rate": 9.817228345852851e-05,
      "loss": 2.9098,
      "step": 270
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.2412109375,
      "learning_rate": 9.814188546165729e-05,
      "loss": 2.7482,
      "step": 271
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.1884765625,
      "learning_rate": 9.811124154523616e-05,
      "loss": 2.9073,
      "step": 272
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.197265625,
      "learning_rate": 9.808035186580111e-05,
      "loss": 3.0365,
      "step": 273
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.203125,
      "learning_rate": 9.804921658114359e-05,
      "loss": 2.955,
      "step": 274
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.1923828125,
      "learning_rate": 9.801783585030959e-05,
      "loss": 2.762,
      "step": 275
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.2080078125,
      "learning_rate": 9.798620983359891e-05,
      "loss": 2.8661,
      "step": 276
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.2255859375,
      "learning_rate": 9.795433869256437e-05,
      "loss": 2.9003,
      "step": 277
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.1962890625,
      "learning_rate": 9.792222259001089e-05,
      "loss": 2.8853,
      "step": 278
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.2197265625,
      "learning_rate": 9.788986168999472e-05,
      "loss": 2.9787,
      "step": 279
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.208984375,
      "learning_rate": 9.785725615782262e-05,
      "loss": 2.8432,
      "step": 280
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.1884765625,
      "learning_rate": 9.782440616005094e-05,
      "loss": 2.8604,
      "step": 281
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.1923828125,
      "learning_rate": 9.779131186448485e-05,
      "loss": 2.9534,
      "step": 282
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.2001953125,
      "learning_rate": 9.775797344017742e-05,
      "loss": 2.8828,
      "step": 283
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.203125,
      "learning_rate": 9.77243910574288e-05,
      "loss": 2.899,
      "step": 284
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.19921875,
      "learning_rate": 9.769056488778537e-05,
      "loss": 2.8659,
      "step": 285
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.19921875,
      "learning_rate": 9.765649510403876e-05,
      "loss": 2.9604,
      "step": 286
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.2119140625,
      "learning_rate": 9.762218188022507e-05,
      "loss": 2.8586,
      "step": 287
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.2177734375,
      "learning_rate": 9.758762539162394e-05,
      "loss": 2.857,
      "step": 288
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.2060546875,
      "learning_rate": 9.755282581475769e-05,
      "loss": 2.8769,
      "step": 289
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.205078125,
      "learning_rate": 9.751778332739033e-05,
      "loss": 2.9267,
      "step": 290
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.2119140625,
      "learning_rate": 9.748249810852678e-05,
      "loss": 2.8505,
      "step": 291
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.1884765625,
      "learning_rate": 9.744697033841182e-05,
      "loss": 2.9105,
      "step": 292
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.31640625,
      "learning_rate": 9.74112001985293e-05,
      "loss": 2.8426,
      "step": 293
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.2177734375,
      "learning_rate": 9.73751878716011e-05,
      "loss": 2.9998,
      "step": 294
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.1962890625,
      "learning_rate": 9.733893354158627e-05,
      "loss": 2.9245,
      "step": 295
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.1923828125,
      "learning_rate": 9.730243739368006e-05,
      "loss": 2.8276,
      "step": 296
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.201171875,
      "learning_rate": 9.726569961431297e-05,
      "loss": 2.9854,
      "step": 297
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.1923828125,
      "learning_rate": 9.722872039114983e-05,
      "loss": 2.8831,
      "step": 298
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.2099609375,
      "learning_rate": 9.719149991308883e-05,
      "loss": 2.9008,
      "step": 299
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.1904296875,
      "learning_rate": 9.715403837026046e-05,
      "loss": 2.8225,
      "step": 300
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.2060546875,
      "learning_rate": 9.711633595402673e-05,
      "loss": 2.668,
      "step": 301
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.1982421875,
      "learning_rate": 9.707839285698003e-05,
      "loss": 2.811,
      "step": 302
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.20703125,
      "learning_rate": 9.70402092729422e-05,
      "loss": 2.8424,
      "step": 303
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.1904296875,
      "learning_rate": 9.700178539696357e-05,
      "loss": 2.9388,
      "step": 304
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.201171875,
      "learning_rate": 9.696312142532192e-05,
      "loss": 2.8066,
      "step": 305
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.251953125,
      "learning_rate": 9.692421755552146e-05,
      "loss": 2.8588,
      "step": 306
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.2001953125,
      "learning_rate": 9.688507398629192e-05,
      "loss": 3.0199,
      "step": 307
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.205078125,
      "learning_rate": 9.68456909175874e-05,
      "loss": 2.8869,
      "step": 308
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.1923828125,
      "learning_rate": 9.680606855058548e-05,
      "loss": 3.0214,
      "step": 309
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2490234375,
      "learning_rate": 9.676620708768607e-05,
      "loss": 2.7682,
      "step": 310
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.212890625,
      "learning_rate": 9.672610673251047e-05,
      "loss": 2.7695,
      "step": 311
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.224609375,
      "learning_rate": 9.66857676899003e-05,
      "loss": 2.7786,
      "step": 312
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.232421875,
      "learning_rate": 9.664519016591644e-05,
      "loss": 2.8967,
      "step": 313
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.201171875,
      "learning_rate": 9.660437436783798e-05,
      "loss": 2.8649,
      "step": 314
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.1982421875,
      "learning_rate": 9.656332050416116e-05,
      "loss": 2.9264,
      "step": 315
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.2265625,
      "learning_rate": 9.652202878459836e-05,
      "loss": 2.8679,
      "step": 316
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.1982421875,
      "learning_rate": 9.64804994200769e-05,
      "loss": 3.0169,
      "step": 317
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.2158203125,
      "learning_rate": 9.643873262273812e-05,
      "loss": 2.9535,
      "step": 318
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.2060546875,
      "learning_rate": 9.639672860593618e-05,
      "loss": 3.0882,
      "step": 319
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.22265625,
      "learning_rate": 9.635448758423702e-05,
      "loss": 2.8857,
      "step": 320
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.2021484375,
      "learning_rate": 9.631200977341726e-05,
      "loss": 2.9318,
      "step": 321
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.216796875,
      "learning_rate": 9.626929539046308e-05,
      "loss": 2.8758,
      "step": 322
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.197265625,
      "learning_rate": 9.622634465356912e-05,
      "loss": 2.8717,
      "step": 323
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.2216796875,
      "learning_rate": 9.61831577821374e-05,
      "loss": 2.8192,
      "step": 324
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.2080078125,
      "learning_rate": 9.613973499677614e-05,
      "loss": 2.8833,
      "step": 325
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.2001953125,
      "learning_rate": 9.609607651929867e-05,
      "loss": 2.981,
      "step": 326
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.19921875,
      "learning_rate": 9.605218257272226e-05,
      "loss": 2.9339,
      "step": 327
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.189453125,
      "learning_rate": 9.600805338126706e-05,
      "loss": 2.9508,
      "step": 328
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.1943359375,
      "learning_rate": 9.596368917035489e-05,
      "loss": 2.8477,
      "step": 329
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.1904296875,
      "learning_rate": 9.591909016660807e-05,
      "loss": 2.8,
      "step": 330
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.201171875,
      "learning_rate": 9.58742565978483e-05,
      "loss": 2.9305,
      "step": 331
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.2119140625,
      "learning_rate": 9.582918869309555e-05,
      "loss": 2.9434,
      "step": 332
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.212890625,
      "learning_rate": 9.578388668256675e-05,
      "loss": 2.9859,
      "step": 333
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.2060546875,
      "learning_rate": 9.573835079767476e-05,
      "loss": 2.8472,
      "step": 334
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.205078125,
      "learning_rate": 9.569258127102707e-05,
      "loss": 2.8493,
      "step": 335
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.240234375,
      "learning_rate": 9.56465783364247e-05,
      "loss": 2.8966,
      "step": 336
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.197265625,
      "learning_rate": 9.560034222886097e-05,
      "loss": 2.9202,
      "step": 337
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.208984375,
      "learning_rate": 9.555387318452027e-05,
      "loss": 2.8406,
      "step": 338
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.205078125,
      "learning_rate": 9.55071714407769e-05,
      "loss": 2.9148,
      "step": 339
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.27734375,
      "learning_rate": 9.546023723619386e-05,
      "loss": 2.8923,
      "step": 340
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.1875,
      "learning_rate": 9.541307081052158e-05,
      "loss": 2.8269,
      "step": 341
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.2119140625,
      "learning_rate": 9.536567240469676e-05,
      "loss": 2.7779,
      "step": 342
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.197265625,
      "learning_rate": 9.531804226084106e-05,
      "loss": 2.8812,
      "step": 343
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.2109375,
      "learning_rate": 9.527018062225999e-05,
      "loss": 2.8519,
      "step": 344
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.20703125,
      "learning_rate": 9.522208773344147e-05,
      "loss": 2.7871,
      "step": 345
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.201171875,
      "learning_rate": 9.517376384005482e-05,
      "loss": 2.8827,
      "step": 346
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.1943359375,
      "learning_rate": 9.512520918894929e-05,
      "loss": 2.989,
      "step": 347
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.234375,
      "learning_rate": 9.507642402815296e-05,
      "loss": 2.8511,
      "step": 348
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.2294921875,
      "learning_rate": 9.502740860687136e-05,
      "loss": 2.7984,
      "step": 349
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.2041015625,
      "learning_rate": 9.497816317548625e-05,
      "loss": 2.9946,
      "step": 350
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.2158203125,
      "learning_rate": 9.492868798555435e-05,
      "loss": 3.0491,
      "step": 351
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.2216796875,
      "learning_rate": 9.4878983289806e-05,
      "loss": 2.9142,
      "step": 352
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.1982421875,
      "learning_rate": 9.482904934214399e-05,
      "loss": 2.9859,
      "step": 353
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.2138671875,
      "learning_rate": 9.477888639764207e-05,
      "loss": 2.6734,
      "step": 354
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.2392578125,
      "learning_rate": 9.472849471254386e-05,
      "loss": 2.9098,
      "step": 355
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.2138671875,
      "learning_rate": 9.467787454426135e-05,
      "loss": 2.8851,
      "step": 356
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.2109375,
      "learning_rate": 9.462702615137375e-05,
      "loss": 2.903,
      "step": 357
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.20703125,
      "learning_rate": 9.457594979362603e-05,
      "loss": 2.8478,
      "step": 358
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.201171875,
      "learning_rate": 9.452464573192769e-05,
      "loss": 2.9294,
      "step": 359
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.197265625,
      "learning_rate": 9.447311422835142e-05,
      "loss": 2.7301,
      "step": 360
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.2265625,
      "learning_rate": 9.442135554613164e-05,
      "loss": 2.8769,
      "step": 361
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.201171875,
      "learning_rate": 9.436936994966333e-05,
      "loss": 2.8787,
      "step": 362
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.19921875,
      "learning_rate": 9.431715770450061e-05,
      "loss": 2.8153,
      "step": 363
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.201171875,
      "learning_rate": 9.42647190773553e-05,
      "loss": 2.9275,
      "step": 364
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.2001953125,
      "learning_rate": 9.421205433609568e-05,
      "loss": 2.9361,
      "step": 365
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.2177734375,
      "learning_rate": 9.415916374974508e-05,
      "loss": 2.8623,
      "step": 366
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.2060546875,
      "learning_rate": 9.410604758848045e-05,
      "loss": 2.7908,
      "step": 367
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.240234375,
      "learning_rate": 9.405270612363108e-05,
      "loss": 2.9422,
      "step": 368
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.203125,
      "learning_rate": 9.399913962767714e-05,
      "loss": 2.954,
      "step": 369
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.21484375,
      "learning_rate": 9.39453483742483e-05,
      "loss": 2.9395,
      "step": 370
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.201171875,
      "learning_rate": 9.389133263812233e-05,
      "loss": 2.8314,
      "step": 371
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.2431640625,
      "learning_rate": 9.383709269522376e-05,
      "loss": 2.9512,
      "step": 372
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.2109375,
      "learning_rate": 9.378262882262237e-05,
      "loss": 2.8335,
      "step": 373
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.2109375,
      "learning_rate": 9.372794129853183e-05,
      "loss": 2.8797,
      "step": 374
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.21875,
      "learning_rate": 9.367303040230828e-05,
      "loss": 2.9573,
      "step": 375
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.2197265625,
      "learning_rate": 9.361789641444892e-05,
      "loss": 2.9636,
      "step": 376
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.2119140625,
      "learning_rate": 9.356253961659049e-05,
      "loss": 3.0348,
      "step": 377
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.2255859375,
      "learning_rate": 9.350696029150796e-05,
      "loss": 2.9379,
      "step": 378
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.2216796875,
      "learning_rate": 9.345115872311299e-05,
      "loss": 2.8708,
      "step": 379
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.2041015625,
      "learning_rate": 9.339513519645249e-05,
      "loss": 2.8555,
      "step": 380
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.2197265625,
      "learning_rate": 9.333888999770721e-05,
      "loss": 2.8698,
      "step": 381
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.2080078125,
      "learning_rate": 9.328242341419024e-05,
      "loss": 2.9412,
      "step": 382
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.208984375,
      "learning_rate": 9.322573573434556e-05,
      "loss": 2.8188,
      "step": 383
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.2314453125,
      "learning_rate": 9.316882724774655e-05,
      "loss": 2.8737,
      "step": 384
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.2119140625,
      "learning_rate": 9.311169824509454e-05,
      "loss": 3.0021,
      "step": 385
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.2451171875,
      "learning_rate": 9.305434901821727e-05,
      "loss": 2.8447,
      "step": 386
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.19921875,
      "learning_rate": 9.299677986006745e-05,
      "loss": 2.8477,
      "step": 387
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.2138671875,
      "learning_rate": 9.293899106472128e-05,
      "loss": 2.7592,
      "step": 388
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.220703125,
      "learning_rate": 9.288098292737687e-05,
      "loss": 2.8087,
      "step": 389
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.2099609375,
      "learning_rate": 9.282275574435281e-05,
      "loss": 2.7886,
      "step": 390
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.20703125,
      "learning_rate": 9.27643098130866e-05,
      "loss": 2.9455,
      "step": 391
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.236328125,
      "learning_rate": 9.270564543213316e-05,
      "loss": 2.8704,
      "step": 392
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.22265625,
      "learning_rate": 9.264676290116334e-05,
      "loss": 3.0358,
      "step": 393
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.2109375,
      "learning_rate": 9.258766252096229e-05,
      "loss": 2.8455,
      "step": 394
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.2041015625,
      "learning_rate": 9.2528344593428e-05,
      "loss": 2.8679,
      "step": 395
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.20703125,
      "learning_rate": 9.246880942156979e-05,
      "loss": 2.92,
      "step": 396
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.205078125,
      "learning_rate": 9.240905730950662e-05,
      "loss": 2.8337,
      "step": 397
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.21875,
      "learning_rate": 9.234908856246573e-05,
      "loss": 2.9253,
      "step": 398
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.2119140625,
      "learning_rate": 9.228890348678091e-05,
      "loss": 2.8178,
      "step": 399
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.2275390625,
      "learning_rate": 9.222850238989103e-05,
      "loss": 2.8431,
      "step": 400
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.20703125,
      "learning_rate": 9.216788558033842e-05,
      "loss": 2.8507,
      "step": 401
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.21875,
      "learning_rate": 9.210705336776738e-05,
      "loss": 2.8042,
      "step": 402
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.232421875,
      "learning_rate": 9.204600606292247e-05,
      "loss": 2.7428,
      "step": 403
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.2431640625,
      "learning_rate": 9.198474397764703e-05,
      "loss": 2.9186,
      "step": 404
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.208984375,
      "learning_rate": 9.192326742488152e-05,
      "loss": 2.758,
      "step": 405
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.2177734375,
      "learning_rate": 9.186157671866198e-05,
      "loss": 2.7766,
      "step": 406
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.21875,
      "learning_rate": 9.179967217411836e-05,
      "loss": 2.9291,
      "step": 407
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.2265625,
      "learning_rate": 9.173755410747295e-05,
      "loss": 2.9151,
      "step": 408
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.2021484375,
      "learning_rate": 9.167522283603881e-05,
      "loss": 2.9379,
      "step": 409
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.2099609375,
      "learning_rate": 9.161267867821802e-05,
      "loss": 2.991,
      "step": 410
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.201171875,
      "learning_rate": 9.154992195350018e-05,
      "loss": 2.8,
      "step": 411
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.2119140625,
      "learning_rate": 9.148695298246071e-05,
      "loss": 2.8673,
      "step": 412
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.2353515625,
      "learning_rate": 9.142377208675925e-05,
      "loss": 2.7978,
      "step": 413
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.2041015625,
      "learning_rate": 9.136037958913797e-05,
      "loss": 2.6354,
      "step": 414
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.2177734375,
      "learning_rate": 9.129677581342e-05,
      "loss": 2.9119,
      "step": 415
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.2197265625,
      "learning_rate": 9.123296108450766e-05,
      "loss": 2.9516,
      "step": 416
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.2275390625,
      "learning_rate": 9.116893572838091e-05,
      "loss": 3.0752,
      "step": 417
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.2080078125,
      "learning_rate": 9.110470007209565e-05,
      "loss": 2.8032,
      "step": 418
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.19921875,
      "learning_rate": 9.104025444378198e-05,
      "loss": 2.8507,
      "step": 419
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.2138671875,
      "learning_rate": 9.097559917264267e-05,
      "loss": 2.9537,
      "step": 420
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.201171875,
      "learning_rate": 9.091073458895132e-05,
      "loss": 2.7444,
      "step": 421
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.2275390625,
      "learning_rate": 9.084566102405079e-05,
      "loss": 2.9968,
      "step": 422
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.2275390625,
      "learning_rate": 9.078037881035144e-05,
      "loss": 2.8609,
      "step": 423
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.2021484375,
      "learning_rate": 9.071488828132946e-05,
      "loss": 2.9784,
      "step": 424
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.21484375,
      "learning_rate": 9.064918977152516e-05,
      "loss": 2.9294,
      "step": 425
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.2158203125,
      "learning_rate": 9.058328361654126e-05,
      "loss": 2.8986,
      "step": 426
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.2138671875,
      "learning_rate": 9.05171701530412e-05,
      "loss": 2.9447,
      "step": 427
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.2177734375,
      "learning_rate": 9.045084971874738e-05,
      "loss": 3.0267,
      "step": 428
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.2109375,
      "learning_rate": 9.038432265243944e-05,
      "loss": 2.945,
      "step": 429
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.19921875,
      "learning_rate": 9.031758929395258e-05,
      "loss": 2.93,
      "step": 430
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.22265625,
      "learning_rate": 9.025064998417573e-05,
      "loss": 2.6988,
      "step": 431
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.2099609375,
      "learning_rate": 9.018350506504994e-05,
      "loss": 2.9954,
      "step": 432
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.2177734375,
      "learning_rate": 9.011615487956648e-05,
      "loss": 2.8464,
      "step": 433
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.2197265625,
      "learning_rate": 9.004859977176526e-05,
      "loss": 2.8591,
      "step": 434
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.2138671875,
      "learning_rate": 8.998084008673285e-05,
      "loss": 2.7918,
      "step": 435
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.2275390625,
      "learning_rate": 8.991287617060099e-05,
      "loss": 2.8686,
      "step": 436
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.59765625,
      "learning_rate": 8.984470837054456e-05,
      "loss": 2.9499,
      "step": 437
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.2109375,
      "learning_rate": 8.977633703477998e-05,
      "loss": 2.8066,
      "step": 438
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.232421875,
      "learning_rate": 8.970776251256341e-05,
      "loss": 2.8707,
      "step": 439
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.2080078125,
      "learning_rate": 8.963898515418884e-05,
      "loss": 2.9348,
      "step": 440
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.244140625,
      "learning_rate": 8.95700053109865e-05,
      "loss": 2.9664,
      "step": 441
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.2158203125,
      "learning_rate": 8.950082333532084e-05,
      "loss": 2.9495,
      "step": 442
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.232421875,
      "learning_rate": 8.943143958058895e-05,
      "loss": 2.8828,
      "step": 443
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.2041015625,
      "learning_rate": 8.93618544012186e-05,
      "loss": 2.751,
      "step": 444
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.220703125,
      "learning_rate": 8.929206815266652e-05,
      "loss": 2.8572,
      "step": 445
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.2197265625,
      "learning_rate": 8.922208119141649e-05,
      "loss": 3.0063,
      "step": 446
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.21484375,
      "learning_rate": 8.915189387497762e-05,
      "loss": 2.9651,
      "step": 447
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.212890625,
      "learning_rate": 8.908150656188246e-05,
      "loss": 2.763,
      "step": 448
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.203125,
      "learning_rate": 8.90109196116852e-05,
      "loss": 2.8864,
      "step": 449
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.228515625,
      "learning_rate": 8.894013338495981e-05,
      "loss": 3.0453,
      "step": 450
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.2099609375,
      "learning_rate": 8.886914824329822e-05,
      "loss": 2.7993,
      "step": 451
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.2216796875,
      "learning_rate": 8.879796454930846e-05,
      "loss": 2.9442,
      "step": 452
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.2392578125,
      "learning_rate": 8.87265826666128e-05,
      "loss": 2.8627,
      "step": 453
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.234375,
      "learning_rate": 8.865500295984591e-05,
      "loss": 2.8572,
      "step": 454
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.234375,
      "learning_rate": 8.8583225794653e-05,
      "loss": 2.8837,
      "step": 455
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.224609375,
      "learning_rate": 8.851125153768792e-05,
      "loss": 2.8056,
      "step": 456
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.2177734375,
      "learning_rate": 8.843908055661129e-05,
      "loss": 2.9423,
      "step": 457
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.2138671875,
      "learning_rate": 8.836671322008873e-05,
      "loss": 2.8376,
      "step": 458
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.22265625,
      "learning_rate": 8.82941498977888e-05,
      "loss": 2.9517,
      "step": 459
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.2158203125,
      "learning_rate": 8.82213909603812e-05,
      "loss": 2.8906,
      "step": 460
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.2158203125,
      "learning_rate": 8.814843677953494e-05,
      "loss": 2.9146,
      "step": 461
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.208984375,
      "learning_rate": 8.807528772791633e-05,
      "loss": 2.8619,
      "step": 462
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.21484375,
      "learning_rate": 8.800194417918713e-05,
      "loss": 2.873,
      "step": 463
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.2080078125,
      "learning_rate": 8.792840650800265e-05,
      "loss": 2.8486,
      "step": 464
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.271484375,
      "learning_rate": 8.78546750900098e-05,
      "loss": 2.8559,
      "step": 465
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2353515625,
      "learning_rate": 8.77807503018452e-05,
      "loss": 2.9266,
      "step": 466
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.2177734375,
      "learning_rate": 8.770663252113327e-05,
      "loss": 2.9509,
      "step": 467
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.216796875,
      "learning_rate": 8.763232212648422e-05,
      "loss": 2.6395,
      "step": 468
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.2216796875,
      "learning_rate": 8.755781949749226e-05,
      "loss": 2.8634,
      "step": 469
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.2080078125,
      "learning_rate": 8.74831250147335e-05,
      "loss": 2.9255,
      "step": 470
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.20703125,
      "learning_rate": 8.740823905976413e-05,
      "loss": 2.8341,
      "step": 471
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.25390625,
      "learning_rate": 8.73331620151184e-05,
      "loss": 2.9161,
      "step": 472
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.2109375,
      "learning_rate": 8.725789426430668e-05,
      "loss": 2.8218,
      "step": 473
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.21875,
      "learning_rate": 8.718243619181355e-05,
      "loss": 2.9347,
      "step": 474
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.2119140625,
      "learning_rate": 8.710678818309576e-05,
      "loss": 2.833,
      "step": 475
    },
    {
      "epoch": 3.09,
      "grad_norm": 0.2119140625,
      "learning_rate": 8.703095062458031e-05,
      "loss": 2.9153,
      "step": 476
    },
    {
      "epoch": 3.09,
      "grad_norm": 0.2236328125,
      "learning_rate": 8.695492390366246e-05,
      "loss": 2.9553,
      "step": 477
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.2255859375,
      "learning_rate": 8.687870840870373e-05,
      "loss": 2.7963,
      "step": 478
    },
    {
      "epoch": 3.11,
      "grad_norm": 0.2080078125,
      "learning_rate": 8.680230452903002e-05,
      "loss": 2.9341,
      "step": 479
    },
    {
      "epoch": 3.11,
      "grad_norm": 0.2177734375,
      "learning_rate": 8.672571265492943e-05,
      "loss": 2.9304,
      "step": 480
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.2060546875,
      "learning_rate": 8.664893317765046e-05,
      "loss": 2.8258,
      "step": 481
    },
    {
      "epoch": 3.13,
      "grad_norm": 0.2451171875,
      "learning_rate": 8.657196648939991e-05,
      "loss": 2.9071,
      "step": 482
    },
    {
      "epoch": 3.13,
      "grad_norm": 0.2060546875,
      "learning_rate": 8.649481298334087e-05,
      "loss": 2.9233,
      "step": 483
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.208984375,
      "learning_rate": 8.641747305359076e-05,
      "loss": 2.8667,
      "step": 484
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.2392578125,
      "learning_rate": 8.63399470952193e-05,
      "loss": 2.969,
      "step": 485
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.205078125,
      "learning_rate": 8.626223550424647e-05,
      "loss": 2.8692,
      "step": 486
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.2412109375,
      "learning_rate": 8.61843386776405e-05,
      "loss": 2.9893,
      "step": 487
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.20703125,
      "learning_rate": 8.610625701331587e-05,
      "loss": 2.9246,
      "step": 488
    },
    {
      "epoch": 3.17,
      "grad_norm": 0.2265625,
      "learning_rate": 8.60279909101312e-05,
      "loss": 2.8639,
      "step": 489
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.21484375,
      "learning_rate": 8.594954076788736e-05,
      "loss": 2.8106,
      "step": 490
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.2255859375,
      "learning_rate": 8.587090698732523e-05,
      "loss": 2.8776,
      "step": 491
    },
    {
      "epoch": 3.19,
      "grad_norm": 0.2197265625,
      "learning_rate": 8.579208997012382e-05,
      "loss": 2.9872,
      "step": 492
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.2158203125,
      "learning_rate": 8.571309011889813e-05,
      "loss": 2.8316,
      "step": 493
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.2333984375,
      "learning_rate": 8.563390783719708e-05,
      "loss": 2.7307,
      "step": 494
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.2216796875,
      "learning_rate": 8.555454352950161e-05,
      "loss": 2.7375,
      "step": 495
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.220703125,
      "learning_rate": 8.547499760122235e-05,
      "loss": 2.8531,
      "step": 496
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.228515625,
      "learning_rate": 8.539527045869775e-05,
      "loss": 2.905,
      "step": 497
    },
    {
      "epoch": 3.23,
      "grad_norm": 0.2109375,
      "learning_rate": 8.531536250919194e-05,
      "loss": 2.9031,
      "step": 498
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.2197265625,
      "learning_rate": 8.523527416089266e-05,
      "loss": 2.7908,
      "step": 499
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.23046875,
      "learning_rate": 8.515500582290914e-05,
      "loss": 2.8953,
      "step": 500
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.2353515625,
      "learning_rate": 8.507455790527008e-05,
      "loss": 2.9114,
      "step": 501
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.2255859375,
      "learning_rate": 8.499393081892147e-05,
      "loss": 2.8888,
      "step": 502
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.2236328125,
      "learning_rate": 8.491312497572457e-05,
      "loss": 2.9205,
      "step": 503
    },
    {
      "epoch": 3.27,
      "grad_norm": 0.2099609375,
      "learning_rate": 8.483214078845373e-05,
      "loss": 2.8697,
      "step": 504
    },
    {
      "epoch": 3.27,
      "grad_norm": 0.2294921875,
      "learning_rate": 8.475097867079436e-05,
      "loss": 2.9177,
      "step": 505
    },
    {
      "epoch": 3.28,
      "grad_norm": 0.2177734375,
      "learning_rate": 8.466963903734077e-05,
      "loss": 2.9486,
      "step": 506
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.244140625,
      "learning_rate": 8.458812230359405e-05,
      "loss": 2.8096,
      "step": 507
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.2138671875,
      "learning_rate": 8.450642888595994e-05,
      "loss": 2.9871,
      "step": 508
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.2138671875,
      "learning_rate": 8.442455920174676e-05,
      "loss": 2.8101,
      "step": 509
    },
    {
      "epoch": 3.31,
      "grad_norm": 0.2158203125,
      "learning_rate": 8.434251366916322e-05,
      "loss": 2.8584,
      "step": 510
    },
    {
      "epoch": 3.31,
      "grad_norm": 0.2236328125,
      "learning_rate": 8.426029270731631e-05,
      "loss": 2.8738,
      "step": 511
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.21875,
      "learning_rate": 8.417789673620914e-05,
      "loss": 2.8513,
      "step": 512
    },
    {
      "epoch": 3.33,
      "grad_norm": 0.220703125,
      "learning_rate": 8.40953261767388e-05,
      "loss": 2.8706,
      "step": 513
    },
    {
      "epoch": 3.33,
      "grad_norm": 0.240234375,
      "learning_rate": 8.401258145069425e-05,
      "loss": 2.9151,
      "step": 514
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.2294921875,
      "learning_rate": 8.392966298075413e-05,
      "loss": 2.8181,
      "step": 515
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.2158203125,
      "learning_rate": 8.384657119048453e-05,
      "loss": 2.8672,
      "step": 516
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.2109375,
      "learning_rate": 8.3763306504337e-05,
      "loss": 2.9051,
      "step": 517
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.21484375,
      "learning_rate": 8.36798693476462e-05,
      "loss": 2.9788,
      "step": 518
    },
    {
      "epoch": 3.37,
      "grad_norm": 0.2138671875,
      "learning_rate": 8.359626014662786e-05,
      "loss": 2.7837,
      "step": 519
    },
    {
      "epoch": 3.37,
      "grad_norm": 0.2275390625,
      "learning_rate": 8.351247932837655e-05,
      "loss": 2.9193,
      "step": 520
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.21875,
      "learning_rate": 8.342852732086345e-05,
      "loss": 3.0203,
      "step": 521
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.23046875,
      "learning_rate": 8.334440455293426e-05,
      "loss": 3.0435,
      "step": 522
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.22265625,
      "learning_rate": 8.326011145430696e-05,
      "loss": 2.7872,
      "step": 523
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.2119140625,
      "learning_rate": 8.31756484555696e-05,
      "loss": 2.9394,
      "step": 524
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.216796875,
      "learning_rate": 8.309101598817813e-05,
      "loss": 2.9172,
      "step": 525
    },
    {
      "epoch": 3.41,
      "grad_norm": 0.2216796875,
      "learning_rate": 8.300621448445416e-05,
      "loss": 2.8628,
      "step": 526
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.2275390625,
      "learning_rate": 8.292124437758279e-05,
      "loss": 2.7355,
      "step": 527
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.248046875,
      "learning_rate": 8.283610610161041e-05,
      "loss": 2.9043,
      "step": 528
    },
    {
      "epoch": 3.43,
      "grad_norm": 0.2490234375,
      "learning_rate": 8.27508000914424e-05,
      "loss": 2.9637,
      "step": 529
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.224609375,
      "learning_rate": 8.266532678284103e-05,
      "loss": 2.8891,
      "step": 530
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.216796875,
      "learning_rate": 8.257968661242312e-05,
      "loss": 2.8281,
      "step": 531
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.2236328125,
      "learning_rate": 8.249388001765788e-05,
      "loss": 3.026,
      "step": 532
    },
    {
      "epoch": 3.46,
      "grad_norm": 0.228515625,
      "learning_rate": 8.240790743686462e-05,
      "loss": 2.9169,
      "step": 533
    },
    {
      "epoch": 3.46,
      "grad_norm": 0.232421875,
      "learning_rate": 8.232176930921057e-05,
      "loss": 2.8883,
      "step": 534
    },
    {
      "epoch": 3.47,
      "grad_norm": 0.21484375,
      "learning_rate": 8.223546607470863e-05,
      "loss": 2.8216,
      "step": 535
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.255859375,
      "learning_rate": 8.214899817421506e-05,
      "loss": 2.81,
      "step": 536
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.22265625,
      "learning_rate": 8.206236604942732e-05,
      "loss": 3.0176,
      "step": 537
    },
    {
      "epoch": 3.49,
      "grad_norm": 0.2216796875,
      "learning_rate": 8.19755701428817e-05,
      "loss": 2.7455,
      "step": 538
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.2236328125,
      "learning_rate": 8.188861089795119e-05,
      "loss": 2.9649,
      "step": 539
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.2060546875,
      "learning_rate": 8.18014887588431e-05,
      "loss": 2.8282,
      "step": 540
    },
    {
      "epoch": 3.51,
      "grad_norm": 0.2197265625,
      "learning_rate": 8.171420417059688e-05,
      "loss": 2.8468,
      "step": 541
    },
    {
      "epoch": 3.51,
      "grad_norm": 0.216796875,
      "learning_rate": 8.162675757908176e-05,
      "loss": 2.8983,
      "step": 542
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.220703125,
      "learning_rate": 8.153914943099456e-05,
      "loss": 2.9954,
      "step": 543
    },
    {
      "epoch": 3.53,
      "grad_norm": 0.2236328125,
      "learning_rate": 8.145138017385736e-05,
      "loss": 2.8162,
      "step": 544
    },
    {
      "epoch": 3.53,
      "grad_norm": 0.2216796875,
      "learning_rate": 8.13634502560152e-05,
      "loss": 2.8807,
      "step": 545
    },
    {
      "epoch": 3.54,
      "grad_norm": 0.2197265625,
      "learning_rate": 8.127536012663382e-05,
      "loss": 2.942,
      "step": 546
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.2255859375,
      "learning_rate": 8.118711023569737e-05,
      "loss": 2.8691,
      "step": 547
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.2109375,
      "learning_rate": 8.10987010340061e-05,
      "loss": 2.8899,
      "step": 548
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.2255859375,
      "learning_rate": 8.101013297317402e-05,
      "loss": 3.0318,
      "step": 549
    },
    {
      "epoch": 3.57,
      "grad_norm": 0.236328125,
      "learning_rate": 8.092140650562665e-05,
      "loss": 2.8851,
      "step": 550
    },
    {
      "epoch": 3.57,
      "grad_norm": 0.2177734375,
      "learning_rate": 8.083252208459873e-05,
      "loss": 2.8906,
      "step": 551
    },
    {
      "epoch": 3.58,
      "grad_norm": 0.2216796875,
      "learning_rate": 8.074348016413177e-05,
      "loss": 2.8669,
      "step": 552
    },
    {
      "epoch": 3.59,
      "grad_norm": 0.2099609375,
      "learning_rate": 8.06542811990719e-05,
      "loss": 3.0059,
      "step": 553
    },
    {
      "epoch": 3.59,
      "grad_norm": 0.2314453125,
      "learning_rate": 8.056492564506744e-05,
      "loss": 2.8723,
      "step": 554
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.2333984375,
      "learning_rate": 8.047541395856661e-05,
      "loss": 3.0097,
      "step": 555
    },
    {
      "epoch": 3.61,
      "grad_norm": 0.2314453125,
      "learning_rate": 8.038574659681517e-05,
      "loss": 2.9037,
      "step": 556
    },
    {
      "epoch": 3.61,
      "grad_norm": 0.2236328125,
      "learning_rate": 8.029592401785412e-05,
      "loss": 2.84,
      "step": 557
    },
    {
      "epoch": 3.62,
      "grad_norm": 0.2265625,
      "learning_rate": 8.020594668051737e-05,
      "loss": 2.878,
      "step": 558
    },
    {
      "epoch": 3.62,
      "grad_norm": 0.220703125,
      "learning_rate": 8.011581504442929e-05,
      "loss": 2.8618,
      "step": 559
    },
    {
      "epoch": 3.63,
      "grad_norm": 0.2216796875,
      "learning_rate": 8.002552957000254e-05,
      "loss": 2.8542,
      "step": 560
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.2275390625,
      "learning_rate": 7.993509071843554e-05,
      "loss": 2.9354,
      "step": 561
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.21875,
      "learning_rate": 7.984449895171026e-05,
      "loss": 2.9461,
      "step": 562
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.2265625,
      "learning_rate": 7.975375473258975e-05,
      "loss": 2.8278,
      "step": 563
    },
    {
      "epoch": 3.66,
      "grad_norm": 0.2138671875,
      "learning_rate": 7.966285852461583e-05,
      "loss": 2.8538,
      "step": 564
    },
    {
      "epoch": 3.66,
      "grad_norm": 0.23046875,
      "learning_rate": 7.957181079210675e-05,
      "loss": 2.9506,
      "step": 565
    },
    {
      "epoch": 3.67,
      "grad_norm": 0.2109375,
      "learning_rate": 7.948061200015474e-05,
      "loss": 2.6927,
      "step": 566
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.275390625,
      "learning_rate": 7.938926261462366e-05,
      "loss": 2.7346,
      "step": 567
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.251953125,
      "learning_rate": 7.92977631021467e-05,
      "loss": 2.962,
      "step": 568
    },
    {
      "epoch": 3.69,
      "grad_norm": 0.2275390625,
      "learning_rate": 7.920611393012385e-05,
      "loss": 2.8689,
      "step": 569
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.21875,
      "learning_rate": 7.911431556671968e-05,
      "loss": 2.8003,
      "step": 570
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.2275390625,
      "learning_rate": 7.90223684808608e-05,
      "loss": 2.9368,
      "step": 571
    },
    {
      "epoch": 3.71,
      "grad_norm": 0.2255859375,
      "learning_rate": 7.893027314223355e-05,
      "loss": 2.8985,
      "step": 572
    },
    {
      "epoch": 3.72,
      "grad_norm": 0.2294921875,
      "learning_rate": 7.883803002128161e-05,
      "loss": 2.9332,
      "step": 573
    },
    {
      "epoch": 3.72,
      "grad_norm": 0.22265625,
      "learning_rate": 7.874563958920349e-05,
      "loss": 2.8862,
      "step": 574
    },
    {
      "epoch": 3.73,
      "grad_norm": 0.220703125,
      "learning_rate": 7.865310231795026e-05,
      "loss": 2.7651,
      "step": 575
    },
    {
      "epoch": 3.73,
      "grad_norm": 0.244140625,
      "learning_rate": 7.856041868022305e-05,
      "loss": 2.8222,
      "step": 576
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.224609375,
      "learning_rate": 7.846758914947068e-05,
      "loss": 2.923,
      "step": 577
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.22265625,
      "learning_rate": 7.837461419988723e-05,
      "loss": 2.7539,
      "step": 578
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.2216796875,
      "learning_rate": 7.828149430640958e-05,
      "loss": 2.8757,
      "step": 579
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.25,
      "learning_rate": 7.818822994471505e-05,
      "loss": 3.0338,
      "step": 580
    },
    {
      "epoch": 3.77,
      "grad_norm": 0.2265625,
      "learning_rate": 7.809482159121887e-05,
      "loss": 2.7604,
      "step": 581
    },
    {
      "epoch": 3.77,
      "grad_norm": 0.2265625,
      "learning_rate": 7.800126972307196e-05,
      "loss": 2.9592,
      "step": 582
    },
    {
      "epoch": 3.78,
      "grad_norm": 0.306640625,
      "learning_rate": 7.790757481815816e-05,
      "loss": 2.7599,
      "step": 583
    },
    {
      "epoch": 3.79,
      "grad_norm": 0.228515625,
      "learning_rate": 7.781373735509207e-05,
      "loss": 2.7743,
      "step": 584
    },
    {
      "epoch": 3.79,
      "grad_norm": 0.22265625,
      "learning_rate": 7.771975781321655e-05,
      "loss": 2.5949,
      "step": 585
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.2236328125,
      "learning_rate": 7.762563667260014e-05,
      "loss": 2.8867,
      "step": 586
    },
    {
      "epoch": 3.81,
      "grad_norm": 0.251953125,
      "learning_rate": 7.753137441403476e-05,
      "loss": 2.8015,
      "step": 587
    },
    {
      "epoch": 3.81,
      "grad_norm": 0.2431640625,
      "learning_rate": 7.743697151903316e-05,
      "loss": 2.8441,
      "step": 588
    },
    {
      "epoch": 3.82,
      "grad_norm": 0.2236328125,
      "learning_rate": 7.734242846982649e-05,
      "loss": 2.8909,
      "step": 589
    },
    {
      "epoch": 3.83,
      "grad_norm": 0.228515625,
      "learning_rate": 7.724774574936188e-05,
      "loss": 2.8932,
      "step": 590
    },
    {
      "epoch": 3.83,
      "grad_norm": 0.25390625,
      "learning_rate": 7.715292384129991e-05,
      "loss": 2.8609,
      "step": 591
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.2275390625,
      "learning_rate": 7.705796323001211e-05,
      "loss": 2.7629,
      "step": 592
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.234375,
      "learning_rate": 7.696286440057862e-05,
      "loss": 2.9248,
      "step": 593
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.2578125,
      "learning_rate": 7.686762783878562e-05,
      "loss": 2.7648,
      "step": 594
    },
    {
      "epoch": 3.86,
      "grad_norm": 0.2255859375,
      "learning_rate": 7.677225403112276e-05,
      "loss": 2.7897,
      "step": 595
    },
    {
      "epoch": 3.86,
      "grad_norm": 0.2373046875,
      "learning_rate": 7.667674346478089e-05,
      "loss": 2.7902,
      "step": 596
    },
    {
      "epoch": 3.87,
      "grad_norm": 0.2451171875,
      "learning_rate": 7.658109662764941e-05,
      "loss": 2.8817,
      "step": 597
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.2490234375,
      "learning_rate": 7.64853140083138e-05,
      "loss": 2.7734,
      "step": 598
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.228515625,
      "learning_rate": 7.638939609605318e-05,
      "loss": 2.7619,
      "step": 599
    },
    {
      "epoch": 3.89,
      "grad_norm": 0.2265625,
      "learning_rate": 7.629334338083773e-05,
      "loss": 2.9165,
      "step": 600
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.21875,
      "learning_rate": 7.619715635332631e-05,
      "loss": 2.8995,
      "step": 601
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.23828125,
      "learning_rate": 7.610083550486381e-05,
      "loss": 2.817,
      "step": 602
    },
    {
      "epoch": 3.91,
      "grad_norm": 0.23046875,
      "learning_rate": 7.600438132747872e-05,
      "loss": 2.9488,
      "step": 603
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.2421875,
      "learning_rate": 7.590779431388064e-05,
      "loss": 2.8321,
      "step": 604
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.228515625,
      "learning_rate": 7.581107495745769e-05,
      "loss": 2.7825,
      "step": 605
    },
    {
      "epoch": 3.93,
      "grad_norm": 0.236328125,
      "learning_rate": 7.571422375227403e-05,
      "loss": 2.819,
      "step": 606
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.2275390625,
      "learning_rate": 7.561724119306734e-05,
      "loss": 2.9308,
      "step": 607
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.2314453125,
      "learning_rate": 7.552012777524631e-05,
      "loss": 2.9679,
      "step": 608
    },
    {
      "epoch": 3.95,
      "grad_norm": 0.23046875,
      "learning_rate": 7.542288399488804e-05,
      "loss": 2.9195,
      "step": 609
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.2158203125,
      "learning_rate": 7.532551034873559e-05,
      "loss": 2.7696,
      "step": 610
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.232421875,
      "learning_rate": 7.522800733419535e-05,
      "loss": 2.8725,
      "step": 611
    },
    {
      "epoch": 3.97,
      "grad_norm": 0.2333984375,
      "learning_rate": 7.513037544933465e-05,
      "loss": 2.8998,
      "step": 612
    },
    {
      "epoch": 3.97,
      "grad_norm": 0.244140625,
      "learning_rate": 7.5032615192879e-05,
      "loss": 2.8386,
      "step": 613
    },
    {
      "epoch": 3.98,
      "grad_norm": 0.2236328125,
      "learning_rate": 7.493472706420974e-05,
      "loss": 2.7892,
      "step": 614
    },
    {
      "epoch": 3.99,
      "grad_norm": 0.228515625,
      "learning_rate": 7.483671156336141e-05,
      "loss": 2.91,
      "step": 615
    },
    {
      "epoch": 3.99,
      "grad_norm": 0.22265625,
      "learning_rate": 7.473856919101918e-05,
      "loss": 2.9163,
      "step": 616
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.21875,
      "learning_rate": 7.464030044851625e-05,
      "loss": 2.7508,
      "step": 617
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.2265625,
      "learning_rate": 7.454190583783142e-05,
      "loss": 2.9447,
      "step": 618
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.263671875,
      "learning_rate": 7.444338586158646e-05,
      "loss": 2.8628,
      "step": 619
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.234375,
      "learning_rate": 7.43447410230435e-05,
      "loss": 2.9871,
      "step": 620
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.2392578125,
      "learning_rate": 7.424597182610248e-05,
      "loss": 2.8239,
      "step": 621
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.2216796875,
      "learning_rate": 7.414707877529863e-05,
      "loss": 2.9611,
      "step": 622
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.224609375,
      "learning_rate": 7.404806237579984e-05,
      "loss": 2.7269,
      "step": 623
    },
    {
      "epoch": 4.05,
      "grad_norm": 0.2333984375,
      "learning_rate": 7.394892313340409e-05,
      "loss": 2.8375,
      "step": 624
    },
    {
      "epoch": 4.05,
      "grad_norm": 0.228515625,
      "learning_rate": 7.384966155453685e-05,
      "loss": 2.8355,
      "step": 625
    },
    {
      "epoch": 4.06,
      "grad_norm": 0.2265625,
      "learning_rate": 7.375027814624855e-05,
      "loss": 2.854,
      "step": 626
    },
    {
      "epoch": 4.07,
      "grad_norm": 0.234375,
      "learning_rate": 7.365077341621192e-05,
      "loss": 2.9918,
      "step": 627
    },
    {
      "epoch": 4.07,
      "grad_norm": 0.2353515625,
      "learning_rate": 7.355114787271945e-05,
      "loss": 3.0063,
      "step": 628
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.2392578125,
      "learning_rate": 7.345140202468077e-05,
      "loss": 2.9123,
      "step": 629
    },
    {
      "epoch": 4.09,
      "grad_norm": 0.2255859375,
      "learning_rate": 7.335153638162005e-05,
      "loss": 2.8628,
      "step": 630
    },
    {
      "epoch": 4.09,
      "grad_norm": 0.2353515625,
      "learning_rate": 7.325155145367335e-05,
      "loss": 2.9065,
      "step": 631
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.2412109375,
      "learning_rate": 7.315144775158617e-05,
      "loss": 2.9423,
      "step": 632
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.21875,
      "learning_rate": 7.305122578671063e-05,
      "loss": 2.7666,
      "step": 633
    },
    {
      "epoch": 4.11,
      "grad_norm": 0.28125,
      "learning_rate": 7.295088607100304e-05,
      "loss": 2.8806,
      "step": 634
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.232421875,
      "learning_rate": 7.285042911702115e-05,
      "loss": 2.9417,
      "step": 635
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.224609375,
      "learning_rate": 7.274985543792165e-05,
      "loss": 2.937,
      "step": 636
    },
    {
      "epoch": 4.13,
      "grad_norm": 0.2255859375,
      "learning_rate": 7.264916554745742e-05,
      "loss": 2.7119,
      "step": 637
    },
    {
      "epoch": 4.14,
      "grad_norm": 0.2275390625,
      "learning_rate": 7.2548359959975e-05,
      "loss": 2.8445,
      "step": 638
    },
    {
      "epoch": 4.14,
      "grad_norm": 0.224609375,
      "learning_rate": 7.244743919041198e-05,
      "loss": 3.002,
      "step": 639
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.2470703125,
      "learning_rate": 7.234640375429427e-05,
      "loss": 2.7852,
      "step": 640
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.2275390625,
      "learning_rate": 7.224525416773354e-05,
      "loss": 2.9537,
      "step": 641
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.232421875,
      "learning_rate": 7.214399094742457e-05,
      "loss": 2.7808,
      "step": 642
    },
    {
      "epoch": 4.17,
      "grad_norm": 0.240234375,
      "learning_rate": 7.204261461064258e-05,
      "loss": 2.9676,
      "step": 643
    },
    {
      "epoch": 4.18,
      "grad_norm": 0.2333984375,
      "learning_rate": 7.194112567524069e-05,
      "loss": 2.9139,
      "step": 644
    },
    {
      "epoch": 4.18,
      "grad_norm": 0.232421875,
      "learning_rate": 7.183952465964711e-05,
      "loss": 2.8894,
      "step": 645
    },
    {
      "epoch": 4.19,
      "grad_norm": 0.2470703125,
      "learning_rate": 7.173781208286262e-05,
      "loss": 2.7805,
      "step": 646
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.2265625,
      "learning_rate": 7.16359884644579e-05,
      "loss": 2.7489,
      "step": 647
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.2353515625,
      "learning_rate": 7.15340543245708e-05,
      "loss": 2.887,
      "step": 648
    },
    {
      "epoch": 4.21,
      "grad_norm": 0.2412109375,
      "learning_rate": 7.143201018390381e-05,
      "loss": 3.0104,
      "step": 649
    },
    {
      "epoch": 4.21,
      "grad_norm": 0.236328125,
      "learning_rate": 7.132985656372126e-05,
      "loss": 2.9439,
      "step": 650
    },
    {
      "epoch": 4.22,
      "grad_norm": 0.2490234375,
      "learning_rate": 7.122759398584677e-05,
      "loss": 2.9776,
      "step": 651
    },
    {
      "epoch": 4.23,
      "grad_norm": 0.2451171875,
      "learning_rate": 7.112522297266053e-05,
      "loss": 2.9369,
      "step": 652
    },
    {
      "epoch": 4.23,
      "grad_norm": 0.2451171875,
      "learning_rate": 7.102274404709661e-05,
      "loss": 2.8486,
      "step": 653
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.23828125,
      "learning_rate": 7.092015773264038e-05,
      "loss": 2.9156,
      "step": 654
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.23828125,
      "learning_rate": 7.081746455332576e-05,
      "loss": 2.9445,
      "step": 655
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.2421875,
      "learning_rate": 7.071466503373251e-05,
      "loss": 2.9528,
      "step": 656
    },
    {
      "epoch": 4.26,
      "grad_norm": 0.2333984375,
      "learning_rate": 7.061175969898366e-05,
      "loss": 2.8281,
      "step": 657
    },
    {
      "epoch": 4.27,
      "grad_norm": 0.2431640625,
      "learning_rate": 7.050874907474271e-05,
      "loss": 2.8805,
      "step": 658
    },
    {
      "epoch": 4.27,
      "grad_norm": 0.2421875,
      "learning_rate": 7.040563368721108e-05,
      "loss": 2.7507,
      "step": 659
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.244140625,
      "learning_rate": 7.030241406312528e-05,
      "loss": 2.8637,
      "step": 660
    },
    {
      "epoch": 4.29,
      "grad_norm": 0.2373046875,
      "learning_rate": 7.019909072975429e-05,
      "loss": 2.8872,
      "step": 661
    },
    {
      "epoch": 4.29,
      "grad_norm": 0.2353515625,
      "learning_rate": 7.009566421489687e-05,
      "loss": 2.8171,
      "step": 662
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.236328125,
      "learning_rate": 6.99921350468789e-05,
      "loss": 2.8969,
      "step": 663
    },
    {
      "epoch": 4.31,
      "grad_norm": 0.255859375,
      "learning_rate": 6.988850375455056e-05,
      "loss": 3.0025,
      "step": 664
    },
    {
      "epoch": 4.31,
      "grad_norm": 0.2578125,
      "learning_rate": 6.978477086728374e-05,
      "loss": 2.8526,
      "step": 665
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.236328125,
      "learning_rate": 6.968093691496931e-05,
      "loss": 2.8715,
      "step": 666
    },
    {
      "epoch": 4.33,
      "grad_norm": 0.24609375,
      "learning_rate": 6.957700242801439e-05,
      "loss": 2.7217,
      "step": 667
    },
    {
      "epoch": 4.33,
      "grad_norm": 0.2421875,
      "learning_rate": 6.947296793733962e-05,
      "loss": 2.8822,
      "step": 668
    },
    {
      "epoch": 4.34,
      "grad_norm": 0.251953125,
      "learning_rate": 6.936883397437654e-05,
      "loss": 2.7174,
      "step": 669
    },
    {
      "epoch": 4.34,
      "grad_norm": 0.2421875,
      "learning_rate": 6.926460107106482e-05,
      "loss": 2.8861,
      "step": 670
    },
    {
      "epoch": 4.35,
      "grad_norm": 0.2333984375,
      "learning_rate": 6.916026975984946e-05,
      "loss": 2.8073,
      "step": 671
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.26953125,
      "learning_rate": 6.905584057367823e-05,
      "loss": 2.8513,
      "step": 672
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.2333984375,
      "learning_rate": 6.895131404599884e-05,
      "loss": 2.904,
      "step": 673
    },
    {
      "epoch": 4.37,
      "grad_norm": 0.251953125,
      "learning_rate": 6.884669071075622e-05,
      "loss": 2.9084,
      "step": 674
    },
    {
      "epoch": 4.38,
      "grad_norm": 0.248046875,
      "learning_rate": 6.874197110238985e-05,
      "loss": 2.8593,
      "step": 675
    },
    {
      "epoch": 4.38,
      "grad_norm": 0.2431640625,
      "learning_rate": 6.863715575583098e-05,
      "loss": 2.8095,
      "step": 676
    },
    {
      "epoch": 4.39,
      "grad_norm": 0.2392578125,
      "learning_rate": 6.853224520649991e-05,
      "loss": 2.8484,
      "step": 677
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.26953125,
      "learning_rate": 6.842723999030325e-05,
      "loss": 2.7656,
      "step": 678
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.25390625,
      "learning_rate": 6.832214064363121e-05,
      "loss": 2.9813,
      "step": 679
    },
    {
      "epoch": 4.41,
      "grad_norm": 0.236328125,
      "learning_rate": 6.821694770335481e-05,
      "loss": 2.9336,
      "step": 680
    },
    {
      "epoch": 4.42,
      "grad_norm": 0.279296875,
      "learning_rate": 6.811166170682323e-05,
      "loss": 2.9336,
      "step": 681
    },
    {
      "epoch": 4.42,
      "grad_norm": 0.255859375,
      "learning_rate": 6.800628319186091e-05,
      "loss": 2.791,
      "step": 682
    },
    {
      "epoch": 4.43,
      "grad_norm": 0.2392578125,
      "learning_rate": 6.790081269676496e-05,
      "loss": 2.9948,
      "step": 683
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.2294921875,
      "learning_rate": 6.779525076030232e-05,
      "loss": 2.8877,
      "step": 684
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.25,
      "learning_rate": 6.768959792170706e-05,
      "loss": 2.7593,
      "step": 685
    },
    {
      "epoch": 4.45,
      "grad_norm": 0.2392578125,
      "learning_rate": 6.758385472067757e-05,
      "loss": 2.7711,
      "step": 686
    },
    {
      "epoch": 4.45,
      "grad_norm": 0.287109375,
      "learning_rate": 6.747802169737382e-05,
      "loss": 2.8785,
      "step": 687
    },
    {
      "epoch": 4.46,
      "grad_norm": 0.2294921875,
      "learning_rate": 6.737209939241467e-05,
      "loss": 2.7024,
      "step": 688
    },
    {
      "epoch": 4.47,
      "grad_norm": 0.2431640625,
      "learning_rate": 6.726608834687498e-05,
      "loss": 2.8623,
      "step": 689
    },
    {
      "epoch": 4.47,
      "grad_norm": 0.279296875,
      "learning_rate": 6.715998910228296e-05,
      "loss": 2.8384,
      "step": 690
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.2734375,
      "learning_rate": 6.705380220061737e-05,
      "loss": 2.9464,
      "step": 691
    },
    {
      "epoch": 4.49,
      "grad_norm": 0.2392578125,
      "learning_rate": 6.694752818430472e-05,
      "loss": 2.8279,
      "step": 692
    },
    {
      "epoch": 4.49,
      "grad_norm": 0.2265625,
      "learning_rate": 6.68411675962165e-05,
      "loss": 2.9335,
      "step": 693
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.2265625,
      "learning_rate": 6.673472097966646e-05,
      "loss": 2.8504,
      "step": 694
    },
    {
      "epoch": 4.51,
      "grad_norm": 0.2490234375,
      "learning_rate": 6.66281888784078e-05,
      "loss": 2.8746,
      "step": 695
    },
    {
      "epoch": 4.51,
      "grad_norm": 0.26171875,
      "learning_rate": 6.65215718366304e-05,
      "loss": 2.8849,
      "step": 696
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.248046875,
      "learning_rate": 6.641487039895802e-05,
      "loss": 2.9125,
      "step": 697
    },
    {
      "epoch": 4.53,
      "grad_norm": 0.24609375,
      "learning_rate": 6.630808511044552e-05,
      "loss": 2.8212,
      "step": 698
    },
    {
      "epoch": 4.53,
      "grad_norm": 0.2451171875,
      "learning_rate": 6.620121651657614e-05,
      "loss": 2.8858,
      "step": 699
    },
    {
      "epoch": 4.54,
      "grad_norm": 0.232421875,
      "learning_rate": 6.60942651632586e-05,
      "loss": 2.994,
      "step": 700
    },
    {
      "epoch": 4.55,
      "grad_norm": 0.26171875,
      "learning_rate": 6.59872315968244e-05,
      "loss": 2.8422,
      "step": 701
    },
    {
      "epoch": 4.55,
      "grad_norm": 0.2373046875,
      "learning_rate": 6.588011636402504e-05,
      "loss": 2.8878,
      "step": 702
    },
    {
      "epoch": 4.56,
      "grad_norm": 0.244140625,
      "learning_rate": 6.577292001202913e-05,
      "loss": 2.6996,
      "step": 703
    },
    {
      "epoch": 4.56,
      "grad_norm": 0.2470703125,
      "learning_rate": 6.566564308841969e-05,
      "loss": 2.7742,
      "step": 704
    },
    {
      "epoch": 4.57,
      "grad_norm": 0.244140625,
      "learning_rate": 6.555828614119132e-05,
      "loss": 2.8342,
      "step": 705
    },
    {
      "epoch": 4.58,
      "grad_norm": 0.248046875,
      "learning_rate": 6.545084971874738e-05,
      "loss": 2.7907,
      "step": 706
    },
    {
      "epoch": 4.58,
      "grad_norm": 0.2412109375,
      "learning_rate": 6.534333436989721e-05,
      "loss": 2.9286,
      "step": 707
    },
    {
      "epoch": 4.59,
      "grad_norm": 0.25390625,
      "learning_rate": 6.523574064385332e-05,
      "loss": 2.8837,
      "step": 708
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.24609375,
      "learning_rate": 6.512806909022862e-05,
      "loss": 2.8773,
      "step": 709
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.275390625,
      "learning_rate": 6.502032025903355e-05,
      "loss": 2.8676,
      "step": 710
    },
    {
      "epoch": 4.61,
      "grad_norm": 0.240234375,
      "learning_rate": 6.49124947006733e-05,
      "loss": 2.8825,
      "step": 711
    },
    {
      "epoch": 4.62,
      "grad_norm": 0.2578125,
      "learning_rate": 6.480459296594502e-05,
      "loss": 2.9624,
      "step": 712
    },
    {
      "epoch": 4.62,
      "grad_norm": 0.251953125,
      "learning_rate": 6.469661560603498e-05,
      "loss": 2.7431,
      "step": 713
    },
    {
      "epoch": 4.63,
      "grad_norm": 0.2392578125,
      "learning_rate": 6.458856317251574e-05,
      "loss": 2.7913,
      "step": 714
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.2470703125,
      "learning_rate": 6.448043621734337e-05,
      "loss": 2.8111,
      "step": 715
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.234375,
      "learning_rate": 6.437223529285463e-05,
      "loss": 2.8851,
      "step": 716
    },
    {
      "epoch": 4.65,
      "grad_norm": 0.240234375,
      "learning_rate": 6.42639609517641e-05,
      "loss": 2.8323,
      "step": 717
    },
    {
      "epoch": 4.66,
      "grad_norm": 0.2490234375,
      "learning_rate": 6.41556137471614e-05,
      "loss": 2.8309,
      "step": 718
    },
    {
      "epoch": 4.66,
      "grad_norm": 0.2333984375,
      "learning_rate": 6.404719423250835e-05,
      "loss": 2.9156,
      "step": 719
    },
    {
      "epoch": 4.67,
      "grad_norm": 0.234375,
      "learning_rate": 6.393870296163615e-05,
      "loss": 2.8716,
      "step": 720
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.26953125,
      "learning_rate": 6.383014048874259e-05,
      "loss": 2.9366,
      "step": 721
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.2451171875,
      "learning_rate": 6.372150736838906e-05,
      "loss": 2.923,
      "step": 722
    },
    {
      "epoch": 4.69,
      "grad_norm": 0.25,
      "learning_rate": 6.361280415549797e-05,
      "loss": 2.8042,
      "step": 723
    },
    {
      "epoch": 4.69,
      "grad_norm": 0.2431640625,
      "learning_rate": 6.350403140534971e-05,
      "loss": 2.8529,
      "step": 724
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.2392578125,
      "learning_rate": 6.339518967357985e-05,
      "loss": 2.8613,
      "step": 725
    },
    {
      "epoch": 4.71,
      "grad_norm": 0.2314453125,
      "learning_rate": 6.328627951617639e-05,
      "loss": 2.6432,
      "step": 726
    },
    {
      "epoch": 4.71,
      "grad_norm": 0.23046875,
      "learning_rate": 6.317730148947684e-05,
      "loss": 2.9011,
      "step": 727
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.2392578125,
      "learning_rate": 6.306825615016542e-05,
      "loss": 2.8865,
      "step": 728
    },
    {
      "epoch": 4.73,
      "grad_norm": 0.2333984375,
      "learning_rate": 6.295914405527017e-05,
      "loss": 2.8611,
      "step": 729
    },
    {
      "epoch": 4.73,
      "grad_norm": 0.216796875,
      "learning_rate": 6.284996576216014e-05,
      "loss": 2.879,
      "step": 730
    },
    {
      "epoch": 4.74,
      "grad_norm": 0.2578125,
      "learning_rate": 6.274072182854258e-05,
      "loss": 2.7749,
      "step": 731
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.25,
      "learning_rate": 6.263141281245996e-05,
      "loss": 2.8148,
      "step": 732
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.234375,
      "learning_rate": 6.252203927228727e-05,
      "loss": 2.8564,
      "step": 733
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.2373046875,
      "learning_rate": 6.24126017667291e-05,
      "loss": 2.9329,
      "step": 734
    },
    {
      "epoch": 4.77,
      "grad_norm": 0.228515625,
      "learning_rate": 6.230310085481677e-05,
      "loss": 2.9132,
      "step": 735
    },
    {
      "epoch": 4.77,
      "grad_norm": 0.41015625,
      "learning_rate": 6.219353709590549e-05,
      "loss": 2.8841,
      "step": 736
    },
    {
      "epoch": 4.78,
      "grad_norm": 0.240234375,
      "learning_rate": 6.208391104967152e-05,
      "loss": 2.7788,
      "step": 737
    },
    {
      "epoch": 4.79,
      "grad_norm": 0.251953125,
      "learning_rate": 6.197422327610931e-05,
      "loss": 2.7996,
      "step": 738
    },
    {
      "epoch": 4.79,
      "grad_norm": 0.228515625,
      "learning_rate": 6.186447433552861e-05,
      "loss": 2.7927,
      "step": 739
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.26171875,
      "learning_rate": 6.17546647885516e-05,
      "loss": 2.7385,
      "step": 740
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.2333984375,
      "learning_rate": 6.164479519611013e-05,
      "loss": 2.9378,
      "step": 741
    },
    {
      "epoch": 4.81,
      "grad_norm": 0.24609375,
      "learning_rate": 6.153486611944267e-05,
      "loss": 2.9609,
      "step": 742
    },
    {
      "epoch": 4.82,
      "grad_norm": 0.240234375,
      "learning_rate": 6.142487812009163e-05,
      "loss": 2.8865,
      "step": 743
    },
    {
      "epoch": 4.82,
      "grad_norm": 0.24609375,
      "learning_rate": 6.131483175990036e-05,
      "loss": 2.8591,
      "step": 744
    },
    {
      "epoch": 4.83,
      "grad_norm": 0.248046875,
      "learning_rate": 6.120472760101039e-05,
      "loss": 2.7495,
      "step": 745
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.3046875,
      "learning_rate": 6.109456620585845e-05,
      "loss": 2.8123,
      "step": 746
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.2578125,
      "learning_rate": 6.098434813717362e-05,
      "loss": 2.8354,
      "step": 747
    },
    {
      "epoch": 4.85,
      "grad_norm": 0.23828125,
      "learning_rate": 6.0874073957974565e-05,
      "loss": 2.8516,
      "step": 748
    },
    {
      "epoch": 4.86,
      "grad_norm": 0.2392578125,
      "learning_rate": 6.076374423156651e-05,
      "loss": 2.9193,
      "step": 749
    },
    {
      "epoch": 4.86,
      "grad_norm": 0.2412109375,
      "learning_rate": 6.065335952153845e-05,
      "loss": 2.8762,
      "step": 750
    },
    {
      "epoch": 4.87,
      "grad_norm": 0.453125,
      "learning_rate": 6.054292039176024e-05,
      "loss": 2.7768,
      "step": 751
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.25,
      "learning_rate": 6.043242740637971e-05,
      "loss": 2.9083,
      "step": 752
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.2177734375,
      "learning_rate": 6.032188112981986e-05,
      "loss": 2.7781,
      "step": 753
    },
    {
      "epoch": 4.89,
      "grad_norm": 0.251953125,
      "learning_rate": 6.021128212677582e-05,
      "loss": 2.8614,
      "step": 754
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.25,
      "learning_rate": 6.010063096221214e-05,
      "loss": 2.8548,
      "step": 755
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.248046875,
      "learning_rate": 5.998992820135978e-05,
      "loss": 2.7642,
      "step": 756
    },
    {
      "epoch": 4.91,
      "grad_norm": 0.2333984375,
      "learning_rate": 5.987917440971328e-05,
      "loss": 2.7289,
      "step": 757
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.255859375,
      "learning_rate": 5.976837015302784e-05,
      "loss": 3.0088,
      "step": 758
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.263671875,
      "learning_rate": 5.965751599731646e-05,
      "loss": 3.0301,
      "step": 759
    },
    {
      "epoch": 4.93,
      "grad_norm": 0.2431640625,
      "learning_rate": 5.954661250884703e-05,
      "loss": 2.8895,
      "step": 760
    },
    {
      "epoch": 4.93,
      "grad_norm": 0.2373046875,
      "learning_rate": 5.943566025413947e-05,
      "loss": 2.8989,
      "step": 761
    },
    {
      "epoch": 4.94,
      "grad_norm": 0.2431640625,
      "learning_rate": 5.932465979996274e-05,
      "loss": 2.7724,
      "step": 762
    },
    {
      "epoch": 4.95,
      "grad_norm": 0.2431640625,
      "learning_rate": 5.9213611713332105e-05,
      "loss": 2.8496,
      "step": 763
    },
    {
      "epoch": 4.95,
      "grad_norm": 0.25,
      "learning_rate": 5.910251656150609e-05,
      "loss": 2.8623,
      "step": 764
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.2431640625,
      "learning_rate": 5.899137491198363e-05,
      "loss": 2.8811,
      "step": 765
    },
    {
      "epoch": 4.97,
      "grad_norm": 0.234375,
      "learning_rate": 5.888018733250122e-05,
      "loss": 2.8041,
      "step": 766
    },
    {
      "epoch": 4.97,
      "grad_norm": 0.251953125,
      "learning_rate": 5.876895439102996e-05,
      "loss": 2.9093,
      "step": 767
    },
    {
      "epoch": 4.98,
      "grad_norm": 0.2421875,
      "learning_rate": 5.8657676655772664e-05,
      "loss": 2.7384,
      "step": 768
    },
    {
      "epoch": 4.99,
      "grad_norm": 0.2412109375,
      "learning_rate": 5.854635469516094e-05,
      "loss": 2.79,
      "step": 769
    },
    {
      "epoch": 4.99,
      "grad_norm": 0.25390625,
      "learning_rate": 5.8434989077852366e-05,
      "loss": 2.8417,
      "step": 770
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.25390625,
      "learning_rate": 5.8323580372727494e-05,
      "loss": 2.8055,
      "step": 771
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2421875,
      "learning_rate": 5.821212914888695e-05,
      "loss": 2.9322,
      "step": 772
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.2451171875,
      "learning_rate": 5.810063597564862e-05,
      "loss": 2.8527,
      "step": 773
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.2431640625,
      "learning_rate": 5.7989101422544635e-05,
      "loss": 2.8602,
      "step": 774
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.2294921875,
      "learning_rate": 5.78775260593185e-05,
      "loss": 2.7685,
      "step": 775
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.275390625,
      "learning_rate": 5.776591045592219e-05,
      "loss": 2.9886,
      "step": 776
    },
    {
      "epoch": 5.04,
      "grad_norm": 0.2294921875,
      "learning_rate": 5.765425518251327e-05,
      "loss": 2.7399,
      "step": 777
    },
    {
      "epoch": 5.04,
      "grad_norm": 0.24609375,
      "learning_rate": 5.754256080945191e-05,
      "loss": 2.7561,
      "step": 778
    },
    {
      "epoch": 5.05,
      "grad_norm": 0.251953125,
      "learning_rate": 5.7430827907298026e-05,
      "loss": 2.8124,
      "step": 779
    },
    {
      "epoch": 5.06,
      "grad_norm": 0.25,
      "learning_rate": 5.7319057046808335e-05,
      "loss": 2.8271,
      "step": 780
    },
    {
      "epoch": 5.06,
      "grad_norm": 0.255859375,
      "learning_rate": 5.7207248798933464e-05,
      "loss": 2.8709,
      "step": 781
    },
    {
      "epoch": 5.07,
      "grad_norm": 0.2470703125,
      "learning_rate": 5.709540373481506e-05,
      "loss": 2.8222,
      "step": 782
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.240234375,
      "learning_rate": 5.6983522425782755e-05,
      "loss": 2.7604,
      "step": 783
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.291015625,
      "learning_rate": 5.687160544335138e-05,
      "loss": 2.9652,
      "step": 784
    },
    {
      "epoch": 5.09,
      "grad_norm": 0.2431640625,
      "learning_rate": 5.6759653359218e-05,
      "loss": 2.935,
      "step": 785
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.2431640625,
      "learning_rate": 5.664766674525897e-05,
      "loss": 2.9264,
      "step": 786
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.2470703125,
      "learning_rate": 5.6535646173527026e-05,
      "loss": 2.9221,
      "step": 787
    },
    {
      "epoch": 5.11,
      "grad_norm": 0.25,
      "learning_rate": 5.6423592216248377e-05,
      "loss": 2.8823,
      "step": 788
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.2490234375,
      "learning_rate": 5.631150544581979e-05,
      "loss": 2.9078,
      "step": 789
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.240234375,
      "learning_rate": 5.619938643480561e-05,
      "loss": 2.8621,
      "step": 790
    },
    {
      "epoch": 5.13,
      "grad_norm": 0.251953125,
      "learning_rate": 5.608723575593491e-05,
      "loss": 2.9557,
      "step": 791
    },
    {
      "epoch": 5.14,
      "grad_norm": 0.25390625,
      "learning_rate": 5.59750539820985e-05,
      "loss": 2.8704,
      "step": 792
    },
    {
      "epoch": 5.14,
      "grad_norm": 0.259765625,
      "learning_rate": 5.5862841686346056e-05,
      "loss": 3.0442,
      "step": 793
    },
    {
      "epoch": 5.15,
      "grad_norm": 0.2373046875,
      "learning_rate": 5.5750599441883155e-05,
      "loss": 2.9999,
      "step": 794
    },
    {
      "epoch": 5.16,
      "grad_norm": 0.2333984375,
      "learning_rate": 5.5638327822068345e-05,
      "loss": 2.7802,
      "step": 795
    },
    {
      "epoch": 5.16,
      "grad_norm": 0.2431640625,
      "learning_rate": 5.5526027400410266e-05,
      "loss": 2.8031,
      "step": 796
    },
    {
      "epoch": 5.17,
      "grad_norm": 0.265625,
      "learning_rate": 5.541369875056466e-05,
      "loss": 2.9267,
      "step": 797
    },
    {
      "epoch": 5.17,
      "grad_norm": 0.2451171875,
      "learning_rate": 5.530134244633145e-05,
      "loss": 2.8802,
      "step": 798
    },
    {
      "epoch": 5.18,
      "grad_norm": 0.2412109375,
      "learning_rate": 5.518895906165186e-05,
      "loss": 2.798,
      "step": 799
    },
    {
      "epoch": 5.19,
      "grad_norm": 0.2734375,
      "learning_rate": 5.5076549170605406e-05,
      "loss": 2.7434,
      "step": 800
    },
    {
      "epoch": 5.19,
      "grad_norm": 0.2451171875,
      "learning_rate": 5.496411334740705e-05,
      "loss": 3.0203,
      "step": 801
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.2431640625,
      "learning_rate": 5.485165216640419e-05,
      "loss": 2.7157,
      "step": 802
    },
    {
      "epoch": 5.21,
      "grad_norm": 0.2431640625,
      "learning_rate": 5.4739166202073756e-05,
      "loss": 2.8139,
      "step": 803
    },
    {
      "epoch": 5.21,
      "grad_norm": 0.24609375,
      "learning_rate": 5.4626656029019304e-05,
      "loss": 2.8713,
      "step": 804
    },
    {
      "epoch": 5.22,
      "grad_norm": 0.2412109375,
      "learning_rate": 5.4514122221968013e-05,
      "loss": 2.7331,
      "step": 805
    },
    {
      "epoch": 5.23,
      "grad_norm": 0.2470703125,
      "learning_rate": 5.440156535576783e-05,
      "loss": 2.93,
      "step": 806
    },
    {
      "epoch": 5.23,
      "grad_norm": 0.2578125,
      "learning_rate": 5.4288986005384476e-05,
      "loss": 2.9818,
      "step": 807
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.24609375,
      "learning_rate": 5.4176384745898536e-05,
      "loss": 2.8804,
      "step": 808
    },
    {
      "epoch": 5.25,
      "grad_norm": 0.2490234375,
      "learning_rate": 5.406376215250246e-05,
      "loss": 2.8133,
      "step": 809
    },
    {
      "epoch": 5.25,
      "grad_norm": 0.244140625,
      "learning_rate": 5.3951118800497745e-05,
      "loss": 2.9217,
      "step": 810
    },
    {
      "epoch": 5.26,
      "grad_norm": 0.23046875,
      "learning_rate": 5.383845526529192e-05,
      "loss": 2.7861,
      "step": 811
    },
    {
      "epoch": 5.27,
      "grad_norm": 0.236328125,
      "learning_rate": 5.372577212239556e-05,
      "loss": 2.9047,
      "step": 812
    },
    {
      "epoch": 5.27,
      "grad_norm": 0.2431640625,
      "learning_rate": 5.361306994741945e-05,
      "loss": 2.8652,
      "step": 813
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.255859375,
      "learning_rate": 5.3500349316071585e-05,
      "loss": 2.9484,
      "step": 814
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.2333984375,
      "learning_rate": 5.338761080415424e-05,
      "loss": 2.9389,
      "step": 815
    },
    {
      "epoch": 5.29,
      "grad_norm": 0.2421875,
      "learning_rate": 5.327485498756101e-05,
      "loss": 2.8511,
      "step": 816
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.25390625,
      "learning_rate": 5.31620824422739e-05,
      "loss": 2.9644,
      "step": 817
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.287109375,
      "learning_rate": 5.3049293744360365e-05,
      "loss": 2.8432,
      "step": 818
    },
    {
      "epoch": 5.31,
      "grad_norm": 0.2470703125,
      "learning_rate": 5.29364894699704e-05,
      "loss": 2.8567,
      "step": 819
    },
    {
      "epoch": 5.32,
      "grad_norm": 0.244140625,
      "learning_rate": 5.2823670195333494e-05,
      "loss": 2.8629,
      "step": 820
    },
    {
      "epoch": 5.32,
      "grad_norm": 0.251953125,
      "learning_rate": 5.271083649675586e-05,
      "loss": 2.7768,
      "step": 821
    },
    {
      "epoch": 5.33,
      "grad_norm": 0.26953125,
      "learning_rate": 5.259798895061732e-05,
      "loss": 2.735,
      "step": 822
    },
    {
      "epoch": 5.34,
      "grad_norm": 0.25,
      "learning_rate": 5.2485128133368434e-05,
      "loss": 2.8147,
      "step": 823
    },
    {
      "epoch": 5.34,
      "grad_norm": 0.25,
      "learning_rate": 5.23722546215276e-05,
      "loss": 2.9185,
      "step": 824
    },
    {
      "epoch": 5.35,
      "grad_norm": 0.2451171875,
      "learning_rate": 5.225936899167803e-05,
      "loss": 2.7479,
      "step": 825
    },
    {
      "epoch": 5.36,
      "grad_norm": 0.2734375,
      "learning_rate": 5.214647182046484e-05,
      "loss": 2.6526,
      "step": 826
    },
    {
      "epoch": 5.36,
      "grad_norm": 0.2451171875,
      "learning_rate": 5.203356368459209e-05,
      "loss": 2.9678,
      "step": 827
    },
    {
      "epoch": 5.37,
      "grad_norm": 0.2412109375,
      "learning_rate": 5.192064516081988e-05,
      "loss": 2.7916,
      "step": 828
    },
    {
      "epoch": 5.38,
      "grad_norm": 0.251953125,
      "learning_rate": 5.1807716825961375e-05,
      "loss": 2.7177,
      "step": 829
    },
    {
      "epoch": 5.38,
      "grad_norm": 0.251953125,
      "learning_rate": 5.169477925687981e-05,
      "loss": 2.9096,
      "step": 830
    },
    {
      "epoch": 5.39,
      "grad_norm": 0.23828125,
      "learning_rate": 5.1581833030485636e-05,
      "loss": 2.6971,
      "step": 831
    },
    {
      "epoch": 5.39,
      "grad_norm": 0.248046875,
      "learning_rate": 5.146887872373353e-05,
      "loss": 2.747,
      "step": 832
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.2470703125,
      "learning_rate": 5.1355916913619404e-05,
      "loss": 2.8526,
      "step": 833
    },
    {
      "epoch": 5.41,
      "grad_norm": 0.2373046875,
      "learning_rate": 5.124294817717752e-05,
      "loss": 2.7584,
      "step": 834
    },
    {
      "epoch": 5.41,
      "grad_norm": 0.267578125,
      "learning_rate": 5.112997309147753e-05,
      "loss": 2.8588,
      "step": 835
    },
    {
      "epoch": 5.42,
      "grad_norm": 0.251953125,
      "learning_rate": 5.101699223362153e-05,
      "loss": 2.7038,
      "step": 836
    },
    {
      "epoch": 5.43,
      "grad_norm": 0.248046875,
      "learning_rate": 5.090400618074108e-05,
      "loss": 2.9771,
      "step": 837
    },
    {
      "epoch": 5.43,
      "grad_norm": 0.2470703125,
      "learning_rate": 5.0791015509994265e-05,
      "loss": 2.8251,
      "step": 838
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.2392578125,
      "learning_rate": 5.067802079856279e-05,
      "loss": 2.9497,
      "step": 839
    },
    {
      "epoch": 5.45,
      "grad_norm": 0.26171875,
      "learning_rate": 5.0565022623648995e-05,
      "loss": 2.7975,
      "step": 840
    },
    {
      "epoch": 5.45,
      "grad_norm": 0.259765625,
      "learning_rate": 5.0452021562472894e-05,
      "loss": 2.9197,
      "step": 841
    },
    {
      "epoch": 5.46,
      "grad_norm": 0.2470703125,
      "learning_rate": 5.033901819226924e-05,
      "loss": 2.9433,
      "step": 842
    },
    {
      "epoch": 5.47,
      "grad_norm": 0.232421875,
      "learning_rate": 5.022601309028462e-05,
      "loss": 2.7929,
      "step": 843
    },
    {
      "epoch": 5.47,
      "grad_norm": 0.25390625,
      "learning_rate": 5.0113006833774445e-05,
      "loss": 2.8595,
      "step": 844
    },
    {
      "epoch": 5.48,
      "grad_norm": 0.2431640625,
      "learning_rate": 5e-05,
      "loss": 2.6837,
      "step": 845
    },
    {
      "epoch": 5.49,
      "grad_norm": 0.24609375,
      "learning_rate": 4.9886993166225574e-05,
      "loss": 2.9072,
      "step": 846
    },
    {
      "epoch": 5.49,
      "grad_norm": 0.2412109375,
      "learning_rate": 4.9773986909715394e-05,
      "loss": 2.6976,
      "step": 847
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.255859375,
      "learning_rate": 4.966098180773078e-05,
      "loss": 3.0246,
      "step": 848
    },
    {
      "epoch": 5.51,
      "grad_norm": 0.2421875,
      "learning_rate": 4.954797843752712e-05,
      "loss": 2.7848,
      "step": 849
    },
    {
      "epoch": 5.51,
      "grad_norm": 0.2412109375,
      "learning_rate": 4.9434977376351023e-05,
      "loss": 2.6951,
      "step": 850
    },
    {
      "epoch": 5.52,
      "grad_norm": 0.23828125,
      "learning_rate": 4.932197920143721e-05,
      "loss": 2.8813,
      "step": 851
    },
    {
      "epoch": 5.52,
      "grad_norm": 0.251953125,
      "learning_rate": 4.920898449000575e-05,
      "loss": 2.8129,
      "step": 852
    },
    {
      "epoch": 5.53,
      "grad_norm": 0.25,
      "learning_rate": 4.909599381925892e-05,
      "loss": 2.8558,
      "step": 853
    },
    {
      "epoch": 5.54,
      "grad_norm": 0.267578125,
      "learning_rate": 4.898300776637848e-05,
      "loss": 2.8922,
      "step": 854
    },
    {
      "epoch": 5.54,
      "grad_norm": 0.2431640625,
      "learning_rate": 4.887002690852249e-05,
      "loss": 2.9645,
      "step": 855
    },
    {
      "epoch": 5.55,
      "grad_norm": 0.28125,
      "learning_rate": 4.875705182282249e-05,
      "loss": 2.7613,
      "step": 856
    },
    {
      "epoch": 5.56,
      "grad_norm": 0.2578125,
      "learning_rate": 4.864408308638062e-05,
      "loss": 2.9411,
      "step": 857
    },
    {
      "epoch": 5.56,
      "grad_norm": 0.2412109375,
      "learning_rate": 4.853112127626648e-05,
      "loss": 2.9555,
      "step": 858
    },
    {
      "epoch": 5.57,
      "grad_norm": 0.251953125,
      "learning_rate": 4.841816696951437e-05,
      "loss": 2.7901,
      "step": 859
    },
    {
      "epoch": 5.58,
      "grad_norm": 0.2392578125,
      "learning_rate": 4.8305220743120186e-05,
      "loss": 2.8036,
      "step": 860
    },
    {
      "epoch": 5.58,
      "grad_norm": 0.248046875,
      "learning_rate": 4.8192283174038636e-05,
      "loss": 2.7369,
      "step": 861
    },
    {
      "epoch": 5.59,
      "grad_norm": 0.275390625,
      "learning_rate": 4.807935483918013e-05,
      "loss": 3.0061,
      "step": 862
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.2451171875,
      "learning_rate": 4.7966436315407924e-05,
      "loss": 2.8441,
      "step": 863
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.267578125,
      "learning_rate": 4.785352817953519e-05,
      "loss": 2.8804,
      "step": 864
    },
    {
      "epoch": 5.61,
      "grad_norm": 0.26171875,
      "learning_rate": 4.774063100832199e-05,
      "loss": 2.896,
      "step": 865
    },
    {
      "epoch": 5.62,
      "grad_norm": 0.25390625,
      "learning_rate": 4.762774537847242e-05,
      "loss": 2.8668,
      "step": 866
    },
    {
      "epoch": 5.62,
      "grad_norm": 0.2578125,
      "learning_rate": 4.751487186663157e-05,
      "loss": 2.6957,
      "step": 867
    },
    {
      "epoch": 5.63,
      "grad_norm": 0.26171875,
      "learning_rate": 4.74020110493827e-05,
      "loss": 2.898,
      "step": 868
    },
    {
      "epoch": 5.63,
      "grad_norm": 0.2490234375,
      "learning_rate": 4.728916350324415e-05,
      "loss": 2.9712,
      "step": 869
    },
    {
      "epoch": 5.64,
      "grad_norm": 0.255859375,
      "learning_rate": 4.717632980466651e-05,
      "loss": 2.9901,
      "step": 870
    },
    {
      "epoch": 5.65,
      "grad_norm": 0.25,
      "learning_rate": 4.706351053002963e-05,
      "loss": 2.9244,
      "step": 871
    },
    {
      "epoch": 5.65,
      "grad_norm": 0.2578125,
      "learning_rate": 4.695070625563965e-05,
      "loss": 2.8001,
      "step": 872
    },
    {
      "epoch": 5.66,
      "grad_norm": 0.2490234375,
      "learning_rate": 4.683791755772612e-05,
      "loss": 2.9105,
      "step": 873
    },
    {
      "epoch": 5.67,
      "grad_norm": 0.26953125,
      "learning_rate": 4.6725145012439e-05,
      "loss": 2.945,
      "step": 874
    },
    {
      "epoch": 5.67,
      "grad_norm": 0.248046875,
      "learning_rate": 4.661238919584577e-05,
      "loss": 2.8565,
      "step": 875
    },
    {
      "epoch": 5.68,
      "grad_norm": 0.248046875,
      "learning_rate": 4.649965068392842e-05,
      "loss": 2.7454,
      "step": 876
    },
    {
      "epoch": 5.69,
      "grad_norm": 0.25390625,
      "learning_rate": 4.638693005258056e-05,
      "loss": 2.8909,
      "step": 877
    },
    {
      "epoch": 5.69,
      "grad_norm": 0.2412109375,
      "learning_rate": 4.6274227877604445e-05,
      "loss": 2.8159,
      "step": 878
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.24609375,
      "learning_rate": 4.6161544734708086e-05,
      "loss": 2.9153,
      "step": 879
    },
    {
      "epoch": 5.71,
      "grad_norm": 0.25390625,
      "learning_rate": 4.6048881199502267e-05,
      "loss": 2.9615,
      "step": 880
    },
    {
      "epoch": 5.71,
      "grad_norm": 0.23828125,
      "learning_rate": 4.593623784749755e-05,
      "loss": 2.8994,
      "step": 881
    },
    {
      "epoch": 5.72,
      "grad_norm": 0.255859375,
      "learning_rate": 4.5823615254101496e-05,
      "loss": 2.7923,
      "step": 882
    },
    {
      "epoch": 5.73,
      "grad_norm": 0.248046875,
      "learning_rate": 4.571101399461553e-05,
      "loss": 2.9039,
      "step": 883
    },
    {
      "epoch": 5.73,
      "grad_norm": 0.236328125,
      "learning_rate": 4.559843464423218e-05,
      "loss": 2.8193,
      "step": 884
    },
    {
      "epoch": 5.74,
      "grad_norm": 0.255859375,
      "learning_rate": 4.5485877778031985e-05,
      "loss": 2.9244,
      "step": 885
    },
    {
      "epoch": 5.75,
      "grad_norm": 0.2392578125,
      "learning_rate": 4.537334397098071e-05,
      "loss": 2.8806,
      "step": 886
    },
    {
      "epoch": 5.75,
      "grad_norm": 0.240234375,
      "learning_rate": 4.5260833797926255e-05,
      "loss": 2.6679,
      "step": 887
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.25,
      "learning_rate": 4.5148347833595825e-05,
      "loss": 2.8962,
      "step": 888
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.248046875,
      "learning_rate": 4.5035886652592965e-05,
      "loss": 2.8049,
      "step": 889
    },
    {
      "epoch": 5.77,
      "grad_norm": 0.255859375,
      "learning_rate": 4.4923450829394605e-05,
      "loss": 2.8315,
      "step": 890
    },
    {
      "epoch": 5.78,
      "grad_norm": 0.2470703125,
      "learning_rate": 4.4811040938348165e-05,
      "loss": 2.946,
      "step": 891
    },
    {
      "epoch": 5.78,
      "grad_norm": 0.2412109375,
      "learning_rate": 4.4698657553668556e-05,
      "loss": 2.8884,
      "step": 892
    },
    {
      "epoch": 5.79,
      "grad_norm": 0.265625,
      "learning_rate": 4.458630124943535e-05,
      "loss": 2.8673,
      "step": 893
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.2412109375,
      "learning_rate": 4.447397259958974e-05,
      "loss": 2.8349,
      "step": 894
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.2470703125,
      "learning_rate": 4.436167217793166e-05,
      "loss": 2.8664,
      "step": 895
    },
    {
      "epoch": 5.81,
      "grad_norm": 0.244140625,
      "learning_rate": 4.424940055811687e-05,
      "loss": 2.8035,
      "step": 896
    },
    {
      "epoch": 5.82,
      "grad_norm": 0.26171875,
      "learning_rate": 4.413715831365395e-05,
      "loss": 2.9294,
      "step": 897
    },
    {
      "epoch": 5.82,
      "grad_norm": 0.240234375,
      "learning_rate": 4.402494601790151e-05,
      "loss": 2.8042,
      "step": 898
    },
    {
      "epoch": 5.83,
      "grad_norm": 0.236328125,
      "learning_rate": 4.39127642440651e-05,
      "loss": 2.7855,
      "step": 899
    },
    {
      "epoch": 5.84,
      "grad_norm": 0.2578125,
      "learning_rate": 4.380061356519441e-05,
      "loss": 2.9226,
      "step": 900
    },
    {
      "epoch": 5.84,
      "grad_norm": 0.2734375,
      "learning_rate": 4.368849455418022e-05,
      "loss": 3.072,
      "step": 901
    },
    {
      "epoch": 5.85,
      "grad_norm": 0.267578125,
      "learning_rate": 4.3576407783751635e-05,
      "loss": 2.9901,
      "step": 902
    },
    {
      "epoch": 5.86,
      "grad_norm": 0.2412109375,
      "learning_rate": 4.346435382647297e-05,
      "loss": 2.7185,
      "step": 903
    },
    {
      "epoch": 5.86,
      "grad_norm": 0.251953125,
      "learning_rate": 4.335233325474104e-05,
      "loss": 2.9604,
      "step": 904
    },
    {
      "epoch": 5.87,
      "grad_norm": 0.251953125,
      "learning_rate": 4.3240346640782016e-05,
      "loss": 2.8994,
      "step": 905
    },
    {
      "epoch": 5.87,
      "grad_norm": 0.251953125,
      "learning_rate": 4.3128394556648635e-05,
      "loss": 2.8431,
      "step": 906
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.2431640625,
      "learning_rate": 4.301647757421727e-05,
      "loss": 2.8825,
      "step": 907
    },
    {
      "epoch": 5.89,
      "grad_norm": 0.2421875,
      "learning_rate": 4.290459626518495e-05,
      "loss": 2.8507,
      "step": 908
    },
    {
      "epoch": 5.89,
      "grad_norm": 0.255859375,
      "learning_rate": 4.279275120106654e-05,
      "loss": 2.8798,
      "step": 909
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.25390625,
      "learning_rate": 4.268094295319167e-05,
      "loss": 2.7039,
      "step": 910
    },
    {
      "epoch": 5.91,
      "grad_norm": 0.236328125,
      "learning_rate": 4.2569172092701985e-05,
      "loss": 2.7809,
      "step": 911
    },
    {
      "epoch": 5.91,
      "grad_norm": 0.236328125,
      "learning_rate": 4.245743919054811e-05,
      "loss": 2.8045,
      "step": 912
    },
    {
      "epoch": 5.92,
      "grad_norm": 0.2451171875,
      "learning_rate": 4.234574481748674e-05,
      "loss": 2.9026,
      "step": 913
    },
    {
      "epoch": 5.93,
      "grad_norm": 0.23046875,
      "learning_rate": 4.223408954407782e-05,
      "loss": 2.6912,
      "step": 914
    },
    {
      "epoch": 5.93,
      "grad_norm": 0.2451171875,
      "learning_rate": 4.2122473940681514e-05,
      "loss": 2.808,
      "step": 915
    },
    {
      "epoch": 5.94,
      "grad_norm": 0.318359375,
      "learning_rate": 4.201089857745539e-05,
      "loss": 2.8765,
      "step": 916
    },
    {
      "epoch": 5.95,
      "grad_norm": 0.2490234375,
      "learning_rate": 4.1899364024351386e-05,
      "loss": 2.8019,
      "step": 917
    },
    {
      "epoch": 5.95,
      "grad_norm": 0.2333984375,
      "learning_rate": 4.178787085111306e-05,
      "loss": 2.7941,
      "step": 918
    },
    {
      "epoch": 5.96,
      "grad_norm": 0.25390625,
      "learning_rate": 4.1676419627272524e-05,
      "loss": 2.8539,
      "step": 919
    },
    {
      "epoch": 5.97,
      "grad_norm": 0.2578125,
      "learning_rate": 4.1565010922147646e-05,
      "loss": 2.8092,
      "step": 920
    },
    {
      "epoch": 5.97,
      "grad_norm": 0.2451171875,
      "learning_rate": 4.1453645304839076e-05,
      "loss": 2.8502,
      "step": 921
    },
    {
      "epoch": 5.98,
      "grad_norm": 0.236328125,
      "learning_rate": 4.1342323344227354e-05,
      "loss": 2.9005,
      "step": 922
    },
    {
      "epoch": 5.99,
      "grad_norm": 0.25,
      "learning_rate": 4.123104560897005e-05,
      "loss": 2.8322,
      "step": 923
    },
    {
      "epoch": 5.99,
      "grad_norm": 0.2412109375,
      "learning_rate": 4.111981266749878e-05,
      "loss": 2.9509,
      "step": 924
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.263671875,
      "learning_rate": 4.100862508801639e-05,
      "loss": 2.7039,
      "step": 925
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.244140625,
      "learning_rate": 4.089748343849392e-05,
      "loss": 2.8282,
      "step": 926
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.259765625,
      "learning_rate": 4.0786388286667906e-05,
      "loss": 2.7794,
      "step": 927
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.271484375,
      "learning_rate": 4.0675340200037255e-05,
      "loss": 2.91,
      "step": 928
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.2412109375,
      "learning_rate": 4.056433974586055e-05,
      "loss": 2.794,
      "step": 929
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.267578125,
      "learning_rate": 4.045338749115298e-05,
      "loss": 2.7983,
      "step": 930
    },
    {
      "epoch": 6.04,
      "grad_norm": 0.24609375,
      "learning_rate": 4.0342484002683555e-05,
      "loss": 2.8895,
      "step": 931
    },
    {
      "epoch": 6.04,
      "grad_norm": 0.2490234375,
      "learning_rate": 4.023162984697218e-05,
      "loss": 2.8974,
      "step": 932
    },
    {
      "epoch": 6.05,
      "grad_norm": 0.2578125,
      "learning_rate": 4.012082559028672e-05,
      "loss": 2.7114,
      "step": 933
    },
    {
      "epoch": 6.06,
      "grad_norm": 0.25,
      "learning_rate": 4.001007179864023e-05,
      "loss": 2.9226,
      "step": 934
    },
    {
      "epoch": 6.06,
      "grad_norm": 0.2451171875,
      "learning_rate": 3.9899369037787856e-05,
      "loss": 2.8734,
      "step": 935
    },
    {
      "epoch": 6.07,
      "grad_norm": 0.25,
      "learning_rate": 3.978871787322418e-05,
      "loss": 2.8207,
      "step": 936
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.2412109375,
      "learning_rate": 3.967811887018015e-05,
      "loss": 2.7673,
      "step": 937
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.240234375,
      "learning_rate": 3.9567572593620294e-05,
      "loss": 2.8823,
      "step": 938
    },
    {
      "epoch": 6.09,
      "grad_norm": 0.251953125,
      "learning_rate": 3.945707960823979e-05,
      "loss": 2.9125,
      "step": 939
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.275390625,
      "learning_rate": 3.934664047846156e-05,
      "loss": 2.7618,
      "step": 940
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.259765625,
      "learning_rate": 3.92362557684335e-05,
      "loss": 2.8961,
      "step": 941
    },
    {
      "epoch": 6.11,
      "grad_norm": 0.244140625,
      "learning_rate": 3.912592604202544e-05,
      "loss": 2.93,
      "step": 942
    },
    {
      "epoch": 6.11,
      "grad_norm": 0.271484375,
      "learning_rate": 3.9015651862826384e-05,
      "loss": 2.9123,
      "step": 943
    },
    {
      "epoch": 6.12,
      "grad_norm": 0.251953125,
      "learning_rate": 3.8905433794141566e-05,
      "loss": 2.835,
      "step": 944
    },
    {
      "epoch": 6.13,
      "grad_norm": 0.2421875,
      "learning_rate": 3.879527239898962e-05,
      "loss": 2.8292,
      "step": 945
    },
    {
      "epoch": 6.13,
      "grad_norm": 0.23828125,
      "learning_rate": 3.8685168240099654e-05,
      "loss": 2.7956,
      "step": 946
    },
    {
      "epoch": 6.14,
      "grad_norm": 0.2431640625,
      "learning_rate": 3.857512187990838e-05,
      "loss": 2.825,
      "step": 947
    },
    {
      "epoch": 6.15,
      "grad_norm": 0.26171875,
      "learning_rate": 3.846513388055735e-05,
      "loss": 2.7678,
      "step": 948
    },
    {
      "epoch": 6.15,
      "grad_norm": 0.2490234375,
      "learning_rate": 3.8355204803889886e-05,
      "loss": 2.8366,
      "step": 949
    },
    {
      "epoch": 6.16,
      "grad_norm": 0.2490234375,
      "learning_rate": 3.82453352114484e-05,
      "loss": 2.8476,
      "step": 950
    },
    {
      "epoch": 6.17,
      "grad_norm": 0.259765625,
      "learning_rate": 3.81355256644714e-05,
      "loss": 2.7458,
      "step": 951
    },
    {
      "epoch": 6.17,
      "grad_norm": 0.2412109375,
      "learning_rate": 3.8025776723890707e-05,
      "loss": 2.9211,
      "step": 952
    },
    {
      "epoch": 6.18,
      "grad_norm": 0.25,
      "learning_rate": 3.791608895032848e-05,
      "loss": 2.8076,
      "step": 953
    },
    {
      "epoch": 6.19,
      "grad_norm": 0.2734375,
      "learning_rate": 3.780646290409453e-05,
      "loss": 2.8565,
      "step": 954
    },
    {
      "epoch": 6.19,
      "grad_norm": 0.25,
      "learning_rate": 3.7696899145183255e-05,
      "loss": 2.7352,
      "step": 955
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.2470703125,
      "learning_rate": 3.758739823327092e-05,
      "loss": 2.7807,
      "step": 956
    },
    {
      "epoch": 6.21,
      "grad_norm": 0.2578125,
      "learning_rate": 3.747796072771275e-05,
      "loss": 2.8506,
      "step": 957
    },
    {
      "epoch": 6.21,
      "grad_norm": 0.240234375,
      "learning_rate": 3.736858718754005e-05,
      "loss": 2.8021,
      "step": 958
    },
    {
      "epoch": 6.22,
      "grad_norm": 0.24609375,
      "learning_rate": 3.725927817145744e-05,
      "loss": 2.8074,
      "step": 959
    },
    {
      "epoch": 6.22,
      "grad_norm": 0.248046875,
      "learning_rate": 3.715003423783986e-05,
      "loss": 2.7228,
      "step": 960
    },
    {
      "epoch": 6.23,
      "grad_norm": 0.25,
      "learning_rate": 3.7040855944729846e-05,
      "loss": 2.8937,
      "step": 961
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.244140625,
      "learning_rate": 3.693174384983459e-05,
      "loss": 2.8179,
      "step": 962
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.251953125,
      "learning_rate": 3.682269851052317e-05,
      "loss": 2.8481,
      "step": 963
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.251953125,
      "learning_rate": 3.6713720483823636e-05,
      "loss": 2.7495,
      "step": 964
    },
    {
      "epoch": 6.26,
      "grad_norm": 0.25,
      "learning_rate": 3.660481032642016e-05,
      "loss": 2.7207,
      "step": 965
    },
    {
      "epoch": 6.26,
      "grad_norm": 0.251953125,
      "learning_rate": 3.649596859465031e-05,
      "loss": 2.9907,
      "step": 966
    },
    {
      "epoch": 6.27,
      "grad_norm": 0.2470703125,
      "learning_rate": 3.638719584450202e-05,
      "loss": 2.8635,
      "step": 967
    },
    {
      "epoch": 6.28,
      "grad_norm": 0.2412109375,
      "learning_rate": 3.627849263161094e-05,
      "loss": 2.7348,
      "step": 968
    },
    {
      "epoch": 6.28,
      "grad_norm": 0.248046875,
      "learning_rate": 3.6169859511257413e-05,
      "loss": 2.8264,
      "step": 969
    },
    {
      "epoch": 6.29,
      "grad_norm": 0.2421875,
      "learning_rate": 3.606129703836385e-05,
      "loss": 2.9102,
      "step": 970
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.2490234375,
      "learning_rate": 3.5952805767491674e-05,
      "loss": 2.8655,
      "step": 971
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.24609375,
      "learning_rate": 3.584438625283861e-05,
      "loss": 2.6933,
      "step": 972
    },
    {
      "epoch": 6.31,
      "grad_norm": 0.2451171875,
      "learning_rate": 3.5736039048235916e-05,
      "loss": 2.7968,
      "step": 973
    },
    {
      "epoch": 6.32,
      "grad_norm": 0.267578125,
      "learning_rate": 3.562776470714538e-05,
      "loss": 2.8321,
      "step": 974
    },
    {
      "epoch": 6.32,
      "grad_norm": 0.291015625,
      "learning_rate": 3.551956378265664e-05,
      "loss": 2.9169,
      "step": 975
    },
    {
      "epoch": 6.33,
      "grad_norm": 0.271484375,
      "learning_rate": 3.541143682748426e-05,
      "loss": 2.8194,
      "step": 976
    },
    {
      "epoch": 6.34,
      "grad_norm": 0.259765625,
      "learning_rate": 3.530338439396503e-05,
      "loss": 2.7959,
      "step": 977
    },
    {
      "epoch": 6.34,
      "grad_norm": 0.2421875,
      "learning_rate": 3.5195407034054984e-05,
      "loss": 2.6937,
      "step": 978
    },
    {
      "epoch": 6.35,
      "grad_norm": 0.25390625,
      "learning_rate": 3.5087505299326705e-05,
      "loss": 2.7383,
      "step": 979
    },
    {
      "epoch": 6.35,
      "grad_norm": 0.2578125,
      "learning_rate": 3.497967974096647e-05,
      "loss": 2.9906,
      "step": 980
    },
    {
      "epoch": 6.36,
      "grad_norm": 0.25390625,
      "learning_rate": 3.487193090977139e-05,
      "loss": 2.9469,
      "step": 981
    },
    {
      "epoch": 6.37,
      "grad_norm": 0.27734375,
      "learning_rate": 3.47642593561467e-05,
      "loss": 2.8105,
      "step": 982
    },
    {
      "epoch": 6.37,
      "grad_norm": 0.2392578125,
      "learning_rate": 3.46566656301028e-05,
      "loss": 2.7239,
      "step": 983
    },
    {
      "epoch": 6.38,
      "grad_norm": 0.2451171875,
      "learning_rate": 3.4549150281252636e-05,
      "loss": 2.8864,
      "step": 984
    },
    {
      "epoch": 6.39,
      "grad_norm": 0.267578125,
      "learning_rate": 3.4441713858808685e-05,
      "loss": 2.8361,
      "step": 985
    },
    {
      "epoch": 6.39,
      "grad_norm": 0.263671875,
      "learning_rate": 3.4334356911580315e-05,
      "loss": 2.8858,
      "step": 986
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.2578125,
      "learning_rate": 3.422707998797086e-05,
      "loss": 2.8874,
      "step": 987
    },
    {
      "epoch": 6.41,
      "grad_norm": 0.2490234375,
      "learning_rate": 3.411988363597497e-05,
      "loss": 2.7442,
      "step": 988
    },
    {
      "epoch": 6.41,
      "grad_norm": 0.255859375,
      "learning_rate": 3.4012768403175614e-05,
      "loss": 2.8765,
      "step": 989
    },
    {
      "epoch": 6.42,
      "grad_norm": 0.25390625,
      "learning_rate": 3.390573483674142e-05,
      "loss": 2.9004,
      "step": 990
    },
    {
      "epoch": 6.43,
      "grad_norm": 0.251953125,
      "learning_rate": 3.379878348342388e-05,
      "loss": 2.9416,
      "step": 991
    },
    {
      "epoch": 6.43,
      "grad_norm": 0.255859375,
      "learning_rate": 3.369191488955449e-05,
      "loss": 2.6758,
      "step": 992
    },
    {
      "epoch": 6.44,
      "grad_norm": 0.283203125,
      "learning_rate": 3.3585129601042e-05,
      "loss": 2.9453,
      "step": 993
    },
    {
      "epoch": 6.45,
      "grad_norm": 0.251953125,
      "learning_rate": 3.3478428163369594e-05,
      "loss": 2.9615,
      "step": 994
    },
    {
      "epoch": 6.45,
      "grad_norm": 0.296875,
      "learning_rate": 3.33718111215922e-05,
      "loss": 2.8736,
      "step": 995
    },
    {
      "epoch": 6.46,
      "grad_norm": 0.248046875,
      "learning_rate": 3.326527902033356e-05,
      "loss": 2.8506,
      "step": 996
    },
    {
      "epoch": 6.46,
      "grad_norm": 0.265625,
      "learning_rate": 3.315883240378351e-05,
      "loss": 2.8693,
      "step": 997
    },
    {
      "epoch": 6.47,
      "grad_norm": 0.251953125,
      "learning_rate": 3.30524718156953e-05,
      "loss": 2.8813,
      "step": 998
    },
    {
      "epoch": 6.48,
      "grad_norm": 0.25,
      "learning_rate": 3.2946197799382626e-05,
      "loss": 2.8492,
      "step": 999
    },
    {
      "epoch": 6.48,
      "grad_norm": 0.255859375,
      "learning_rate": 3.2840010897717045e-05,
      "loss": 2.8973,
      "step": 1000
    },
    {
      "epoch": 6.49,
      "grad_norm": 0.267578125,
      "learning_rate": 3.273391165312502e-05,
      "loss": 2.8121,
      "step": 1001
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.25,
      "learning_rate": 3.2627900607585345e-05,
      "loss": 2.7747,
      "step": 1002
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.2490234375,
      "learning_rate": 3.252197830262618e-05,
      "loss": 2.8814,
      "step": 1003
    },
    {
      "epoch": 6.51,
      "grad_norm": 0.275390625,
      "learning_rate": 3.241614527932245e-05,
      "loss": 2.9145,
      "step": 1004
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.248046875,
      "learning_rate": 3.2310402078292956e-05,
      "loss": 2.8736,
      "step": 1005
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.2578125,
      "learning_rate": 3.220474923969769e-05,
      "loss": 2.7544,
      "step": 1006
    },
    {
      "epoch": 6.53,
      "grad_norm": 0.263671875,
      "learning_rate": 3.209918730323507e-05,
      "loss": 2.8268,
      "step": 1007
    },
    {
      "epoch": 6.54,
      "grad_norm": 0.24609375,
      "learning_rate": 3.19937168081391e-05,
      "loss": 2.9048,
      "step": 1008
    },
    {
      "epoch": 6.54,
      "grad_norm": 0.2470703125,
      "learning_rate": 3.188833829317679e-05,
      "loss": 2.7499,
      "step": 1009
    },
    {
      "epoch": 6.55,
      "grad_norm": 0.248046875,
      "learning_rate": 3.178305229664519e-05,
      "loss": 2.9134,
      "step": 1010
    },
    {
      "epoch": 6.56,
      "grad_norm": 0.248046875,
      "learning_rate": 3.167785935636881e-05,
      "loss": 2.9325,
      "step": 1011
    },
    {
      "epoch": 6.56,
      "grad_norm": 0.255859375,
      "learning_rate": 3.157276000969675e-05,
      "loss": 2.8222,
      "step": 1012
    },
    {
      "epoch": 6.57,
      "grad_norm": 0.25390625,
      "learning_rate": 3.1467754793500104e-05,
      "loss": 2.9379,
      "step": 1013
    },
    {
      "epoch": 6.58,
      "grad_norm": 0.384765625,
      "learning_rate": 3.136284424416904e-05,
      "loss": 2.7516,
      "step": 1014
    },
    {
      "epoch": 6.58,
      "grad_norm": 0.259765625,
      "learning_rate": 3.125802889761016e-05,
      "loss": 3.1101,
      "step": 1015
    },
    {
      "epoch": 6.59,
      "grad_norm": 0.240234375,
      "learning_rate": 3.115330928924379e-05,
      "loss": 2.8436,
      "step": 1016
    },
    {
      "epoch": 6.59,
      "grad_norm": 0.25390625,
      "learning_rate": 3.104868595400117e-05,
      "loss": 2.8506,
      "step": 1017
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.25390625,
      "learning_rate": 3.094415942632178e-05,
      "loss": 2.7165,
      "step": 1018
    },
    {
      "epoch": 6.61,
      "grad_norm": 0.26171875,
      "learning_rate": 3.0839730240150535e-05,
      "loss": 2.8749,
      "step": 1019
    },
    {
      "epoch": 6.61,
      "grad_norm": 0.265625,
      "learning_rate": 3.073539892893519e-05,
      "loss": 2.9065,
      "step": 1020
    },
    {
      "epoch": 6.62,
      "grad_norm": 0.2470703125,
      "learning_rate": 3.063116602562346e-05,
      "loss": 2.8329,
      "step": 1021
    },
    {
      "epoch": 6.63,
      "grad_norm": 0.2421875,
      "learning_rate": 3.052703206266039e-05,
      "loss": 2.8275,
      "step": 1022
    },
    {
      "epoch": 6.63,
      "grad_norm": 0.2412109375,
      "learning_rate": 3.0422997571985633e-05,
      "loss": 2.8251,
      "step": 1023
    },
    {
      "epoch": 6.64,
      "grad_norm": 0.25390625,
      "learning_rate": 3.0319063085030698e-05,
      "loss": 2.8873,
      "step": 1024
    },
    {
      "epoch": 6.65,
      "grad_norm": 0.251953125,
      "learning_rate": 3.021522913271627e-05,
      "loss": 2.8314,
      "step": 1025
    },
    {
      "epoch": 6.65,
      "grad_norm": 0.2578125,
      "learning_rate": 3.0111496245449444e-05,
      "loss": 2.9029,
      "step": 1026
    },
    {
      "epoch": 6.66,
      "grad_norm": 0.26171875,
      "learning_rate": 3.0007864953121106e-05,
      "loss": 2.8321,
      "step": 1027
    },
    {
      "epoch": 6.67,
      "grad_norm": 0.263671875,
      "learning_rate": 2.9904335785103123e-05,
      "loss": 2.8182,
      "step": 1028
    },
    {
      "epoch": 6.67,
      "grad_norm": 0.251953125,
      "learning_rate": 2.980090927024573e-05,
      "loss": 2.8761,
      "step": 1029
    },
    {
      "epoch": 6.68,
      "grad_norm": 0.248046875,
      "learning_rate": 2.969758593687475e-05,
      "loss": 2.905,
      "step": 1030
    },
    {
      "epoch": 6.69,
      "grad_norm": 0.322265625,
      "learning_rate": 2.9594366312788924e-05,
      "loss": 2.8138,
      "step": 1031
    },
    {
      "epoch": 6.69,
      "grad_norm": 0.240234375,
      "learning_rate": 2.9491250925257307e-05,
      "loss": 2.8252,
      "step": 1032
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.24609375,
      "learning_rate": 2.9388240301016357e-05,
      "loss": 2.8738,
      "step": 1033
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.267578125,
      "learning_rate": 2.9285334966267504e-05,
      "loss": 2.8176,
      "step": 1034
    },
    {
      "epoch": 6.71,
      "grad_norm": 0.255859375,
      "learning_rate": 2.9182535446674242e-05,
      "loss": 2.8685,
      "step": 1035
    },
    {
      "epoch": 6.72,
      "grad_norm": 0.259765625,
      "learning_rate": 2.9079842267359615e-05,
      "loss": 2.8805,
      "step": 1036
    },
    {
      "epoch": 6.72,
      "grad_norm": 0.259765625,
      "learning_rate": 2.8977255952903397e-05,
      "loss": 2.8891,
      "step": 1037
    },
    {
      "epoch": 6.73,
      "grad_norm": 0.251953125,
      "learning_rate": 2.8874777027339507e-05,
      "loss": 2.9032,
      "step": 1038
    },
    {
      "epoch": 6.74,
      "grad_norm": 0.25390625,
      "learning_rate": 2.8772406014153262e-05,
      "loss": 2.7876,
      "step": 1039
    },
    {
      "epoch": 6.74,
      "grad_norm": 0.30859375,
      "learning_rate": 2.8670143436278756e-05,
      "loss": 2.8318,
      "step": 1040
    },
    {
      "epoch": 6.75,
      "grad_norm": 0.251953125,
      "learning_rate": 2.8567989816096212e-05,
      "loss": 2.9721,
      "step": 1041
    },
    {
      "epoch": 6.76,
      "grad_norm": 0.259765625,
      "learning_rate": 2.8465945675429196e-05,
      "loss": 2.8843,
      "step": 1042
    },
    {
      "epoch": 6.76,
      "grad_norm": 0.236328125,
      "learning_rate": 2.8364011535542112e-05,
      "loss": 2.8035,
      "step": 1043
    },
    {
      "epoch": 6.77,
      "grad_norm": 0.267578125,
      "learning_rate": 2.8262187917137388e-05,
      "loss": 2.9208,
      "step": 1044
    },
    {
      "epoch": 6.78,
      "grad_norm": 0.2490234375,
      "learning_rate": 2.816047534035291e-05,
      "loss": 2.9383,
      "step": 1045
    },
    {
      "epoch": 6.78,
      "grad_norm": 0.267578125,
      "learning_rate": 2.8058874324759332e-05,
      "loss": 2.9595,
      "step": 1046
    },
    {
      "epoch": 6.79,
      "grad_norm": 0.2734375,
      "learning_rate": 2.795738538935742e-05,
      "loss": 3.0865,
      "step": 1047
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.26953125,
      "learning_rate": 2.7856009052575454e-05,
      "loss": 2.8305,
      "step": 1048
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.251953125,
      "learning_rate": 2.7754745832266466e-05,
      "loss": 2.9377,
      "step": 1049
    },
    {
      "epoch": 6.81,
      "grad_norm": 0.2451171875,
      "learning_rate": 2.7653596245705736e-05,
      "loss": 3.0293,
      "step": 1050
    },
    {
      "epoch": 6.81,
      "grad_norm": 0.265625,
      "learning_rate": 2.7552560809588028e-05,
      "loss": 2.8669,
      "step": 1051
    },
    {
      "epoch": 6.82,
      "grad_norm": 0.26171875,
      "learning_rate": 2.7451640040025013e-05,
      "loss": 2.8404,
      "step": 1052
    },
    {
      "epoch": 6.83,
      "grad_norm": 0.271484375,
      "learning_rate": 2.7350834452542594e-05,
      "loss": 2.7769,
      "step": 1053
    },
    {
      "epoch": 6.83,
      "grad_norm": 0.25390625,
      "learning_rate": 2.725014456207836e-05,
      "loss": 2.9292,
      "step": 1054
    },
    {
      "epoch": 6.84,
      "grad_norm": 0.2392578125,
      "learning_rate": 2.714957088297886e-05,
      "loss": 2.6734,
      "step": 1055
    },
    {
      "epoch": 6.85,
      "grad_norm": 0.28515625,
      "learning_rate": 2.704911392899696e-05,
      "loss": 2.8267,
      "step": 1056
    },
    {
      "epoch": 6.85,
      "grad_norm": 0.244140625,
      "learning_rate": 2.6948774213289375e-05,
      "loss": 2.8947,
      "step": 1057
    },
    {
      "epoch": 6.86,
      "grad_norm": 0.25,
      "learning_rate": 2.6848552248413833e-05,
      "loss": 2.987,
      "step": 1058
    },
    {
      "epoch": 6.87,
      "grad_norm": 0.25390625,
      "learning_rate": 2.6748448546326667e-05,
      "loss": 2.9902,
      "step": 1059
    },
    {
      "epoch": 6.87,
      "grad_norm": 0.255859375,
      "learning_rate": 2.664846361837997e-05,
      "loss": 2.9757,
      "step": 1060
    },
    {
      "epoch": 6.88,
      "grad_norm": 0.251953125,
      "learning_rate": 2.654859797531924e-05,
      "loss": 2.8732,
      "step": 1061
    },
    {
      "epoch": 6.89,
      "grad_norm": 0.27734375,
      "learning_rate": 2.6448852127280543e-05,
      "loss": 2.7973,
      "step": 1062
    },
    {
      "epoch": 6.89,
      "grad_norm": 0.251953125,
      "learning_rate": 2.6349226583788077e-05,
      "loss": 2.8798,
      "step": 1063
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.25,
      "learning_rate": 2.6249721853751465e-05,
      "loss": 2.9013,
      "step": 1064
    },
    {
      "epoch": 6.91,
      "grad_norm": 0.251953125,
      "learning_rate": 2.6150338445463145e-05,
      "loss": 2.8685,
      "step": 1065
    },
    {
      "epoch": 6.91,
      "grad_norm": 0.25390625,
      "learning_rate": 2.6051076866595915e-05,
      "loss": 2.8574,
      "step": 1066
    },
    {
      "epoch": 6.92,
      "grad_norm": 0.2421875,
      "learning_rate": 2.5951937624200164e-05,
      "loss": 2.8347,
      "step": 1067
    },
    {
      "epoch": 6.93,
      "grad_norm": 0.25390625,
      "learning_rate": 2.5852921224701376e-05,
      "loss": 2.9118,
      "step": 1068
    },
    {
      "epoch": 6.93,
      "grad_norm": 0.25390625,
      "learning_rate": 2.5754028173897522e-05,
      "loss": 2.82,
      "step": 1069
    },
    {
      "epoch": 6.94,
      "grad_norm": 0.27734375,
      "learning_rate": 2.565525897695651e-05,
      "loss": 2.8314,
      "step": 1070
    },
    {
      "epoch": 6.94,
      "grad_norm": 0.26953125,
      "learning_rate": 2.5556614138413525e-05,
      "loss": 2.7757,
      "step": 1071
    },
    {
      "epoch": 6.95,
      "grad_norm": 0.255859375,
      "learning_rate": 2.5458094162168577e-05,
      "loss": 2.9139,
      "step": 1072
    },
    {
      "epoch": 6.96,
      "grad_norm": 0.267578125,
      "learning_rate": 2.5359699551483766e-05,
      "loss": 2.8283,
      "step": 1073
    },
    {
      "epoch": 6.96,
      "grad_norm": 0.310546875,
      "learning_rate": 2.5261430808980846e-05,
      "loss": 2.8735,
      "step": 1074
    },
    {
      "epoch": 6.97,
      "grad_norm": 0.2431640625,
      "learning_rate": 2.51632884366386e-05,
      "loss": 2.7276,
      "step": 1075
    },
    {
      "epoch": 6.98,
      "grad_norm": 0.248046875,
      "learning_rate": 2.5065272935790252e-05,
      "loss": 2.8907,
      "step": 1076
    },
    {
      "epoch": 6.98,
      "grad_norm": 0.25,
      "learning_rate": 2.4967384807121013e-05,
      "loss": 2.92,
      "step": 1077
    },
    {
      "epoch": 6.99,
      "grad_norm": 0.25390625,
      "learning_rate": 2.4869624550665354e-05,
      "loss": 2.7417,
      "step": 1078
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.25390625,
      "learning_rate": 2.477199266580465e-05,
      "loss": 2.7122,
      "step": 1079
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.251953125,
      "learning_rate": 2.467448965126443e-05,
      "loss": 2.8681,
      "step": 1080
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.62890625,
      "learning_rate": 2.457711600511198e-05,
      "loss": 2.8062,
      "step": 1081
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.25390625,
      "learning_rate": 2.4479872224753714e-05,
      "loss": 2.917,
      "step": 1082
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.2490234375,
      "learning_rate": 2.438275880693266e-05,
      "loss": 2.8376,
      "step": 1083
    },
    {
      "epoch": 7.03,
      "grad_norm": 0.25390625,
      "learning_rate": 2.4285776247725985e-05,
      "loss": 2.8178,
      "step": 1084
    },
    {
      "epoch": 7.04,
      "grad_norm": 0.251953125,
      "learning_rate": 2.418892504254231e-05,
      "loss": 2.922,
      "step": 1085
    },
    {
      "epoch": 7.04,
      "grad_norm": 0.25,
      "learning_rate": 2.4092205686119364e-05,
      "loss": 2.9361,
      "step": 1086
    },
    {
      "epoch": 7.05,
      "grad_norm": 0.25,
      "learning_rate": 2.3995618672521287e-05,
      "loss": 2.8117,
      "step": 1087
    },
    {
      "epoch": 7.05,
      "grad_norm": 0.251953125,
      "learning_rate": 2.389916449513621e-05,
      "loss": 2.8736,
      "step": 1088
    },
    {
      "epoch": 7.06,
      "grad_norm": 0.263671875,
      "learning_rate": 2.380284364667371e-05,
      "loss": 2.921,
      "step": 1089
    },
    {
      "epoch": 7.07,
      "grad_norm": 0.26171875,
      "learning_rate": 2.3706656619162278e-05,
      "loss": 3.0679,
      "step": 1090
    },
    {
      "epoch": 7.07,
      "grad_norm": 0.240234375,
      "learning_rate": 2.361060390394684e-05,
      "loss": 2.8728,
      "step": 1091
    },
    {
      "epoch": 7.08,
      "grad_norm": 0.2451171875,
      "learning_rate": 2.3514685991686204e-05,
      "loss": 2.7966,
      "step": 1092
    },
    {
      "epoch": 7.09,
      "grad_norm": 0.251953125,
      "learning_rate": 2.3418903372350597e-05,
      "loss": 2.8351,
      "step": 1093
    },
    {
      "epoch": 7.09,
      "grad_norm": 0.24609375,
      "learning_rate": 2.3323256535219096e-05,
      "loss": 2.8199,
      "step": 1094
    },
    {
      "epoch": 7.1,
      "grad_norm": 0.26171875,
      "learning_rate": 2.3227745968877255e-05,
      "loss": 2.9069,
      "step": 1095
    },
    {
      "epoch": 7.11,
      "grad_norm": 0.28125,
      "learning_rate": 2.3132372161214394e-05,
      "loss": 2.8728,
      "step": 1096
    },
    {
      "epoch": 7.11,
      "grad_norm": 0.26171875,
      "learning_rate": 2.3037135599421377e-05,
      "loss": 2.9717,
      "step": 1097
    },
    {
      "epoch": 7.12,
      "grad_norm": 0.26171875,
      "learning_rate": 2.29420367699879e-05,
      "loss": 2.9164,
      "step": 1098
    },
    {
      "epoch": 7.13,
      "grad_norm": 0.255859375,
      "learning_rate": 2.2847076158700104e-05,
      "loss": 2.8333,
      "step": 1099
    },
    {
      "epoch": 7.13,
      "grad_norm": 0.2392578125,
      "learning_rate": 2.2752254250638126e-05,
      "loss": 2.7919,
      "step": 1100
    },
    {
      "epoch": 7.14,
      "grad_norm": 0.2890625,
      "learning_rate": 2.2657571530173506e-05,
      "loss": 2.9779,
      "step": 1101
    },
    {
      "epoch": 7.15,
      "grad_norm": 0.255859375,
      "learning_rate": 2.2563028480966853e-05,
      "loss": 2.9098,
      "step": 1102
    },
    {
      "epoch": 7.15,
      "grad_norm": 0.2421875,
      "learning_rate": 2.2468625585965252e-05,
      "loss": 2.7099,
      "step": 1103
    },
    {
      "epoch": 7.16,
      "grad_norm": 0.267578125,
      "learning_rate": 2.2374363327399873e-05,
      "loss": 2.8078,
      "step": 1104
    },
    {
      "epoch": 7.17,
      "grad_norm": 0.2578125,
      "learning_rate": 2.2280242186783473e-05,
      "loss": 2.89,
      "step": 1105
    },
    {
      "epoch": 7.17,
      "grad_norm": 0.251953125,
      "learning_rate": 2.218626264490793e-05,
      "loss": 2.8638,
      "step": 1106
    },
    {
      "epoch": 7.18,
      "grad_norm": 0.24609375,
      "learning_rate": 2.2092425181841864e-05,
      "loss": 2.8326,
      "step": 1107
    },
    {
      "epoch": 7.18,
      "grad_norm": 0.2490234375,
      "learning_rate": 2.199873027692805e-05,
      "loss": 2.8007,
      "step": 1108
    },
    {
      "epoch": 7.19,
      "grad_norm": 0.24609375,
      "learning_rate": 2.1905178408781114e-05,
      "loss": 2.9038,
      "step": 1109
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.24609375,
      "learning_rate": 2.1811770055284968e-05,
      "loss": 2.8519,
      "step": 1110
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.30078125,
      "learning_rate": 2.171850569359043e-05,
      "loss": 2.868,
      "step": 1111
    },
    {
      "epoch": 7.21,
      "grad_norm": 0.265625,
      "learning_rate": 2.1625385800112767e-05,
      "loss": 2.8602,
      "step": 1112
    },
    {
      "epoch": 7.22,
      "grad_norm": 0.27734375,
      "learning_rate": 2.153241085052932e-05,
      "loss": 2.8509,
      "step": 1113
    },
    {
      "epoch": 7.22,
      "grad_norm": 0.259765625,
      "learning_rate": 2.1439581319776962e-05,
      "loss": 2.8604,
      "step": 1114
    },
    {
      "epoch": 7.23,
      "grad_norm": 0.25390625,
      "learning_rate": 2.134689768204975e-05,
      "loss": 2.8754,
      "step": 1115
    },
    {
      "epoch": 7.24,
      "grad_norm": 0.271484375,
      "learning_rate": 2.1254360410796524e-05,
      "loss": 2.9005,
      "step": 1116
    },
    {
      "epoch": 7.24,
      "grad_norm": 0.255859375,
      "learning_rate": 2.116196997871841e-05,
      "loss": 2.6289,
      "step": 1117
    },
    {
      "epoch": 7.25,
      "grad_norm": 0.255859375,
      "learning_rate": 2.1069726857766458e-05,
      "loss": 2.8538,
      "step": 1118
    },
    {
      "epoch": 7.26,
      "grad_norm": 0.255859375,
      "learning_rate": 2.0977631519139208e-05,
      "loss": 2.8243,
      "step": 1119
    },
    {
      "epoch": 7.26,
      "grad_norm": 0.255859375,
      "learning_rate": 2.0885684433280333e-05,
      "loss": 2.8228,
      "step": 1120
    },
    {
      "epoch": 7.27,
      "grad_norm": 0.25390625,
      "learning_rate": 2.079388606987615e-05,
      "loss": 2.7454,
      "step": 1121
    },
    {
      "epoch": 7.28,
      "grad_norm": 0.2490234375,
      "learning_rate": 2.0702236897853316e-05,
      "loss": 2.8695,
      "step": 1122
    },
    {
      "epoch": 7.28,
      "grad_norm": 0.2578125,
      "learning_rate": 2.061073738537635e-05,
      "loss": 2.8783,
      "step": 1123
    },
    {
      "epoch": 7.29,
      "grad_norm": 0.26953125,
      "learning_rate": 2.051938799984528e-05,
      "loss": 2.8774,
      "step": 1124
    },
    {
      "epoch": 7.29,
      "grad_norm": 0.271484375,
      "learning_rate": 2.042818920789326e-05,
      "loss": 2.8245,
      "step": 1125
    },
    {
      "epoch": 7.3,
      "grad_norm": 0.255859375,
      "learning_rate": 2.0337141475384164e-05,
      "loss": 2.9685,
      "step": 1126
    },
    {
      "epoch": 7.31,
      "grad_norm": 0.2470703125,
      "learning_rate": 2.0246245267410262e-05,
      "loss": 2.8099,
      "step": 1127
    },
    {
      "epoch": 7.31,
      "grad_norm": 0.25390625,
      "learning_rate": 2.0155501048289745e-05,
      "loss": 2.8017,
      "step": 1128
    },
    {
      "epoch": 7.32,
      "grad_norm": 0.28125,
      "learning_rate": 2.0064909281564465e-05,
      "loss": 2.9104,
      "step": 1129
    },
    {
      "epoch": 7.33,
      "grad_norm": 0.26953125,
      "learning_rate": 1.9974470429997483e-05,
      "loss": 2.8708,
      "step": 1130
    },
    {
      "epoch": 7.33,
      "grad_norm": 0.244140625,
      "learning_rate": 1.9884184955570727e-05,
      "loss": 2.8157,
      "step": 1131
    },
    {
      "epoch": 7.34,
      "grad_norm": 0.25390625,
      "learning_rate": 1.979405331948266e-05,
      "loss": 2.823,
      "step": 1132
    },
    {
      "epoch": 7.35,
      "grad_norm": 0.28125,
      "learning_rate": 1.970407598214588e-05,
      "loss": 2.8005,
      "step": 1133
    },
    {
      "epoch": 7.35,
      "grad_norm": 0.244140625,
      "learning_rate": 1.961425340318484e-05,
      "loss": 2.7375,
      "step": 1134
    },
    {
      "epoch": 7.36,
      "grad_norm": 0.26171875,
      "learning_rate": 1.952458604143339e-05,
      "loss": 2.8358,
      "step": 1135
    },
    {
      "epoch": 7.37,
      "grad_norm": 0.263671875,
      "learning_rate": 1.943507435493256e-05,
      "loss": 2.7271,
      "step": 1136
    },
    {
      "epoch": 7.37,
      "grad_norm": 0.271484375,
      "learning_rate": 1.9345718800928093e-05,
      "loss": 2.8692,
      "step": 1137
    },
    {
      "epoch": 7.38,
      "grad_norm": 0.25,
      "learning_rate": 1.9256519835868236e-05,
      "loss": 2.8126,
      "step": 1138
    },
    {
      "epoch": 7.39,
      "grad_norm": 0.25,
      "learning_rate": 1.9167477915401306e-05,
      "loss": 2.8329,
      "step": 1139
    },
    {
      "epoch": 7.39,
      "grad_norm": 0.294921875,
      "learning_rate": 1.907859349437336e-05,
      "loss": 2.9189,
      "step": 1140
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.2490234375,
      "learning_rate": 1.8989867026826014e-05,
      "loss": 2.947,
      "step": 1141
    },
    {
      "epoch": 7.41,
      "grad_norm": 0.259765625,
      "learning_rate": 1.890129896599392e-05,
      "loss": 2.9207,
      "step": 1142
    },
    {
      "epoch": 7.41,
      "grad_norm": 0.267578125,
      "learning_rate": 1.8812889764302644e-05,
      "loss": 2.918,
      "step": 1143
    },
    {
      "epoch": 7.42,
      "grad_norm": 0.265625,
      "learning_rate": 1.8724639873366185e-05,
      "loss": 2.9662,
      "step": 1144
    },
    {
      "epoch": 7.42,
      "grad_norm": 0.265625,
      "learning_rate": 1.8636549743984817e-05,
      "loss": 2.9666,
      "step": 1145
    },
    {
      "epoch": 7.43,
      "grad_norm": 0.2490234375,
      "learning_rate": 1.8548619826142654e-05,
      "loss": 2.8168,
      "step": 1146
    },
    {
      "epoch": 7.44,
      "grad_norm": 0.255859375,
      "learning_rate": 1.846085056900545e-05,
      "loss": 2.8728,
      "step": 1147
    },
    {
      "epoch": 7.44,
      "grad_norm": 0.255859375,
      "learning_rate": 1.8373242420918258e-05,
      "loss": 2.7635,
      "step": 1148
    },
    {
      "epoch": 7.45,
      "grad_norm": 0.2490234375,
      "learning_rate": 1.828579582940313e-05,
      "loss": 2.891,
      "step": 1149
    },
    {
      "epoch": 7.46,
      "grad_norm": 0.2490234375,
      "learning_rate": 1.8198511241156903e-05,
      "loss": 2.7435,
      "step": 1150
    },
    {
      "epoch": 7.46,
      "grad_norm": 0.267578125,
      "learning_rate": 1.8111389102048802e-05,
      "loss": 2.7892,
      "step": 1151
    },
    {
      "epoch": 7.47,
      "grad_norm": 0.27734375,
      "learning_rate": 1.8024429857118297e-05,
      "loss": 2.9541,
      "step": 1152
    },
    {
      "epoch": 7.48,
      "grad_norm": 0.244140625,
      "learning_rate": 1.7937633950572692e-05,
      "loss": 2.7819,
      "step": 1153
    },
    {
      "epoch": 7.48,
      "grad_norm": 0.24609375,
      "learning_rate": 1.785100182578494e-05,
      "loss": 2.7711,
      "step": 1154
    },
    {
      "epoch": 7.49,
      "grad_norm": 0.25,
      "learning_rate": 1.7764533925291388e-05,
      "loss": 2.8984,
      "step": 1155
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.25390625,
      "learning_rate": 1.767823069078943e-05,
      "loss": 2.8439,
      "step": 1156
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.2470703125,
      "learning_rate": 1.75920925631354e-05,
      "loss": 2.8504,
      "step": 1157
    },
    {
      "epoch": 7.51,
      "grad_norm": 0.2578125,
      "learning_rate": 1.7506119982342127e-05,
      "loss": 2.8139,
      "step": 1158
    },
    {
      "epoch": 7.52,
      "grad_norm": 0.26171875,
      "learning_rate": 1.742031338757688e-05,
      "loss": 2.851,
      "step": 1159
    },
    {
      "epoch": 7.52,
      "grad_norm": 0.251953125,
      "learning_rate": 1.7334673217158974e-05,
      "loss": 2.7878,
      "step": 1160
    },
    {
      "epoch": 7.53,
      "grad_norm": 0.2490234375,
      "learning_rate": 1.7249199908557607e-05,
      "loss": 2.9016,
      "step": 1161
    },
    {
      "epoch": 7.53,
      "grad_norm": 0.259765625,
      "learning_rate": 1.7163893898389606e-05,
      "loss": 2.7708,
      "step": 1162
    },
    {
      "epoch": 7.54,
      "grad_norm": 0.259765625,
      "learning_rate": 1.7078755622417225e-05,
      "loss": 2.9732,
      "step": 1163
    },
    {
      "epoch": 7.55,
      "grad_norm": 0.25390625,
      "learning_rate": 1.6993785515545867e-05,
      "loss": 2.948,
      "step": 1164
    },
    {
      "epoch": 7.55,
      "grad_norm": 0.25390625,
      "learning_rate": 1.6908984011821883e-05,
      "loss": 2.8157,
      "step": 1165
    },
    {
      "epoch": 7.56,
      "grad_norm": 0.26953125,
      "learning_rate": 1.68243515444304e-05,
      "loss": 2.8278,
      "step": 1166
    },
    {
      "epoch": 7.57,
      "grad_norm": 0.2431640625,
      "learning_rate": 1.6739888545693044e-05,
      "loss": 2.8703,
      "step": 1167
    },
    {
      "epoch": 7.57,
      "grad_norm": 0.2421875,
      "learning_rate": 1.6655595447065748e-05,
      "loss": 2.7931,
      "step": 1168
    },
    {
      "epoch": 7.58,
      "grad_norm": 0.25390625,
      "learning_rate": 1.6571472679136555e-05,
      "loss": 2.8251,
      "step": 1169
    },
    {
      "epoch": 7.59,
      "grad_norm": 0.2431640625,
      "learning_rate": 1.6487520671623468e-05,
      "loss": 2.7215,
      "step": 1170
    },
    {
      "epoch": 7.59,
      "grad_norm": 0.2470703125,
      "learning_rate": 1.6403739853372135e-05,
      "loss": 2.8536,
      "step": 1171
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.2578125,
      "learning_rate": 1.632013065235381e-05,
      "loss": 2.8575,
      "step": 1172
    },
    {
      "epoch": 7.61,
      "grad_norm": 0.2578125,
      "learning_rate": 1.623669349566302e-05,
      "loss": 2.6856,
      "step": 1173
    },
    {
      "epoch": 7.61,
      "grad_norm": 0.2412109375,
      "learning_rate": 1.615342880951547e-05,
      "loss": 2.9139,
      "step": 1174
    },
    {
      "epoch": 7.62,
      "grad_norm": 0.25390625,
      "learning_rate": 1.6070337019245895e-05,
      "loss": 2.8188,
      "step": 1175
    },
    {
      "epoch": 7.63,
      "grad_norm": 0.255859375,
      "learning_rate": 1.5987418549305743e-05,
      "loss": 2.73,
      "step": 1176
    },
    {
      "epoch": 7.63,
      "grad_norm": 0.265625,
      "learning_rate": 1.5904673823261208e-05,
      "loss": 2.73,
      "step": 1177
    },
    {
      "epoch": 7.64,
      "grad_norm": 0.345703125,
      "learning_rate": 1.5822103263790865e-05,
      "loss": 2.997,
      "step": 1178
    },
    {
      "epoch": 7.64,
      "grad_norm": 0.251953125,
      "learning_rate": 1.5739707292683697e-05,
      "loss": 2.8568,
      "step": 1179
    },
    {
      "epoch": 7.65,
      "grad_norm": 0.26171875,
      "learning_rate": 1.5657486330836784e-05,
      "loss": 2.8706,
      "step": 1180
    },
    {
      "epoch": 7.66,
      "grad_norm": 0.24609375,
      "learning_rate": 1.5575440798253237e-05,
      "loss": 2.8622,
      "step": 1181
    },
    {
      "epoch": 7.66,
      "grad_norm": 0.25390625,
      "learning_rate": 1.5493571114040068e-05,
      "loss": 2.9922,
      "step": 1182
    },
    {
      "epoch": 7.67,
      "grad_norm": 0.255859375,
      "learning_rate": 1.5411877696405967e-05,
      "loss": 2.7192,
      "step": 1183
    },
    {
      "epoch": 7.68,
      "grad_norm": 0.265625,
      "learning_rate": 1.5330360962659242e-05,
      "loss": 2.7729,
      "step": 1184
    },
    {
      "epoch": 7.68,
      "grad_norm": 0.267578125,
      "learning_rate": 1.5249021329205637e-05,
      "loss": 2.9173,
      "step": 1185
    },
    {
      "epoch": 7.69,
      "grad_norm": 0.259765625,
      "learning_rate": 1.5167859211546276e-05,
      "loss": 2.787,
      "step": 1186
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.25,
      "learning_rate": 1.5086875024275432e-05,
      "loss": 2.9388,
      "step": 1187
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.25390625,
      "learning_rate": 1.5006069181078531e-05,
      "loss": 2.7442,
      "step": 1188
    },
    {
      "epoch": 7.71,
      "grad_norm": 0.271484375,
      "learning_rate": 1.492544209472993e-05,
      "loss": 2.8816,
      "step": 1189
    },
    {
      "epoch": 7.72,
      "grad_norm": 0.259765625,
      "learning_rate": 1.484499417709087e-05,
      "loss": 2.894,
      "step": 1190
    },
    {
      "epoch": 7.72,
      "grad_norm": 0.259765625,
      "learning_rate": 1.4764725839107363e-05,
      "loss": 2.7795,
      "step": 1191
    },
    {
      "epoch": 7.73,
      "grad_norm": 0.267578125,
      "learning_rate": 1.4684637490808067e-05,
      "loss": 2.8553,
      "step": 1192
    },
    {
      "epoch": 7.74,
      "grad_norm": 0.263671875,
      "learning_rate": 1.4604729541302265e-05,
      "loss": 2.8517,
      "step": 1193
    },
    {
      "epoch": 7.74,
      "grad_norm": 0.2490234375,
      "learning_rate": 1.4525002398777654e-05,
      "loss": 2.842,
      "step": 1194
    },
    {
      "epoch": 7.75,
      "grad_norm": 0.26171875,
      "learning_rate": 1.4445456470498392e-05,
      "loss": 2.8335,
      "step": 1195
    },
    {
      "epoch": 7.76,
      "grad_norm": 0.263671875,
      "learning_rate": 1.4366092162802908e-05,
      "loss": 2.856,
      "step": 1196
    },
    {
      "epoch": 7.76,
      "grad_norm": 0.251953125,
      "learning_rate": 1.4286909881101895e-05,
      "loss": 2.7823,
      "step": 1197
    },
    {
      "epoch": 7.77,
      "grad_norm": 0.2412109375,
      "learning_rate": 1.4207910029876198e-05,
      "loss": 2.8751,
      "step": 1198
    },
    {
      "epoch": 7.77,
      "grad_norm": 0.2890625,
      "learning_rate": 1.4129093012674771e-05,
      "loss": 2.8358,
      "step": 1199
    },
    {
      "epoch": 7.78,
      "grad_norm": 0.248046875,
      "learning_rate": 1.405045923211265e-05,
      "loss": 2.8592,
      "step": 1200
    },
    {
      "epoch": 7.79,
      "grad_norm": 0.251953125,
      "learning_rate": 1.3972009089868787e-05,
      "loss": 2.841,
      "step": 1201
    },
    {
      "epoch": 7.79,
      "grad_norm": 0.263671875,
      "learning_rate": 1.3893742986684144e-05,
      "loss": 2.9887,
      "step": 1202
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.25390625,
      "learning_rate": 1.3815661322359514e-05,
      "loss": 2.9268,
      "step": 1203
    },
    {
      "epoch": 7.81,
      "grad_norm": 0.25,
      "learning_rate": 1.3737764495753551e-05,
      "loss": 2.712,
      "step": 1204
    },
    {
      "epoch": 7.81,
      "grad_norm": 0.251953125,
      "learning_rate": 1.3660052904780706e-05,
      "loss": 2.8039,
      "step": 1205
    },
    {
      "epoch": 7.82,
      "grad_norm": 0.265625,
      "learning_rate": 1.3582526946409247e-05,
      "loss": 2.803,
      "step": 1206
    },
    {
      "epoch": 7.83,
      "grad_norm": 0.259765625,
      "learning_rate": 1.3505187016659143e-05,
      "loss": 2.7918,
      "step": 1207
    },
    {
      "epoch": 7.83,
      "grad_norm": 0.265625,
      "learning_rate": 1.3428033510600096e-05,
      "loss": 2.8531,
      "step": 1208
    },
    {
      "epoch": 7.84,
      "grad_norm": 0.2578125,
      "learning_rate": 1.335106682234954e-05,
      "loss": 2.8252,
      "step": 1209
    },
    {
      "epoch": 7.85,
      "grad_norm": 0.279296875,
      "learning_rate": 1.3274287345070562e-05,
      "loss": 2.9139,
      "step": 1210
    },
    {
      "epoch": 7.85,
      "grad_norm": 0.267578125,
      "learning_rate": 1.319769547097e-05,
      "loss": 2.9428,
      "step": 1211
    },
    {
      "epoch": 7.86,
      "grad_norm": 0.248046875,
      "learning_rate": 1.3121291591296265e-05,
      "loss": 2.804,
      "step": 1212
    },
    {
      "epoch": 7.87,
      "grad_norm": 0.25390625,
      "learning_rate": 1.3045076096337556e-05,
      "loss": 2.7403,
      "step": 1213
    },
    {
      "epoch": 7.87,
      "grad_norm": 0.283203125,
      "learning_rate": 1.2969049375419706e-05,
      "loss": 2.9607,
      "step": 1214
    },
    {
      "epoch": 7.88,
      "grad_norm": 0.271484375,
      "learning_rate": 1.2893211816904243e-05,
      "loss": 2.8223,
      "step": 1215
    },
    {
      "epoch": 7.88,
      "grad_norm": 0.275390625,
      "learning_rate": 1.2817563808186456e-05,
      "loss": 2.7763,
      "step": 1216
    },
    {
      "epoch": 7.89,
      "grad_norm": 0.255859375,
      "learning_rate": 1.2742105735693316e-05,
      "loss": 2.9335,
      "step": 1217
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.2470703125,
      "learning_rate": 1.2666837984881608e-05,
      "loss": 2.957,
      "step": 1218
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.259765625,
      "learning_rate": 1.259176094023588e-05,
      "loss": 2.6685,
      "step": 1219
    },
    {
      "epoch": 7.91,
      "grad_norm": 0.265625,
      "learning_rate": 1.2516874985266508e-05,
      "loss": 2.974,
      "step": 1220
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.24609375,
      "learning_rate": 1.2442180502507744e-05,
      "loss": 2.7731,
      "step": 1221
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.25390625,
      "learning_rate": 1.2367677873515782e-05,
      "loss": 2.6557,
      "step": 1222
    },
    {
      "epoch": 7.93,
      "grad_norm": 0.25,
      "learning_rate": 1.2293367478866746e-05,
      "loss": 2.8336,
      "step": 1223
    },
    {
      "epoch": 7.94,
      "grad_norm": 0.25,
      "learning_rate": 1.2219249698154795e-05,
      "loss": 2.8587,
      "step": 1224
    },
    {
      "epoch": 7.94,
      "grad_norm": 0.2490234375,
      "learning_rate": 1.2145324909990202e-05,
      "loss": 2.8425,
      "step": 1225
    },
    {
      "epoch": 7.95,
      "grad_norm": 0.28125,
      "learning_rate": 1.2071593491997357e-05,
      "loss": 2.9349,
      "step": 1226
    },
    {
      "epoch": 7.96,
      "grad_norm": 0.296875,
      "learning_rate": 1.1998055820812881e-05,
      "loss": 2.8505,
      "step": 1227
    },
    {
      "epoch": 7.96,
      "grad_norm": 0.259765625,
      "learning_rate": 1.1924712272083672e-05,
      "loss": 2.847,
      "step": 1228
    },
    {
      "epoch": 7.97,
      "grad_norm": 0.251953125,
      "learning_rate": 1.1851563220465067e-05,
      "loss": 2.93,
      "step": 1229
    },
    {
      "epoch": 7.98,
      "grad_norm": 0.25390625,
      "learning_rate": 1.1778609039618805e-05,
      "loss": 2.8372,
      "step": 1230
    },
    {
      "epoch": 7.98,
      "grad_norm": 0.2578125,
      "learning_rate": 1.170585010221122e-05,
      "loss": 2.8716,
      "step": 1231
    },
    {
      "epoch": 7.99,
      "grad_norm": 0.27734375,
      "learning_rate": 1.1633286779911284e-05,
      "loss": 2.7718,
      "step": 1232
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.267578125,
      "learning_rate": 1.1560919443388719e-05,
      "loss": 2.752,
      "step": 1233
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.259765625,
      "learning_rate": 1.148874846231211e-05,
      "loss": 2.8749,
      "step": 1234
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.24609375,
      "learning_rate": 1.1416774205347013e-05,
      "loss": 2.7759,
      "step": 1235
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.30859375,
      "learning_rate": 1.1344997040154099e-05,
      "loss": 2.7499,
      "step": 1236
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.2578125,
      "learning_rate": 1.1273417333387199e-05,
      "loss": 2.9297,
      "step": 1237
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.248046875,
      "learning_rate": 1.1202035450691545e-05,
      "loss": 2.9152,
      "step": 1238
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.26953125,
      "learning_rate": 1.1130851756701787e-05,
      "loss": 2.7504,
      "step": 1239
    },
    {
      "epoch": 8.04,
      "grad_norm": 0.2578125,
      "learning_rate": 1.1059866615040204e-05,
      "loss": 2.9395,
      "step": 1240
    },
    {
      "epoch": 8.05,
      "grad_norm": 0.244140625,
      "learning_rate": 1.0989080388314821e-05,
      "loss": 2.833,
      "step": 1241
    },
    {
      "epoch": 8.05,
      "grad_norm": 0.265625,
      "learning_rate": 1.0918493438117554e-05,
      "loss": 2.8654,
      "step": 1242
    },
    {
      "epoch": 8.06,
      "grad_norm": 0.2578125,
      "learning_rate": 1.08481061250224e-05,
      "loss": 2.9832,
      "step": 1243
    },
    {
      "epoch": 8.07,
      "grad_norm": 0.28515625,
      "learning_rate": 1.0777918808583514e-05,
      "loss": 2.7787,
      "step": 1244
    },
    {
      "epoch": 8.07,
      "grad_norm": 0.2490234375,
      "learning_rate": 1.0707931847333486e-05,
      "loss": 2.9339,
      "step": 1245
    },
    {
      "epoch": 8.08,
      "grad_norm": 0.244140625,
      "learning_rate": 1.0638145598781386e-05,
      "loss": 2.7871,
      "step": 1246
    },
    {
      "epoch": 8.09,
      "grad_norm": 0.26171875,
      "learning_rate": 1.056856041941106e-05,
      "loss": 2.976,
      "step": 1247
    },
    {
      "epoch": 8.09,
      "grad_norm": 0.2578125,
      "learning_rate": 1.0499176664679178e-05,
      "loss": 2.8389,
      "step": 1248
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.2578125,
      "learning_rate": 1.0429994689013517e-05,
      "loss": 2.7163,
      "step": 1249
    },
    {
      "epoch": 8.11,
      "grad_norm": 0.248046875,
      "learning_rate": 1.0361014845811168e-05,
      "loss": 2.7647,
      "step": 1250
    },
    {
      "epoch": 8.11,
      "grad_norm": 0.291015625,
      "learning_rate": 1.0292237487436601e-05,
      "loss": 2.8878,
      "step": 1251
    },
    {
      "epoch": 8.12,
      "grad_norm": 0.240234375,
      "learning_rate": 1.0223662965220021e-05,
      "loss": 2.7291,
      "step": 1252
    },
    {
      "epoch": 8.12,
      "grad_norm": 0.251953125,
      "learning_rate": 1.015529162945545e-05,
      "loss": 2.746,
      "step": 1253
    },
    {
      "epoch": 8.13,
      "grad_norm": 0.240234375,
      "learning_rate": 1.0087123829399026e-05,
      "loss": 2.755,
      "step": 1254
    },
    {
      "epoch": 8.14,
      "grad_norm": 0.2490234375,
      "learning_rate": 1.0019159913267156e-05,
      "loss": 2.8324,
      "step": 1255
    },
    {
      "epoch": 8.14,
      "grad_norm": 0.2470703125,
      "learning_rate": 9.95140022823477e-06,
      "loss": 2.5243,
      "step": 1256
    },
    {
      "epoch": 8.15,
      "grad_norm": 0.2578125,
      "learning_rate": 9.883845120433526e-06,
      "loss": 2.8776,
      "step": 1257
    },
    {
      "epoch": 8.16,
      "grad_norm": 0.25,
      "learning_rate": 9.816494934950072e-06,
      "loss": 2.8151,
      "step": 1258
    },
    {
      "epoch": 8.16,
      "grad_norm": 0.2470703125,
      "learning_rate": 9.749350015824276e-06,
      "loss": 2.8575,
      "step": 1259
    },
    {
      "epoch": 8.17,
      "grad_norm": 0.26171875,
      "learning_rate": 9.682410706047428e-06,
      "loss": 2.8949,
      "step": 1260
    },
    {
      "epoch": 8.18,
      "grad_norm": 0.275390625,
      "learning_rate": 9.615677347560565e-06,
      "loss": 2.8644,
      "step": 1261
    },
    {
      "epoch": 8.18,
      "grad_norm": 0.255859375,
      "learning_rate": 9.549150281252633e-06,
      "loss": 2.8844,
      "step": 1262
    },
    {
      "epoch": 8.19,
      "grad_norm": 0.265625,
      "learning_rate": 9.482829846958813e-06,
      "loss": 2.9549,
      "step": 1263
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.263671875,
      "learning_rate": 9.416716383458757e-06,
      "loss": 2.7877,
      "step": 1264
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.271484375,
      "learning_rate": 9.350810228474855e-06,
      "loss": 2.8245,
      "step": 1265
    },
    {
      "epoch": 8.21,
      "grad_norm": 0.275390625,
      "learning_rate": 9.285111718670558e-06,
      "loss": 2.8458,
      "step": 1266
    },
    {
      "epoch": 8.22,
      "grad_norm": 0.2451171875,
      "learning_rate": 9.219621189648564e-06,
      "loss": 2.7755,
      "step": 1267
    },
    {
      "epoch": 8.22,
      "grad_norm": 0.263671875,
      "learning_rate": 9.154338975949218e-06,
      "loss": 2.8839,
      "step": 1268
    },
    {
      "epoch": 8.23,
      "grad_norm": 0.25390625,
      "learning_rate": 9.089265411048686e-06,
      "loss": 2.8517,
      "step": 1269
    },
    {
      "epoch": 8.24,
      "grad_norm": 0.2421875,
      "learning_rate": 9.024400827357344e-06,
      "loss": 2.8168,
      "step": 1270
    },
    {
      "epoch": 8.24,
      "grad_norm": 0.255859375,
      "learning_rate": 8.959745556218018e-06,
      "loss": 2.8817,
      "step": 1271
    },
    {
      "epoch": 8.25,
      "grad_norm": 0.279296875,
      "learning_rate": 8.895299927904367e-06,
      "loss": 2.8448,
      "step": 1272
    },
    {
      "epoch": 8.25,
      "grad_norm": 0.2734375,
      "learning_rate": 8.8310642716191e-06,
      "loss": 2.7511,
      "step": 1273
    },
    {
      "epoch": 8.26,
      "grad_norm": 0.25390625,
      "learning_rate": 8.767038915492349e-06,
      "loss": 2.9715,
      "step": 1274
    },
    {
      "epoch": 8.27,
      "grad_norm": 0.251953125,
      "learning_rate": 8.703224186580012e-06,
      "loss": 2.8556,
      "step": 1275
    },
    {
      "epoch": 8.27,
      "grad_norm": 0.259765625,
      "learning_rate": 8.639620410862031e-06,
      "loss": 2.888,
      "step": 1276
    },
    {
      "epoch": 8.28,
      "grad_norm": 0.419921875,
      "learning_rate": 8.576227913240764e-06,
      "loss": 2.8383,
      "step": 1277
    },
    {
      "epoch": 8.29,
      "grad_norm": 0.25390625,
      "learning_rate": 8.513047017539294e-06,
      "loss": 2.8697,
      "step": 1278
    },
    {
      "epoch": 8.29,
      "grad_norm": 0.2490234375,
      "learning_rate": 8.450078046499832e-06,
      "loss": 2.8947,
      "step": 1279
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.2578125,
      "learning_rate": 8.387321321781976e-06,
      "loss": 2.9182,
      "step": 1280
    },
    {
      "epoch": 8.31,
      "grad_norm": 0.2734375,
      "learning_rate": 8.324777163961195e-06,
      "loss": 2.8344,
      "step": 1281
    },
    {
      "epoch": 8.31,
      "grad_norm": 0.24609375,
      "learning_rate": 8.262445892527048e-06,
      "loss": 2.8333,
      "step": 1282
    },
    {
      "epoch": 8.32,
      "grad_norm": 0.25390625,
      "learning_rate": 8.200327825881654e-06,
      "loss": 2.7616,
      "step": 1283
    },
    {
      "epoch": 8.33,
      "grad_norm": 0.25,
      "learning_rate": 8.138423281338042e-06,
      "loss": 2.829,
      "step": 1284
    },
    {
      "epoch": 8.33,
      "grad_norm": 0.244140625,
      "learning_rate": 8.076732575118489e-06,
      "loss": 2.7503,
      "step": 1285
    },
    {
      "epoch": 8.34,
      "grad_norm": 0.263671875,
      "learning_rate": 8.015256022352985e-06,
      "loss": 2.9063,
      "step": 1286
    },
    {
      "epoch": 8.35,
      "grad_norm": 0.251953125,
      "learning_rate": 7.953993937077536e-06,
      "loss": 2.945,
      "step": 1287
    },
    {
      "epoch": 8.35,
      "grad_norm": 0.255859375,
      "learning_rate": 7.892946632232628e-06,
      "loss": 2.8842,
      "step": 1288
    },
    {
      "epoch": 8.36,
      "grad_norm": 0.26171875,
      "learning_rate": 7.832114419661585e-06,
      "loss": 2.7894,
      "step": 1289
    },
    {
      "epoch": 8.36,
      "grad_norm": 0.24609375,
      "learning_rate": 7.77149761010898e-06,
      "loss": 2.8743,
      "step": 1290
    },
    {
      "epoch": 8.37,
      "grad_norm": 0.26171875,
      "learning_rate": 7.711096513219113e-06,
      "loss": 2.822,
      "step": 1291
    },
    {
      "epoch": 8.38,
      "grad_norm": 0.2490234375,
      "learning_rate": 7.650911437534274e-06,
      "loss": 2.7569,
      "step": 1292
    },
    {
      "epoch": 8.38,
      "grad_norm": 0.2392578125,
      "learning_rate": 7.590942690493386e-06,
      "loss": 2.8632,
      "step": 1293
    },
    {
      "epoch": 8.39,
      "grad_norm": 0.2734375,
      "learning_rate": 7.531190578430219e-06,
      "loss": 2.8506,
      "step": 1294
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.25,
      "learning_rate": 7.471655406572003e-06,
      "loss": 2.9873,
      "step": 1295
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.29296875,
      "learning_rate": 7.412337479037718e-06,
      "loss": 2.7562,
      "step": 1296
    },
    {
      "epoch": 8.41,
      "grad_norm": 0.2451171875,
      "learning_rate": 7.3532370988366685e-06,
      "loss": 2.7094,
      "step": 1297
    },
    {
      "epoch": 8.42,
      "grad_norm": 0.28515625,
      "learning_rate": 7.29435456786684e-06,
      "loss": 2.8943,
      "step": 1298
    },
    {
      "epoch": 8.42,
      "grad_norm": 0.25390625,
      "learning_rate": 7.235690186913413e-06,
      "loss": 2.7168,
      "step": 1299
    },
    {
      "epoch": 8.43,
      "grad_norm": 0.24609375,
      "learning_rate": 7.177244255647208e-06,
      "loss": 2.9067,
      "step": 1300
    },
    {
      "epoch": 8.44,
      "grad_norm": 0.25390625,
      "learning_rate": 7.119017072623135e-06,
      "loss": 2.8816,
      "step": 1301
    },
    {
      "epoch": 8.44,
      "grad_norm": 0.25390625,
      "learning_rate": 7.061008935278729e-06,
      "loss": 2.8615,
      "step": 1302
    },
    {
      "epoch": 8.45,
      "grad_norm": 0.25390625,
      "learning_rate": 7.003220139932542e-06,
      "loss": 2.7414,
      "step": 1303
    },
    {
      "epoch": 8.46,
      "grad_norm": 0.251953125,
      "learning_rate": 6.945650981782737e-06,
      "loss": 2.8959,
      "step": 1304
    },
    {
      "epoch": 8.46,
      "grad_norm": 0.2470703125,
      "learning_rate": 6.888301754905469e-06,
      "loss": 2.8268,
      "step": 1305
    },
    {
      "epoch": 8.47,
      "grad_norm": 0.25,
      "learning_rate": 6.831172752253451e-06,
      "loss": 2.8393,
      "step": 1306
    },
    {
      "epoch": 8.47,
      "grad_norm": 0.2578125,
      "learning_rate": 6.7742642656544456e-06,
      "loss": 2.8866,
      "step": 1307
    },
    {
      "epoch": 8.48,
      "grad_norm": 0.265625,
      "learning_rate": 6.717576585809759e-06,
      "loss": 2.868,
      "step": 1308
    },
    {
      "epoch": 8.49,
      "grad_norm": 0.24609375,
      "learning_rate": 6.661110002292797e-06,
      "loss": 2.9444,
      "step": 1309
    },
    {
      "epoch": 8.49,
      "grad_norm": 0.251953125,
      "learning_rate": 6.6048648035475115e-06,
      "loss": 2.9188,
      "step": 1310
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.306640625,
      "learning_rate": 6.548841276887013e-06,
      "loss": 2.8977,
      "step": 1311
    },
    {
      "epoch": 8.51,
      "grad_norm": 0.240234375,
      "learning_rate": 6.493039708492044e-06,
      "loss": 2.7257,
      "step": 1312
    },
    {
      "epoch": 8.51,
      "grad_norm": 0.2421875,
      "learning_rate": 6.437460383409516e-06,
      "loss": 2.6607,
      "step": 1313
    },
    {
      "epoch": 8.52,
      "grad_norm": 0.26171875,
      "learning_rate": 6.3821035855511025e-06,
      "loss": 2.7893,
      "step": 1314
    },
    {
      "epoch": 8.53,
      "grad_norm": 0.2578125,
      "learning_rate": 6.326969597691723e-06,
      "loss": 2.8743,
      "step": 1315
    },
    {
      "epoch": 8.53,
      "grad_norm": 0.251953125,
      "learning_rate": 6.272058701468186e-06,
      "loss": 2.8696,
      "step": 1316
    },
    {
      "epoch": 8.54,
      "grad_norm": 0.279296875,
      "learning_rate": 6.21737117737764e-06,
      "loss": 2.7844,
      "step": 1317
    },
    {
      "epoch": 8.55,
      "grad_norm": 0.3125,
      "learning_rate": 6.162907304776244e-06,
      "loss": 2.8766,
      "step": 1318
    },
    {
      "epoch": 8.55,
      "grad_norm": 0.25,
      "learning_rate": 6.108667361877674e-06,
      "loss": 2.9417,
      "step": 1319
    },
    {
      "epoch": 8.56,
      "grad_norm": 0.25,
      "learning_rate": 6.054651625751717e-06,
      "loss": 2.7809,
      "step": 1320
    },
    {
      "epoch": 8.57,
      "grad_norm": 0.29296875,
      "learning_rate": 6.000860372322864e-06,
      "loss": 2.7122,
      "step": 1321
    },
    {
      "epoch": 8.57,
      "grad_norm": 0.275390625,
      "learning_rate": 5.94729387636892e-06,
      "loss": 2.8478,
      "step": 1322
    },
    {
      "epoch": 8.58,
      "grad_norm": 0.244140625,
      "learning_rate": 5.89395241151956e-06,
      "loss": 2.893,
      "step": 1323
    },
    {
      "epoch": 8.59,
      "grad_norm": 0.255859375,
      "learning_rate": 5.840836250254933e-06,
      "loss": 3.0134,
      "step": 1324
    },
    {
      "epoch": 8.59,
      "grad_norm": 0.255859375,
      "learning_rate": 5.787945663904332e-06,
      "loss": 2.824,
      "step": 1325
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.25390625,
      "learning_rate": 5.735280922644715e-06,
      "loss": 2.906,
      "step": 1326
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.271484375,
      "learning_rate": 5.682842295499419e-06,
      "loss": 2.9332,
      "step": 1327
    },
    {
      "epoch": 8.61,
      "grad_norm": 0.2451171875,
      "learning_rate": 5.630630050336677e-06,
      "loss": 2.7271,
      "step": 1328
    },
    {
      "epoch": 8.62,
      "grad_norm": 0.2490234375,
      "learning_rate": 5.578644453868381e-06,
      "loss": 2.8681,
      "step": 1329
    },
    {
      "epoch": 8.62,
      "grad_norm": 0.2490234375,
      "learning_rate": 5.526885771648599e-06,
      "loss": 2.738,
      "step": 1330
    },
    {
      "epoch": 8.63,
      "grad_norm": 0.279296875,
      "learning_rate": 5.475354268072308e-06,
      "loss": 2.8113,
      "step": 1331
    },
    {
      "epoch": 8.64,
      "grad_norm": 0.26171875,
      "learning_rate": 5.424050206373976e-06,
      "loss": 2.854,
      "step": 1332
    },
    {
      "epoch": 8.64,
      "grad_norm": 0.271484375,
      "learning_rate": 5.3729738486262556e-06,
      "loss": 2.9737,
      "step": 1333
    },
    {
      "epoch": 8.65,
      "grad_norm": 0.267578125,
      "learning_rate": 5.3221254557386525e-06,
      "loss": 2.7648,
      "step": 1334
    },
    {
      "epoch": 8.66,
      "grad_norm": 0.26171875,
      "learning_rate": 5.271505287456152e-06,
      "loss": 2.8901,
      "step": 1335
    },
    {
      "epoch": 8.66,
      "grad_norm": 0.26171875,
      "learning_rate": 5.221113602357936e-06,
      "loss": 2.9008,
      "step": 1336
    },
    {
      "epoch": 8.67,
      "grad_norm": 0.25390625,
      "learning_rate": 5.170950657856022e-06,
      "loss": 2.7811,
      "step": 1337
    },
    {
      "epoch": 8.68,
      "grad_norm": 0.251953125,
      "learning_rate": 5.121016710194004e-06,
      "loss": 2.873,
      "step": 1338
    },
    {
      "epoch": 8.68,
      "grad_norm": 0.2412109375,
      "learning_rate": 5.071312014445667e-06,
      "loss": 2.8274,
      "step": 1339
    },
    {
      "epoch": 8.69,
      "grad_norm": 0.2578125,
      "learning_rate": 5.021836824513759e-06,
      "loss": 2.816,
      "step": 1340
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.263671875,
      "learning_rate": 4.972591393128651e-06,
      "loss": 2.9289,
      "step": 1341
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.27734375,
      "learning_rate": 4.92357597184705e-06,
      "loss": 2.7901,
      "step": 1342
    },
    {
      "epoch": 8.71,
      "grad_norm": 0.2578125,
      "learning_rate": 4.874790811050711e-06,
      "loss": 2.9134,
      "step": 1343
    },
    {
      "epoch": 8.71,
      "grad_norm": 0.26171875,
      "learning_rate": 4.8262361599451855e-06,
      "loss": 2.8306,
      "step": 1344
    },
    {
      "epoch": 8.72,
      "grad_norm": 0.31640625,
      "learning_rate": 4.777912266558532e-06,
      "loss": 2.8537,
      "step": 1345
    },
    {
      "epoch": 8.73,
      "grad_norm": 0.267578125,
      "learning_rate": 4.729819377740019e-06,
      "loss": 2.9383,
      "step": 1346
    },
    {
      "epoch": 8.73,
      "grad_norm": 0.306640625,
      "learning_rate": 4.681957739158938e-06,
      "loss": 2.8747,
      "step": 1347
    },
    {
      "epoch": 8.74,
      "grad_norm": 0.259765625,
      "learning_rate": 4.634327595303251e-06,
      "loss": 3.0087,
      "step": 1348
    },
    {
      "epoch": 8.75,
      "grad_norm": 0.26953125,
      "learning_rate": 4.586929189478428e-06,
      "loss": 2.8355,
      "step": 1349
    },
    {
      "epoch": 8.75,
      "grad_norm": 0.326171875,
      "learning_rate": 4.53976276380616e-06,
      "loss": 2.793,
      "step": 1350
    },
    {
      "epoch": 8.76,
      "grad_norm": 0.2578125,
      "learning_rate": 4.492828559223111e-06,
      "loss": 2.8766,
      "step": 1351
    },
    {
      "epoch": 8.77,
      "grad_norm": 0.259765625,
      "learning_rate": 4.446126815479751e-06,
      "loss": 2.7476,
      "step": 1352
    },
    {
      "epoch": 8.77,
      "grad_norm": 0.248046875,
      "learning_rate": 4.399657771139038e-06,
      "loss": 2.8806,
      "step": 1353
    },
    {
      "epoch": 8.78,
      "grad_norm": 0.2470703125,
      "learning_rate": 4.353421663575302e-06,
      "loss": 2.7699,
      "step": 1354
    },
    {
      "epoch": 8.79,
      "grad_norm": 0.248046875,
      "learning_rate": 4.307418728972934e-06,
      "loss": 2.8096,
      "step": 1355
    },
    {
      "epoch": 8.79,
      "grad_norm": 0.259765625,
      "learning_rate": 4.261649202325252e-06,
      "loss": 2.88,
      "step": 1356
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.267578125,
      "learning_rate": 4.216113317433257e-06,
      "loss": 2.9165,
      "step": 1357
    },
    {
      "epoch": 8.81,
      "grad_norm": 0.25,
      "learning_rate": 4.170811306904459e-06,
      "loss": 2.8305,
      "step": 1358
    },
    {
      "epoch": 8.81,
      "grad_norm": 0.26953125,
      "learning_rate": 4.125743402151705e-06,
      "loss": 2.9095,
      "step": 1359
    },
    {
      "epoch": 8.82,
      "grad_norm": 0.24609375,
      "learning_rate": 4.080909833391944e-06,
      "loss": 2.9131,
      "step": 1360
    },
    {
      "epoch": 8.83,
      "grad_norm": 0.25,
      "learning_rate": 4.036310829645123e-06,
      "loss": 2.808,
      "step": 1361
    },
    {
      "epoch": 8.83,
      "grad_norm": 0.26171875,
      "learning_rate": 3.9919466187329395e-06,
      "loss": 2.8543,
      "step": 1362
    },
    {
      "epoch": 8.84,
      "grad_norm": 0.2470703125,
      "learning_rate": 3.947817427277756e-06,
      "loss": 2.8599,
      "step": 1363
    },
    {
      "epoch": 8.84,
      "grad_norm": 0.259765625,
      "learning_rate": 3.903923480701349e-06,
      "loss": 2.842,
      "step": 1364
    },
    {
      "epoch": 8.85,
      "grad_norm": 0.3046875,
      "learning_rate": 3.860265003223868e-06,
      "loss": 2.8658,
      "step": 1365
    },
    {
      "epoch": 8.86,
      "grad_norm": 0.267578125,
      "learning_rate": 3.816842217862604e-06,
      "loss": 3.0069,
      "step": 1366
    },
    {
      "epoch": 8.86,
      "grad_norm": 0.2451171875,
      "learning_rate": 3.7736553464308767e-06,
      "loss": 2.7716,
      "step": 1367
    },
    {
      "epoch": 8.87,
      "grad_norm": 0.248046875,
      "learning_rate": 3.730704609536928e-06,
      "loss": 2.6785,
      "step": 1368
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.26953125,
      "learning_rate": 3.687990226582744e-06,
      "loss": 2.8028,
      "step": 1369
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.2578125,
      "learning_rate": 3.6455124157629805e-06,
      "loss": 2.8669,
      "step": 1370
    },
    {
      "epoch": 8.89,
      "grad_norm": 0.3203125,
      "learning_rate": 3.603271394063823e-06,
      "loss": 2.8146,
      "step": 1371
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.28515625,
      "learning_rate": 3.561267377261884e-06,
      "loss": 2.9289,
      "step": 1372
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.25390625,
      "learning_rate": 3.5195005799231075e-06,
      "loss": 2.9048,
      "step": 1373
    },
    {
      "epoch": 8.91,
      "grad_norm": 0.28515625,
      "learning_rate": 3.4779712154016485e-06,
      "loss": 2.7739,
      "step": 1374
    },
    {
      "epoch": 8.92,
      "grad_norm": 0.263671875,
      "learning_rate": 3.436679495838835e-06,
      "loss": 2.8506,
      "step": 1375
    },
    {
      "epoch": 8.92,
      "grad_norm": 0.2490234375,
      "learning_rate": 3.3956256321620196e-06,
      "loss": 2.8283,
      "step": 1376
    },
    {
      "epoch": 8.93,
      "grad_norm": 0.263671875,
      "learning_rate": 3.354809834083561e-06,
      "loss": 2.9352,
      "step": 1377
    },
    {
      "epoch": 8.94,
      "grad_norm": 0.265625,
      "learning_rate": 3.3142323100997018e-06,
      "loss": 2.8328,
      "step": 1378
    },
    {
      "epoch": 8.94,
      "grad_norm": 0.25390625,
      "learning_rate": 3.2738932674895418e-06,
      "loss": 2.9086,
      "step": 1379
    },
    {
      "epoch": 8.95,
      "grad_norm": 0.251953125,
      "learning_rate": 3.2337929123139434e-06,
      "loss": 2.8863,
      "step": 1380
    },
    {
      "epoch": 8.95,
      "grad_norm": 0.2578125,
      "learning_rate": 3.193931449414539e-06,
      "loss": 2.7971,
      "step": 1381
    },
    {
      "epoch": 8.96,
      "grad_norm": 0.25,
      "learning_rate": 3.15430908241261e-06,
      "loss": 2.8266,
      "step": 1382
    },
    {
      "epoch": 8.97,
      "grad_norm": 0.240234375,
      "learning_rate": 3.1149260137080914e-06,
      "loss": 2.8768,
      "step": 1383
    },
    {
      "epoch": 8.97,
      "grad_norm": 0.251953125,
      "learning_rate": 3.075782444478542e-06,
      "loss": 2.9464,
      "step": 1384
    },
    {
      "epoch": 8.98,
      "grad_norm": 0.279296875,
      "learning_rate": 3.0368785746780927e-06,
      "loss": 2.9366,
      "step": 1385
    },
    {
      "epoch": 8.99,
      "grad_norm": 0.2490234375,
      "learning_rate": 2.9982146030364365e-06,
      "loss": 2.8242,
      "step": 1386
    },
    {
      "epoch": 8.99,
      "grad_norm": 0.267578125,
      "learning_rate": 2.9597907270577985e-06,
      "loss": 2.9429,
      "step": 1387
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.26171875,
      "learning_rate": 2.9216071430199776e-06,
      "loss": 2.814,
      "step": 1388
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.2490234375,
      "learning_rate": 2.883664045973272e-06,
      "loss": 2.8824,
      "step": 1389
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.25,
      "learning_rate": 2.8459616297395466e-06,
      "loss": 2.7554,
      "step": 1390
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.28515625,
      "learning_rate": 2.8085000869111923e-06,
      "loss": 2.8397,
      "step": 1391
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.26953125,
      "learning_rate": 2.7712796088501693e-06,
      "loss": 2.8049,
      "step": 1392
    },
    {
      "epoch": 9.03,
      "grad_norm": 0.2412109375,
      "learning_rate": 2.7343003856870384e-06,
      "loss": 2.6396,
      "step": 1393
    },
    {
      "epoch": 9.04,
      "grad_norm": 0.25390625,
      "learning_rate": 2.6975626063199475e-06,
      "loss": 2.9384,
      "step": 1394
    },
    {
      "epoch": 9.05,
      "grad_norm": 0.24609375,
      "learning_rate": 2.661066458413741e-06,
      "loss": 2.8426,
      "step": 1395
    },
    {
      "epoch": 9.05,
      "grad_norm": 0.251953125,
      "learning_rate": 2.6248121283989015e-06,
      "loss": 2.8379,
      "step": 1396
    },
    {
      "epoch": 9.06,
      "grad_norm": 0.291015625,
      "learning_rate": 2.588799801470704e-06,
      "loss": 2.9481,
      "step": 1397
    },
    {
      "epoch": 9.07,
      "grad_norm": 0.31640625,
      "learning_rate": 2.5530296615881855e-06,
      "loss": 2.8211,
      "step": 1398
    },
    {
      "epoch": 9.07,
      "grad_norm": 0.263671875,
      "learning_rate": 2.517501891473234e-06,
      "loss": 2.9345,
      "step": 1399
    },
    {
      "epoch": 9.08,
      "grad_norm": 0.267578125,
      "learning_rate": 2.4822166726096774e-06,
      "loss": 2.9028,
      "step": 1400
    },
    {
      "epoch": 9.08,
      "grad_norm": 0.25390625,
      "learning_rate": 2.4471741852423237e-06,
      "loss": 2.8031,
      "step": 1401
    },
    {
      "epoch": 9.09,
      "grad_norm": 0.251953125,
      "learning_rate": 2.4123746083760667e-06,
      "loss": 2.7946,
      "step": 1402
    },
    {
      "epoch": 9.1,
      "grad_norm": 0.25,
      "learning_rate": 2.3778181197749383e-06,
      "loss": 2.9031,
      "step": 1403
    },
    {
      "epoch": 9.1,
      "grad_norm": 0.259765625,
      "learning_rate": 2.343504895961246e-06,
      "loss": 2.9495,
      "step": 1404
    },
    {
      "epoch": 9.11,
      "grad_norm": 0.251953125,
      "learning_rate": 2.3094351122146307e-06,
      "loss": 2.8168,
      "step": 1405
    },
    {
      "epoch": 9.12,
      "grad_norm": 0.271484375,
      "learning_rate": 2.275608942571189e-06,
      "loss": 2.9028,
      "step": 1406
    },
    {
      "epoch": 9.12,
      "grad_norm": 0.2578125,
      "learning_rate": 2.2420265598225907e-06,
      "loss": 2.9088,
      "step": 1407
    },
    {
      "epoch": 9.13,
      "grad_norm": 0.267578125,
      "learning_rate": 2.2086881355151633e-06,
      "loss": 2.9749,
      "step": 1408
    },
    {
      "epoch": 9.14,
      "grad_norm": 0.2578125,
      "learning_rate": 2.1755938399490693e-06,
      "loss": 2.8093,
      "step": 1409
    },
    {
      "epoch": 9.14,
      "grad_norm": 0.26171875,
      "learning_rate": 2.142743842177386e-06,
      "loss": 2.8558,
      "step": 1410
    },
    {
      "epoch": 9.15,
      "grad_norm": 0.296875,
      "learning_rate": 2.110138310005283e-06,
      "loss": 2.862,
      "step": 1411
    },
    {
      "epoch": 9.16,
      "grad_norm": 0.251953125,
      "learning_rate": 2.077777409989118e-06,
      "loss": 2.702,
      "step": 1412
    },
    {
      "epoch": 9.16,
      "grad_norm": 0.255859375,
      "learning_rate": 2.0456613074356368e-06,
      "loss": 2.8275,
      "step": 1413
    },
    {
      "epoch": 9.17,
      "grad_norm": 0.2578125,
      "learning_rate": 2.013790166401097e-06,
      "loss": 2.9701,
      "step": 1414
    },
    {
      "epoch": 9.18,
      "grad_norm": 0.2734375,
      "learning_rate": 1.98216414969043e-06,
      "loss": 2.8442,
      "step": 1415
    },
    {
      "epoch": 9.18,
      "grad_norm": 0.25390625,
      "learning_rate": 1.950783418856422e-06,
      "loss": 2.9398,
      "step": 1416
    },
    {
      "epoch": 9.19,
      "grad_norm": 0.251953125,
      "learning_rate": 1.919648134198887e-06,
      "loss": 2.773,
      "step": 1417
    },
    {
      "epoch": 9.19,
      "grad_norm": 0.251953125,
      "learning_rate": 1.8887584547638504e-06,
      "loss": 2.8388,
      "step": 1418
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.26171875,
      "learning_rate": 1.8581145383427145e-06,
      "loss": 2.9416,
      "step": 1419
    },
    {
      "epoch": 9.21,
      "grad_norm": 0.25,
      "learning_rate": 1.827716541471486e-06,
      "loss": 2.9179,
      "step": 1420
    },
    {
      "epoch": 9.21,
      "grad_norm": 0.267578125,
      "learning_rate": 1.7975646194299478e-06,
      "loss": 2.6622,
      "step": 1421
    },
    {
      "epoch": 9.22,
      "grad_norm": 0.2412109375,
      "learning_rate": 1.7676589262408783e-06,
      "loss": 2.8724,
      "step": 1422
    },
    {
      "epoch": 9.23,
      "grad_norm": 0.26171875,
      "learning_rate": 1.7379996146692723e-06,
      "loss": 2.8157,
      "step": 1423
    },
    {
      "epoch": 9.23,
      "grad_norm": 0.279296875,
      "learning_rate": 1.7085868362215374e-06,
      "loss": 2.9417,
      "step": 1424
    },
    {
      "epoch": 9.24,
      "grad_norm": 0.279296875,
      "learning_rate": 1.6794207411447549e-06,
      "loss": 2.8669,
      "step": 1425
    },
    {
      "epoch": 9.25,
      "grad_norm": 0.279296875,
      "learning_rate": 1.65050147842587e-06,
      "loss": 2.9946,
      "step": 1426
    },
    {
      "epoch": 9.25,
      "grad_norm": 0.255859375,
      "learning_rate": 1.6218291957909748e-06,
      "loss": 2.843,
      "step": 1427
    },
    {
      "epoch": 9.26,
      "grad_norm": 0.265625,
      "learning_rate": 1.5934040397045158e-06,
      "loss": 2.7789,
      "step": 1428
    },
    {
      "epoch": 9.27,
      "grad_norm": 0.25,
      "learning_rate": 1.5652261553685654e-06,
      "loss": 2.8071,
      "step": 1429
    },
    {
      "epoch": 9.27,
      "grad_norm": 0.283203125,
      "learning_rate": 1.5372956867220677e-06,
      "loss": 2.8281,
      "step": 1430
    },
    {
      "epoch": 9.28,
      "grad_norm": 0.255859375,
      "learning_rate": 1.5096127764401447e-06,
      "loss": 2.9783,
      "step": 1431
    },
    {
      "epoch": 9.29,
      "grad_norm": 0.24609375,
      "learning_rate": 1.4821775659332959e-06,
      "loss": 2.814,
      "step": 1432
    },
    {
      "epoch": 9.29,
      "grad_norm": 0.244140625,
      "learning_rate": 1.4549901953467282e-06,
      "loss": 2.77,
      "step": 1433
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.25390625,
      "learning_rate": 1.428050803559644e-06,
      "loss": 2.9018,
      "step": 1434
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.244140625,
      "learning_rate": 1.4013595281844871e-06,
      "loss": 2.9048,
      "step": 1435
    },
    {
      "epoch": 9.31,
      "grad_norm": 0.267578125,
      "learning_rate": 1.3749165055662816e-06,
      "loss": 2.7882,
      "step": 1436
    },
    {
      "epoch": 9.32,
      "grad_norm": 0.2490234375,
      "learning_rate": 1.348721870781916e-06,
      "loss": 2.7763,
      "step": 1437
    },
    {
      "epoch": 9.32,
      "grad_norm": 0.251953125,
      "learning_rate": 1.3227757576394717e-06,
      "loss": 2.9318,
      "step": 1438
    },
    {
      "epoch": 9.33,
      "grad_norm": 0.279296875,
      "learning_rate": 1.2970782986775009e-06,
      "loss": 2.8633,
      "step": 1439
    },
    {
      "epoch": 9.34,
      "grad_norm": 0.25,
      "learning_rate": 1.2716296251644e-06,
      "loss": 2.8152,
      "step": 1440
    },
    {
      "epoch": 9.34,
      "grad_norm": 0.2578125,
      "learning_rate": 1.2464298670976926e-06,
      "loss": 2.9438,
      "step": 1441
    },
    {
      "epoch": 9.35,
      "grad_norm": 0.251953125,
      "learning_rate": 1.2214791532033975e-06,
      "loss": 2.8686,
      "step": 1442
    },
    {
      "epoch": 9.36,
      "grad_norm": 0.2578125,
      "learning_rate": 1.1967776109353734e-06,
      "loss": 2.8981,
      "step": 1443
    },
    {
      "epoch": 9.36,
      "grad_norm": 0.267578125,
      "learning_rate": 1.1723253664746136e-06,
      "loss": 2.8599,
      "step": 1444
    },
    {
      "epoch": 9.37,
      "grad_norm": 0.2578125,
      "learning_rate": 1.1481225447286803e-06,
      "loss": 2.7798,
      "step": 1445
    },
    {
      "epoch": 9.38,
      "grad_norm": 0.255859375,
      "learning_rate": 1.1241692693310158e-06,
      "loss": 2.9574,
      "step": 1446
    },
    {
      "epoch": 9.38,
      "grad_norm": 0.26171875,
      "learning_rate": 1.100465662640332e-06,
      "loss": 2.8267,
      "step": 1447
    },
    {
      "epoch": 9.39,
      "grad_norm": 0.251953125,
      "learning_rate": 1.0770118457399558e-06,
      "loss": 2.895,
      "step": 1448
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.28125,
      "learning_rate": 1.0538079384372456e-06,
      "loss": 2.7203,
      "step": 1449
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.2490234375,
      "learning_rate": 1.0308540592629756e-06,
      "loss": 2.8884,
      "step": 1450
    },
    {
      "epoch": 9.41,
      "grad_norm": 0.255859375,
      "learning_rate": 1.0081503254707026e-06,
      "loss": 2.7549,
      "step": 1451
    },
    {
      "epoch": 9.42,
      "grad_norm": 0.251953125,
      "learning_rate": 9.856968530361942e-07,
      "loss": 2.8363,
      "step": 1452
    },
    {
      "epoch": 9.42,
      "grad_norm": 0.24609375,
      "learning_rate": 9.634937566568192e-07,
      "loss": 2.7862,
      "step": 1453
    },
    {
      "epoch": 9.43,
      "grad_norm": 0.255859375,
      "learning_rate": 9.415411497509796e-07,
      "loss": 2.7917,
      "step": 1454
    },
    {
      "epoch": 9.43,
      "grad_norm": 0.271484375,
      "learning_rate": 9.198391444575071e-07,
      "loss": 2.8357,
      "step": 1455
    },
    {
      "epoch": 9.44,
      "grad_norm": 0.255859375,
      "learning_rate": 8.983878516351241e-07,
      "loss": 2.8501,
      "step": 1456
    },
    {
      "epoch": 9.45,
      "grad_norm": 0.26171875,
      "learning_rate": 8.771873808618436e-07,
      "loss": 2.8656,
      "step": 1457
    },
    {
      "epoch": 9.45,
      "grad_norm": 0.255859375,
      "learning_rate": 8.562378404344263e-07,
      "loss": 2.7917,
      "step": 1458
    },
    {
      "epoch": 9.46,
      "grad_norm": 0.265625,
      "learning_rate": 8.355393373678188e-07,
      "loss": 2.7524,
      "step": 1459
    },
    {
      "epoch": 9.47,
      "grad_norm": 0.2578125,
      "learning_rate": 8.150919773946164e-07,
      "loss": 2.95,
      "step": 1460
    },
    {
      "epoch": 9.47,
      "grad_norm": 0.25390625,
      "learning_rate": 7.948958649645288e-07,
      "loss": 2.8743,
      "step": 1461
    },
    {
      "epoch": 9.48,
      "grad_norm": 0.251953125,
      "learning_rate": 7.749511032438206e-07,
      "loss": 2.8418,
      "step": 1462
    },
    {
      "epoch": 9.49,
      "grad_norm": 0.267578125,
      "learning_rate": 7.552577941148165e-07,
      "loss": 2.8385,
      "step": 1463
    },
    {
      "epoch": 9.49,
      "grad_norm": 0.251953125,
      "learning_rate": 7.358160381753576e-07,
      "loss": 2.8001,
      "step": 1464
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.259765625,
      "learning_rate": 7.166259347382854e-07,
      "loss": 2.8884,
      "step": 1465
    },
    {
      "epoch": 9.51,
      "grad_norm": 0.2578125,
      "learning_rate": 6.97687581830958e-07,
      "loss": 2.762,
      "step": 1466
    },
    {
      "epoch": 9.51,
      "grad_norm": 0.28125,
      "learning_rate": 6.79001076194724e-07,
      "loss": 2.8771,
      "step": 1467
    },
    {
      "epoch": 9.52,
      "grad_norm": 0.2490234375,
      "learning_rate": 6.605665132844552e-07,
      "loss": 2.8228,
      "step": 1468
    },
    {
      "epoch": 9.53,
      "grad_norm": 0.24609375,
      "learning_rate": 6.423839872680304e-07,
      "loss": 2.7962,
      "step": 1469
    },
    {
      "epoch": 9.53,
      "grad_norm": 0.248046875,
      "learning_rate": 6.244535910258698e-07,
      "loss": 2.8643,
      "step": 1470
    },
    {
      "epoch": 9.54,
      "grad_norm": 0.2578125,
      "learning_rate": 6.067754161504624e-07,
      "loss": 2.8168,
      "step": 1471
    },
    {
      "epoch": 9.54,
      "grad_norm": 0.25390625,
      "learning_rate": 5.893495529458892e-07,
      "loss": 2.9881,
      "step": 1472
    },
    {
      "epoch": 9.55,
      "grad_norm": 0.255859375,
      "learning_rate": 5.721760904273676e-07,
      "loss": 2.8927,
      "step": 1473
    },
    {
      "epoch": 9.56,
      "grad_norm": 0.25,
      "learning_rate": 5.552551163207964e-07,
      "loss": 2.7481,
      "step": 1474
    },
    {
      "epoch": 9.56,
      "grad_norm": 0.2578125,
      "learning_rate": 5.385867170623061e-07,
      "loss": 2.9895,
      "step": 1475
    },
    {
      "epoch": 9.57,
      "grad_norm": 0.24609375,
      "learning_rate": 5.221709777978201e-07,
      "loss": 2.8233,
      "step": 1476
    },
    {
      "epoch": 9.58,
      "grad_norm": 0.255859375,
      "learning_rate": 5.060079823826225e-07,
      "loss": 2.8982,
      "step": 1477
    },
    {
      "epoch": 9.58,
      "grad_norm": 0.25390625,
      "learning_rate": 4.900978133809131e-07,
      "loss": 2.8811,
      "step": 1478
    },
    {
      "epoch": 9.59,
      "grad_norm": 0.265625,
      "learning_rate": 4.7444055206540825e-07,
      "loss": 2.7993,
      "step": 1479
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.259765625,
      "learning_rate": 4.590362784169022e-07,
      "loss": 2.734,
      "step": 1480
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.2490234375,
      "learning_rate": 4.43885071123884e-07,
      "loss": 2.7948,
      "step": 1481
    },
    {
      "epoch": 9.61,
      "grad_norm": 0.26953125,
      "learning_rate": 4.2898700758212676e-07,
      "loss": 2.8048,
      "step": 1482
    },
    {
      "epoch": 9.62,
      "grad_norm": 0.265625,
      "learning_rate": 4.143421638942713e-07,
      "loss": 2.9703,
      "step": 1483
    },
    {
      "epoch": 9.62,
      "grad_norm": 0.263671875,
      "learning_rate": 3.9995061486947094e-07,
      "loss": 2.9298,
      "step": 1484
    },
    {
      "epoch": 9.63,
      "grad_norm": 0.259765625,
      "learning_rate": 3.858124340229863e-07,
      "loss": 2.8704,
      "step": 1485
    },
    {
      "epoch": 9.64,
      "grad_norm": 0.251953125,
      "learning_rate": 3.719276935758076e-07,
      "loss": 2.9259,
      "step": 1486
    },
    {
      "epoch": 9.64,
      "grad_norm": 0.291015625,
      "learning_rate": 3.582964644543163e-07,
      "loss": 2.7558,
      "step": 1487
    },
    {
      "epoch": 9.65,
      "grad_norm": 0.2578125,
      "learning_rate": 3.4491881628987976e-07,
      "loss": 2.8796,
      "step": 1488
    },
    {
      "epoch": 9.66,
      "grad_norm": 0.265625,
      "learning_rate": 3.317948174185237e-07,
      "loss": 2.9635,
      "step": 1489
    },
    {
      "epoch": 9.66,
      "grad_norm": 0.2578125,
      "learning_rate": 3.1892453488058803e-07,
      "loss": 2.9359,
      "step": 1490
    },
    {
      "epoch": 9.67,
      "grad_norm": 0.28125,
      "learning_rate": 3.0630803442035504e-07,
      "loss": 2.8037,
      "step": 1491
    },
    {
      "epoch": 9.67,
      "grad_norm": 0.2578125,
      "learning_rate": 2.9394538048574394e-07,
      "loss": 2.827,
      "step": 1492
    },
    {
      "epoch": 9.68,
      "grad_norm": 0.265625,
      "learning_rate": 2.8183663622795564e-07,
      "loss": 2.9209,
      "step": 1493
    },
    {
      "epoch": 9.69,
      "grad_norm": 0.26171875,
      "learning_rate": 2.699818635011842e-07,
      "loss": 2.8436,
      "step": 1494
    },
    {
      "epoch": 9.69,
      "grad_norm": 0.25,
      "learning_rate": 2.5838112286226123e-07,
      "loss": 2.8781,
      "step": 1495
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.2470703125,
      "learning_rate": 2.470344735703678e-07,
      "loss": 2.9189,
      "step": 1496
    },
    {
      "epoch": 9.71,
      "grad_norm": 0.25390625,
      "learning_rate": 2.359419735867452e-07,
      "loss": 2.814,
      "step": 1497
    },
    {
      "epoch": 9.71,
      "grad_norm": 0.26171875,
      "learning_rate": 2.251036795743622e-07,
      "loss": 2.8673,
      "step": 1498
    },
    {
      "epoch": 9.72,
      "grad_norm": 0.255859375,
      "learning_rate": 2.1451964689765402e-07,
      "loss": 2.7655,
      "step": 1499
    },
    {
      "epoch": 9.73,
      "grad_norm": 0.259765625,
      "learning_rate": 2.0418992962224492e-07,
      "loss": 2.7865,
      "step": 1500
    },
    {
      "epoch": 9.73,
      "grad_norm": 0.255859375,
      "learning_rate": 1.941145805146427e-07,
      "loss": 2.9188,
      "step": 1501
    },
    {
      "epoch": 9.74,
      "grad_norm": 0.310546875,
      "learning_rate": 1.8429365104198348e-07,
      "loss": 2.8706,
      "step": 1502
    },
    {
      "epoch": 9.75,
      "grad_norm": 0.2431640625,
      "learning_rate": 1.7472719137178738e-07,
      "loss": 2.8076,
      "step": 1503
    },
    {
      "epoch": 9.75,
      "grad_norm": 0.25390625,
      "learning_rate": 1.6541525037166994e-07,
      "loss": 3.057,
      "step": 1504
    },
    {
      "epoch": 9.76,
      "grad_norm": 0.265625,
      "learning_rate": 1.5635787560911441e-07,
      "loss": 2.8301,
      "step": 1505
    },
    {
      "epoch": 9.77,
      "grad_norm": 0.294921875,
      "learning_rate": 1.4755511335123318e-07,
      "loss": 2.8197,
      "step": 1506
    },
    {
      "epoch": 9.77,
      "grad_norm": 0.26953125,
      "learning_rate": 1.3900700856450121e-07,
      "loss": 2.8947,
      "step": 1507
    },
    {
      "epoch": 9.78,
      "grad_norm": 0.255859375,
      "learning_rate": 1.307136049145563e-07,
      "loss": 2.9376,
      "step": 1508
    },
    {
      "epoch": 9.78,
      "grad_norm": 0.2578125,
      "learning_rate": 1.2267494476596031e-07,
      "loss": 2.7466,
      "step": 1509
    },
    {
      "epoch": 9.79,
      "grad_norm": 0.25,
      "learning_rate": 1.1489106918200487e-07,
      "loss": 2.8941,
      "step": 1510
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.2470703125,
      "learning_rate": 1.0736201792446166e-07,
      "loss": 2.918,
      "step": 1511
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.2490234375,
      "learning_rate": 1.0008782945341577e-07,
      "loss": 2.7191,
      "step": 1512
    },
    {
      "epoch": 9.81,
      "grad_norm": 0.2470703125,
      "learning_rate": 9.306854092705486e-08,
      "loss": 2.8568,
      "step": 1513
    },
    {
      "epoch": 9.82,
      "grad_norm": 0.248046875,
      "learning_rate": 8.630418820148034e-08,
      "loss": 2.6577,
      "step": 1514
    },
    {
      "epoch": 9.82,
      "grad_norm": 0.251953125,
      "learning_rate": 7.979480583052424e-08,
      "loss": 2.7916,
      "step": 1515
    },
    {
      "epoch": 9.83,
      "grad_norm": 0.248046875,
      "learning_rate": 7.354042706556597e-08,
      "loss": 2.8198,
      "step": 1516
    },
    {
      "epoch": 9.84,
      "grad_norm": 0.259765625,
      "learning_rate": 6.754108385538249e-08,
      "loss": 2.8567,
      "step": 1517
    },
    {
      "epoch": 9.84,
      "grad_norm": 0.265625,
      "learning_rate": 6.179680684595402e-08,
      "loss": 2.6246,
      "step": 1518
    },
    {
      "epoch": 9.85,
      "grad_norm": 0.255859375,
      "learning_rate": 5.630762538034739e-08,
      "loss": 2.8629,
      "step": 1519
    },
    {
      "epoch": 9.86,
      "grad_norm": 0.27734375,
      "learning_rate": 5.107356749853298e-08,
      "loss": 2.8525,
      "step": 1520
    },
    {
      "epoch": 9.86,
      "grad_norm": 0.267578125,
      "learning_rate": 4.609465993724027e-08,
      "loss": 2.6964,
      "step": 1521
    },
    {
      "epoch": 9.87,
      "grad_norm": 0.25390625,
      "learning_rate": 4.137092812985799e-08,
      "loss": 2.9054,
      "step": 1522
    },
    {
      "epoch": 9.88,
      "grad_norm": 0.3125,
      "learning_rate": 3.6902396206267566e-08,
      "loss": 2.9781,
      "step": 1523
    },
    {
      "epoch": 9.88,
      "grad_norm": 0.25390625,
      "learning_rate": 3.2689086992720996e-08,
      "loss": 2.8504,
      "step": 1524
    },
    {
      "epoch": 9.89,
      "grad_norm": 0.263671875,
      "learning_rate": 2.873102201175759e-08,
      "loss": 2.8692,
      "step": 1525
    },
    {
      "epoch": 9.9,
      "grad_norm": 0.255859375,
      "learning_rate": 2.5028221482059634e-08,
      "loss": 2.775,
      "step": 1526
    },
    {
      "epoch": 9.9,
      "grad_norm": 0.26171875,
      "learning_rate": 2.1580704318358013e-08,
      "loss": 2.794,
      "step": 1527
    },
    {
      "epoch": 9.91,
      "grad_norm": 0.283203125,
      "learning_rate": 1.8388488131348968e-08,
      "loss": 2.7841,
      "step": 1528
    },
    {
      "epoch": 9.91,
      "grad_norm": 0.259765625,
      "learning_rate": 1.5451589227583052e-08,
      "loss": 2.8619,
      "step": 1529
    },
    {
      "epoch": 9.92,
      "grad_norm": 0.2578125,
      "learning_rate": 1.2770022609409626e-08,
      "loss": 2.9309,
      "step": 1530
    },
    {
      "epoch": 9.93,
      "grad_norm": 0.25390625,
      "learning_rate": 1.034380197486029e-08,
      "loss": 2.7287,
      "step": 1531
    },
    {
      "epoch": 9.93,
      "grad_norm": 0.2451171875,
      "learning_rate": 8.17293971761557e-09,
      "loss": 2.8099,
      "step": 1532
    },
    {
      "epoch": 9.94,
      "grad_norm": 0.240234375,
      "learning_rate": 6.257446926932753e-09,
      "loss": 2.6257,
      "step": 1533
    },
    {
      "epoch": 9.95,
      "grad_norm": 0.265625,
      "learning_rate": 4.5973333875792835e-09,
      "loss": 3.0126,
      "step": 1534
    },
    {
      "epoch": 9.95,
      "grad_norm": 0.2490234375,
      "learning_rate": 3.1926075797827917e-09,
      "loss": 2.6038,
      "step": 1535
    },
    {
      "epoch": 9.96,
      "grad_norm": 0.251953125,
      "learning_rate": 2.043276679197792e-09,
      "loss": 2.829,
      "step": 1536
    }
  ],
  "logging_steps": 1,
  "max_steps": 1540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 16,
  "total_flos": 1.5237777744042394e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
